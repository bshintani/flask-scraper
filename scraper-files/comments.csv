Post ID,Answer ID,User ID,Comment,Date
1,1,1,"Seems legit. But that also means that I'll have to use TLS with plain HTTP; my current hardware doesn't support TLS/SSL/HTTPS - only http, tcp or udp - so I'll have to do TLS 'by hand'. Will it still be advisable to use TLS or are there some simpler methods?",Oct 14 at 17:34
1,1,2,You can use mbed.com/en/technologies/security/mbed-tls to add TLS support to your project. The samples even have a TLS client ready to use. And a server too.,Oct 15 at 1:36
1,1,1,"mbed-tls actually looks very nice, thanks.",Oct 15 at 18:09
1,2,1,"Exactly, so I want to know how can I keep the data secure when user has physical access to device.",Oct 13 at 20:33
1,2,3,"@Amomum: If you have sensitive data on the device in plain (i.e. not encrypted) since they were either created there or they are needed there for doing some computations, then you need to protect these internals of the device against physical access. As you realized yourself: your hardware does not provide this protection. Thus you would need to get hardware which is more tamper resistent. That's why smartcards and similar devices with sensitive data are specifically protected so that they rather break instead of revealing the secrets.",Oct 13 at 20:39
1,2,1,Let's say I can't change current hardware - what's the best I can do?,Oct 13 at 20:45
1,2,3,"@Amomum: What is the best is hard to say without knowing more about the specific use case, i.e. why the IoT device needs the sensitive data in the first place  and what are the risks if the attacker gets access to specific data or can modify the data in a specific way or just corrupt the data.  The best is probably to keep sensitive data off the device and thus far away from the attacker. Others ways might be to obfuscate what's going on or just to have a useful strategy to deal with a compromise of the data.",Oct 13 at 21:20
1,2,1,Device can access remote database; it doesn't actually hold any sensetive data. I guess my main concern is that attacker should not be able to imitate other devices and rewrite their database entries - if he has physical access to his own device. I suppose that if every device will have it's own long and random secret key that is not derived from device ID - that should be enough to mitigate this particular problem?,Oct 13 at 22:09
3,1,7,Smart cards & TPM chips are not particularly IoT devices. The primary purpose of a smart card or TPM chip is to hold certificates. I am asking for e.g. of IoT devices which support certificate enrolment protocols & can use the certificates,Jun 24 at 8:39
3,1,3,@user93353: I did not mean to claim that smart cards are IoT devices and TPM chips are definitely not a IoT device. I mention these to show that the necessary parts to use certificates do not need much resources. I've edited the answer to make it more clear.,Jun 24 at 9:01
3,3,7,I know how certificates can be used. My question is about whether a typical IoT device is equipped to use it.,Jun 24 at 2:23
4,1,10,"From the source, I'm not sure the last ones can be labelled as ""popular"", just that they exist.",Apr 23 at 10:19
5,1,14,"Hardcoded passwords are certainly a big one. Unfortunately that's even the case for insanely expensive high-end core routers the size of your refrigerator... I have a question though, what does HMAC have to do with authentication for passwords? All an HMAC does is mitigate the issue of malleability, not provide secure key exchange.",Apr 20 at 8:40
5,1,15,"Well, my assumption was we are more concerned by the attacker gaining access. Yes, also using encryption, ideally something strong such as mutually authenticated TLS is required, if confidentiality is a concern. My worry was about certificates not being very reliable in IoT, as their distribution is difficult. A good practice for users is to block IoT devices on their routers firewall. That way, they can't be exploited from an outside network unless the attacker already gained access to the network. Using a separate VLAN may be desirable as well.",Apr 20 at 9:10
5,1,16,@PeterHarmann That still doesn't explain what HMAC has to do with this,Apr 20 at 14:35
6,1,18,"So, your answer makes it sound like a client cert is enough for security (as long as more claims aren't needed), but what about the reverse? What about JWT without any client side cert (still over tls)?",Feb 8 at 13:52
7,2,22,"Right, staying offline prevents a lot of problems. How about being on an intranet with other devices that do connect to the internet? For example, how much more vulnerable is an IoT system if it has a raspberry pi as part of its internal network, which in turn is connecting to an internet connected smart phone via bluetooth?",Feb 3 at 3:58
7,2,23,"@cr0, ""device hopping"" is a real concern.  But consider, the bad actor would have to get through internet, bluetooth, and then exploit the RPi and finally exploit the IoT device.  This isn't any different than issues faced by non-IoT intranet devices.",Feb 5 at 19:48
7,5,26,"P.S. I know that that's not how ""Build a better mousetrap"" is usually used.",Feb 5 at 20:36
7,5,22,"This is helpful about physical security - all good things to consider. In my case I'm somewhat new to the area so I don't know risks first hand. Neighbors report theft in the area due to local teenagers. I see teenagers hanging out in the neighborhood but haven't had problems yet. As you said, it's about making targets ""not worth it"" to potential attackers",Feb 6 at 16:36
8,1,27,"Recently, one such doll was found to be so insecure that it was classified as ""hidden espionage device"" in Germany (and banned), see e.g. discussion over at IoT iot.stackexchange.com/questions/1074/… (one of the two referred to in the 3rd paragraph of the #toyfail quote)",Oct 31 '17 at 19:52
8,1,28,"...and if you absolutely must have them, do the sane thing and at the very least segregate them on a network segment all of their own, ideally with no access (beyond that of any untrusted device on the big bad Internet) to anything else. At least that way, if something happens, you are limiting the potential damage somewhat.",Oct 31 '17 at 19:52
8,1,29,"@Michael Kjörling, no, just NO. Anders just explained that this ""doll"" is a spy device, that needs to have access to the internet to work. Your privacy seems to be the last thing on the doll makers list to take into account. The sane thing here is to not have one!",Nov 2 '17 at 8:18
8,1,28,"@Flummox Why do you think I started out my comment the way I did, including the formatting? I agree with this answer, and there's no way I'd buy one myself (for this and for other reasons as well), but if and only if someone has a genuine need for something like this, then there still are steps that can be taken to mitigate the risks a little bit. In such a situation, not at least doing that would be the height of irresponsibility, both toward yourself, others in your household, and others on the Internet.",Nov 2 '17 at 8:26
8,2,28,"Also, keeping in mind the distinction about what a remote attacker is trying to access. Assuming you aren't a high-profile target (and if you are, you probably know better than to trust random strangers on the Internet for security advice), it's fairly unlikely that a remote attacker who gains access to an IoT device (even one that can remotely be turned into an active microphone and speaker, or camera, in your home) is particularly interested in you specifically. It's all the more likely that they are interested in the device itself, e.g. for its computational power or network connectivity.",Oct 31 '17 at 20:16
8,2,28,"In response to your edit, in fairness, I wasn't necessarily thinking of using the device as an attack bot, though that's an obvious thing that could happen (think Mirai and the DNS overload attack against Twitter and friends recently, for one). Think also e.g. bitcoin mining, or sending spam e-mails. Sure, a toy like the one exemplified in the question probably doesn't have enough computational power to make a major difference, but if the cost to the attacker is next to zero, it doesn't need to do much in order to turn a profit, especially if you've got thousands of them working for you...",Oct 31 '17 at 20:21
8,2,31,"There was a recent documentary (BBC if memory serves me correctly) showing the story of an elderly woman who answered the phone to a scammer and was convinced to transfer them a large sum of money. Key to the scam was their use of the camera and microphone on her laptop during the call. If such a device as this ""toy"" is easier to break into than a (presumably) windows machine, then this becomes just one example where an exploit of this type increases the risk surface area",Nov 2 '17 at 4:47
8,3,33,"Never mind the threats to National Security. If every conversation in a large enough sample of homes is recorded and digitised, it does not really bear thinking about that data being used in future prosecutions for crimes against the state. If it is being sent upstream for AI language learning (sold to Google or AWS, say) there may be some value in preserving languages that die out in future?",Nov 1 '17 at 3:21
9,1,39,"Steffen, you once again beat me by seconds;)",Oct 26 '17 at 16:57
9,1,40,"VPN may not be feasible option because the devices use public SIM (not M2M SIM) to connect to management server via GPRS , so I prefer to use standard PKI based TLS. Is it OK to have our own root CA to sign all device specific certs? or do we need an  intermediate CA as well?",Oct 28 '17 at 16:27
9,1,3,"@user1493834: I'm not sure why using VPN should not be possible with public SIM: a VPN only needs data transfer, same as TLS does (there are also TLS based VPNs).  Anyway, intermediate certificates are not strictly required. They are usually used to restrict the risk by restricting root CA operations which involve the CA's private key. This should not be a problem if you only sign 100 certificates in total but it might be a problem if you need to sign 100 certificates each hour.",Oct 28 '17 at 22:56
9,2,40,I meant we cannot have SSL certificate for device authentication. The devices also initiate connection to the server.,Oct 27 '17 at 15:32
11,1,46,"Ok, I understand that browsers can handle self signed certificates by manually accepting the certificate. But what's about API clients that have to accept certificates. They may fail in a large scale. How is this handled?",Sep 29 '17 at 13:02
11,1,47,"The point is not that a web browser manually accept an untrusted certificate raised by the gateway. The design I described was about your CA directly inserted in the trusted CA store (for example in linux like systems you should find it under /etc/ssl/certs/). In this way, you will not receive any security alert to accept or reject, the entire system is trusting your CA. Now you have to worry about how to securely transmit your CA to the IoT client without be intercepted or aleterated",Sep 29 '17 at 13:32
11,1,47,You also have to worry about renewing your certificates and CA periodically (because key lenght expire at a time),Sep 29 '17 at 13:33
11,1,46,Good point. To distribute the certificates for renewal it would be helpful if there are standard protocols (as OSCP Online Certificate Status Protocol to check certificates) for updating certificates without user interaction. Do you know about such protocols?,Sep 29 '17 at 13:37
12,2,49,"Even better - provide a (large) prize for security vulnerabilities, with more severe vulnerabilities (measured in maximum damage they can cause) earning a larger prize. This will hopefully convince some wannabe crackers to disclose the details (certain prize) as opposed to trying to exploit them (uncertain, possibly greater but probably smaller prize, plus risk of being caught).",Sep 1 '17 at 20:53
12,2,50,I would even encourage to make the firmware free software or open source.,Sep 2 '17 at 7:06
12,2,51,"@wizzwizz4 Many businesses do not have the capital to operate a fully-fledged bug bounty program, particularly SMEs and self-funded startups. In general I've seen these businesses offer alternative recompense, such as free or heavily discounted products, t-shirts, swag, etc. depending on the nature of the business and brand. Bug bounties do not necessarily need to be formal and costly.",Sep 2 '17 at 10:53
12,2,49,"@Polynomial Many businesses don't have the capital to not operate a bug bounty program. If a large breach is found, surely it's worth that $x for it not to be found when your clients are suing you for damages caused by a breach.",Sep 2 '17 at 11:33
12,2,51,"@wizzwizz4 I doubt that the lack of a bug bounty program would ever be the confounding factor in a breach. Bounties are great, but they're an optional layer in almost any business' defence budget, perhaps with the exception of highly public organisations. If the goal is to avoid a breach, the cost and time involved with running a BBP can be better invested in more direct defence measures such as staff training and improving blue team capabilities. BBPs are great if you've already got everything else covered and have spare budget, or if the perception of security markets well in your vertical.",Sep 2 '17 at 12:20
12,3,51,"Open source may be a step too far for a commercial product, and the ""many eyes"" principle is generally flawed (see: the state of OpenSSL before Heartbleed). That said, if the project uses any GPL licensed code without special agreement from the author then the full source must be made available anyway.",Sep 1 '17 at 14:30
12,3,28,@Polynomial If the project uses any GPL licensed code then the parts that directly touch the GPL code must be made available as source code. Not all of it. Mere aggregation still applies.,Sep 2 '17 at 23:05
12,3,52,"I can see how that might be an issue with fully Open Source. Also, it usually comes down to semantics when it comes to Open Sourcing on GPL code. I'll look into the OpenSSL matter as well, thanks for that!",Sep 4 '17 at 5:24
12,3,53,"I really think a good answer should address the issue of ""if my software has to be proprietary, is it worth encrypting/obfuscating"".  There may be plenty of reasons to keep software proprietary that have nothing to do with security (contracts with customers, red tape by management, valuable algorithms).   I also believe that publishing your source code isn't a good way to fix up an insecure software development process and shouldn't be overemphasized by dedicating the entire answer to it.",Sep 6 '17 at 21:36
12,5,49,You could always make it illegal to distribute the decryption key! Making numbers illegal definitely works...,Sep 2 '17 at 11:51
12,8,28,"Encryption and signing are orthogonal. Both may have value, but they solve different problems and do so separately.",Sep 2 '17 at 23:10
12,8,58,"Both are very hard if you don't use some crypto library properly, and easy if you do. If you do one, doing the other adds very little effort. And both solve the same problem: Helping to keep the hardware safe.",Sep 2 '17 at 23:43
12,8,59,"What you are missing is that the encryption in the anecdote you mention is only even relevant because the code is encrypted everywhere but inside the trusted execution unit.  For an ordinary processor, even if the update is encrypted in flight or in storage, it will have to be decrypted by something stored on the device to execute.  It's fairly hard to make it so that someone in possession of the a copy of the hardware can't get at the decrypted code, and only in the unusual situations where that is done effectively does encrypting the update in flight matter.",Sep 3 '17 at 19:28
12,8,60,"@gnasher729 Actually, the longer to first hack, the worse. Three years later, it's much harder to fix the bug -- the manufacturer may not even still be around and who knows if they still have the tooling. And three years later, the device might be forgotten about and unmaintained. Three years later, there will be more devices in the field.The sooner flaws are found, the sooner (and more likely) that they're fixed. (And how do you know that one really bad guy didn't know about the flaw and had three extra years to exploit it?)",Sep 4 '17 at 4:23
