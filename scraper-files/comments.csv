Post ID,Answer ID,User ID,Comment,Date
1,2,1,"Right, staying offline prevents a lot of problems. How about being on an intranet with other devices that do connect to the internet? For example, how much more vulnerable is an IoT system if it has a raspberry pi as part of its internal network, which in turn is connecting to an internet connected smart phone via bluetooth?",Feb 3 at 3:58
1,2,2,"@cr0, ""device hopping"" is a real concern.  But consider, the bad actor would have to get through internet, bluetooth, and then exploit the RPi and finally exploit the IoT device.  This isn't any different than issues faced by non-IoT intranet devices.",Feb 5 at 19:48
1,5,5,"P.S. I know that that's not how ""Build a better mousetrap"" is usually used.",Feb 5 at 20:36
1,5,1,"This is helpful about physical security - all good things to consider. In my case I'm somewhat new to the area so I don't know risks first hand. Neighbors report theft in the area due to local teenagers. I see teenagers hanging out in the neighborhood but haven't had problems yet. As you said, it's about making targets ""not worth it"" to potential attackers",Feb 6 at 16:36
2,1,6,"Recently, one such doll was found to be so insecure that it was classified as ""hidden espionage device"" in Germany (and banned), see e.g. discussion over at IoT iot.stackexchange.com/questions/1074/… (one of the two referred to in the 3rd paragraph of the #toyfail quote)",Oct 31 '17 at 19:52
2,1,7,"...and if you absolutely must have them, do the sane thing and at the very least segregate them on a network segment all of their own, ideally with no access (beyond that of any untrusted device on the big bad Internet) to anything else. At least that way, if something happens, you are limiting the potential damage somewhat.",Oct 31 '17 at 19:52
2,1,8,"@Michael Kjörling, no, just NO. Anders just explained that this ""doll"" is a spy device, that needs to have access to the internet to work. Your privacy seems to be the last thing on the doll makers list to take into account. The sane thing here is to not have one!",Nov 2 '17 at 8:18
2,1,7,"@Flummox Why do you think I started out my comment the way I did, including the formatting? I agree with this answer, and there's no way I'd buy one myself (for this and for other reasons as well), but if and only if someone has a genuine need for something like this, then there still are steps that can be taken to mitigate the risks a little bit. In such a situation, not at least doing that would be the height of irresponsibility, both toward yourself, others in your household, and others on the Internet.",Nov 2 '17 at 8:26
2,2,7,"Also, keeping in mind the distinction about what a remote attacker is trying to access. Assuming you aren't a high-profile target (and if you are, you probably know better than to trust random strangers on the Internet for security advice), it's fairly unlikely that a remote attacker who gains access to an IoT device (even one that can remotely be turned into an active microphone and speaker, or camera, in your home) is particularly interested in you specifically. It's all the more likely that they are interested in the device itself, e.g. for its computational power or network connectivity.",Oct 31 '17 at 20:16
2,2,7,"In response to your edit, in fairness, I wasn't necessarily thinking of using the device as an attack bot, though that's an obvious thing that could happen (think Mirai and the DNS overload attack against Twitter and friends recently, for one). Think also e.g. bitcoin mining, or sending spam e-mails. Sure, a toy like the one exemplified in the question probably doesn't have enough computational power to make a major difference, but if the cost to the attacker is next to zero, it doesn't need to do much in order to turn a profit, especially if you've got thousands of them working for you...",Oct 31 '17 at 20:21
2,2,10,"There was a recent documentary (BBC if memory serves me correctly) showing the story of an elderly woman who answered the phone to a scammer and was convinced to transfer them a large sum of money. Key to the scam was their use of the camera and microphone on her laptop during the call. If such a device as this ""toy"" is easier to break into than a (presumably) windows machine, then this becomes just one example where an exploit of this type increases the risk surface area",Nov 2 '17 at 4:47
2,3,12,"Never mind the threats to National Security. If every conversation in a large enough sample of homes is recorded and digitised, it does not really bear thinking about that data being used in future prosecutions for crimes against the state. If it is being sent upstream for AI language learning (sold to Google or AWS, say) there may be some value in preserving languages that die out in future?",Nov 1 '17 at 3:21
3,2,19,"Even better - provide a (large) prize for security vulnerabilities, with more severe vulnerabilities (measured in maximum damage they can cause) earning a larger prize. This will hopefully convince some wannabe crackers to disclose the details (certain prize) as opposed to trying to exploit them (uncertain, possibly greater but probably smaller prize, plus risk of being caught).",Sep 1 '17 at 20:53
3,2,20,I would even encourage to make the firmware free software or open source.,Sep 2 '17 at 7:06
3,2,21,"@wizzwizz4 Many businesses do not have the capital to operate a fully-fledged bug bounty program, particularly SMEs and self-funded startups. In general I've seen these businesses offer alternative recompense, such as free or heavily discounted products, t-shirts, swag, etc. depending on the nature of the business and brand. Bug bounties do not necessarily need to be formal and costly.",Sep 2 '17 at 10:53
3,2,19,"@Polynomial Many businesses don't have the capital to not operate a bug bounty program. If a large breach is found, surely it's worth that $x for it not to be found when your clients are suing you for damages caused by a breach.",Sep 2 '17 at 11:33
3,2,21,"@wizzwizz4 I doubt that the lack of a bug bounty program would ever be the confounding factor in a breach. Bounties are great, but they're an optional layer in almost any business' defence budget, perhaps with the exception of highly public organisations. If the goal is to avoid a breach, the cost and time involved with running a BBP can be better invested in more direct defence measures such as staff training and improving blue team capabilities. BBPs are great if you've already got everything else covered and have spare budget, or if the perception of security markets well in your vertical.",Sep 2 '17 at 12:20
3,3,21,"Open source may be a step too far for a commercial product, and the ""many eyes"" principle is generally flawed (see: the state of OpenSSL before Heartbleed). That said, if the project uses any GPL licensed code without special agreement from the author then the full source must be made available anyway.",Sep 1 '17 at 14:30
3,3,7,@Polynomial If the project uses any GPL licensed code then the parts that directly touch the GPL code must be made available as source code. Not all of it. Mere aggregation still applies.,Sep 2 '17 at 23:05
3,3,22,"I can see how that might be an issue with fully Open Source. Also, it usually comes down to semantics when it comes to Open Sourcing on GPL code. I'll look into the OpenSSL matter as well, thanks for that!",Sep 4 '17 at 5:24
3,3,23,"I really think a good answer should address the issue of ""if my software has to be proprietary, is it worth encrypting/obfuscating"".  There may be plenty of reasons to keep software proprietary that have nothing to do with security (contracts with customers, red tape by management, valuable algorithms).   I also believe that publishing your source code isn't a good way to fix up an insecure software development process and shouldn't be overemphasized by dedicating the entire answer to it.",Sep 6 '17 at 21:36
3,5,19,You could always make it illegal to distribute the decryption key! Making numbers illegal definitely works...,Sep 2 '17 at 11:51
3,8,7,"Encryption and signing are orthogonal. Both may have value, but they solve different problems and do so separately.",Sep 2 '17 at 23:10
3,8,28,"Both are very hard if you don't use some crypto library properly, and easy if you do. If you do one, doing the other adds very little effort. And both solve the same problem: Helping to keep the hardware safe.",Sep 2 '17 at 23:43
3,8,29,"What you are missing is that the encryption in the anecdote you mention is only even relevant because the code is encrypted everywhere but inside the trusted execution unit.  For an ordinary processor, even if the update is encrypted in flight or in storage, it will have to be decrypted by something stored on the device to execute.  It's fairly hard to make it so that someone in possession of the a copy of the hardware can't get at the decrypted code, and only in the unusual situations where that is done effectively does encrypting the update in flight matter.",Sep 3 '17 at 19:28
3,8,30,"@gnasher729 Actually, the longer to first hack, the worse. Three years later, it's much harder to fix the bug -- the manufacturer may not even still be around and who knows if they still have the tooling. And three years later, the device might be forgotten about and unmaintained. Three years later, there will be more devices in the field.The sooner flaws are found, the sooner (and more likely) that they're fixed. (And how do you know that one really bad guy didn't know about the flaw and had three extra years to exploit it?)",Sep 4 '17 at 4:23
4,1,32,"(+1) If ISPs implemented NIF (tools.ietf.org/html/bcp38), that would help.  Although, I'm not sure whether playing wack-a-mole with IPv6 is really feasible unless you are considering ""hard coding"" IPs into devices like MAC addresses.  Otherwise, you are back to, get your IP blocked, get new one, and be back in business.",Oct 26 '16 at 19:38
4,1,33,"@Shackledtodesk I have to agree - I just think at least being able to uniquely, if only temporarily, ID the actual devices has to be a step forward.",Oct 26 '16 at 19:40
4,1,34,@Shackledtodesk are we assuming that IPv6 hard-coded addresses won't be spoofed the way MAC are right now?,Oct 26 '16 at 19:44
4,1,32,"@Mindwin, you make a perfectly valid point about spoofing.",Oct 26 '16 at 19:55
4,1,34,"I once heard a joke about IPv6 in the university, I can't recall it fully, but it ends with ""Fine, I'll just use my lightbulb's [IPv6] address instead."" @Shackledtodesk =) - heck, even iphone's IMEI are being spoofed now.",Oct 26 '16 at 20:01
5,2,33,"A lot of the time, that root password is in the firmware / boot image and cannot be changed without reflashing, unfortunately.  Still worth a try - but if you do try it, make sure you fully power cycle the camera to see if it stays (ie, unplug for 30 seconds to ensure the memory is cleared, plug in again, see what root password it is using)",Oct 25 '16 at 15:18
5,2,40,@crovers edited ;),Oct 25 '16 at 15:19
5,2,41,"I tried changing the password, but it resets at reboot",Oct 26 '16 at 7:21
5,2,40,It's probably embedded in the firmware then. You'll need to use the other mitigating controls to reduce the risk of compromise.,Oct 26 '16 at 12:18
6,1,43,Note that with IPv6 the devices would be accessible by default without even needing UPnP nor opening ports (most consumer-grade routers don't firewall IPv6 from what I've seen).,Oct 25 '16 at 3:58
6,1,44,@AndréBorie It is probably not a good idea for routers to have no firewall by default. I think a large number of consumers have a (possibly unjustified) expectation that the router will protect all the insecure devices on the LAN. And I think those who really don't need the firewall will know how to access the configuration and change the firewall setting.,Oct 25 '16 at 7:22
6,1,45,"@AndréBorie On some level, that expectation is a hangover from IPv4 and NAT, where two devices couldn't communicate unless ports are explicitly opened on routers. It seems likely that as IPv6 adoption increases, and brings universal addressability, a lot of vunerabilities will emerge in software that opens TCP ports and trusts the data received on them.",Oct 25 '16 at 11:20
6,1,46,"@AndréBorie, most consumer-grade routers that support IPv6, e.g. Linksys, do firewall IPv6, but they don't NAT IPv6. Those are two very different things.",Oct 25 '16 at 18:44
6,1,47,"@AndréBorie I've never seen a consumer grade router that didn't firewall IPv6, though I'm sure one must exist. Of course, then you have the additional problem of figuring out the IPv6 address...",Oct 25 '16 at 19:51
6,2,49,"I think OP is interested in knowing how SSH/Telnet would be accessible when the device is connected to a private home network, which would normally have an inbound NAT firewall.",Oct 25 '16 at 3:11
6,2,30,"That is a common misunderstanding. They typically have NAT devices that have firewall capabilities that vary from minimal to none at all. Where there are firewall capabilities, they are almost never enabled.",Oct 25 '16 at 18:44
6,2,46,"@tlng05, don't confuse NAT, a kludge to extend IPv4 addressing, with firewalls. You can have a very secure firewall that doesn't have NAT enabled, and you can NAT on a device without having a firewall. The firewall/router combination is just a convenient place to NAT, but it is not a firewall.",Oct 25 '16 at 18:46
6,2,50,"@RonMaupin Still, if it's behind NAT, how would a telnet request on port 23 ever reach the IoT device? How would the router know to forward to the camera? I've heard stuff about UPnP on here, but why in the hell would the manufacturer forward port 23 through UPnP? Doesn't make sense!",Dec 4 '16 at 22:48
6,2,46,"@RenéG, a firewall protects your network, not NAT. If you have no firewall features, it is possible to take over the router by its public address, Then NAT does nothing for you because the router knows how to get to the internal network. Also, if a different port is open, it is possible under some circumstances to get through NAT to take over an inside host, then all bets are off. NAT doesn't really provide security, firewalls do.",Dec 4 '16 at 22:53
6,3,52,"Its accesible from the wider Internet, there you are correct. I won't say that is wide open. I think for over 20 years the basic routers are closed on the common ports. You cannot connect over port 22 to each ip-adres of something like that. But as stated above. UPnP removes this security big time. Never enable that, that makes your router insecure",Oct 25 '16 at 9:35
6,3,30,"@AdamSitemap The only security UPnP removes is accidental security. If a port is filtered by a firewall, enabling UPnP won't unfilter it. If a port is not filtered by a firewall, any security is accidental and unreliable.",Oct 25 '16 at 18:45
6,4,54,"I think this adds a valuable point: my understanding is that a lot of these crappy IoT devices that have been compromised have actually been placed outside any firewall perimeter a user might have, directly connected to the Internet. (But then, of course, in addition you do have port-forwarding and UPnP scenarios where a device is inside the router/firewall but still vulnerable.)",Oct 25 '16 at 15:04
6,4,30,"@halfinformed Most likely, there is no real firewall to speak of, just a router whose job is to make things ""just work"", not provide protection.",Oct 26 '16 at 17:26
6,4,55,"@halfinformed Yes this is the case but only sometimes, mostly as David said there are no firewalls and routers don't do anything.",Oct 28 '16 at 5:13
6,4,54,"By ""firewall"" I mean even any lousy SOHO router or ISP distributed router with some basic firewall-like functionality. (Meaning basically any device that doesn't just let arbitrary inbound  packets from the Internet through to a user's internal network.) I certainly did not mean to imply that ordinary users are typically utilizing discrete firewall devices.",Oct 29 '16 at 18:53
6,5,56,"But there's no indication that's what's happening. The vuln is in the devices and the crappy upnp-enabled routers, not the vendor's central servers. If it were the latter it would be easy to fix.",Oct 25 '16 at 16:29
6,5,57,There have definitely been hacks into devices through vendor websites.,Oct 25 '16 at 16:54
6,5,48,"The MIRAI botnet and malware is not hacking the vendors' servers or website.  It is directly connecting to the end-users' webcams and other IoT devices by connecting to well-known ports that the devices have exposed using UPnP, then testing a set of 66 different default credentials on those ports.  Yes, someone could theoretically attack the vendor's site, but that hasn't been true for any of the recent massive DDoS attacks.",Oct 25 '16 at 21:40
6,5,57,"The OP's question didn't specifically name the MIRAI botnet (the body of the question did allude to it). The heading is: ""Does the local network need to be hacked first for IoT devices to be accesible?"" Based on that heading, the answer is no, the attacker doesn't even always have to make any effort to breach your router at all. If they can get away with social engineering the IoT device vendor's company, they can get into all of the devices at once since, often, all those devices already made outgoing persistent connections to the IoT vendor. There's more than one IoT threat vector.",Oct 26 '16 at 0:29
6,8,59,"In other words, similar in principle to a DNS reflection attack.",Jan 23 '17 at 4:11
6,8,60,"Yes, in the sense that these IoT devices can be used to perform the DDoS reflection attack on an unsuspecting 3rd party. There are other significant security issues with many IoT devices simply because manufacturers have not designed security into their systems. However, using them to perform DDoS reflection attacks is one of the highest concerns as it provides the potential to impact on large numbers of unsuspecting victims. The other security issues associated with IoT tend to only affect the individual/site running them,so less potential impact.",Jan 24 '17 at 9:33
6,8,48,"@TimX, you said ""In many cases, the devices have not been hacked at all - they are performing as designed."" Except an IoT network is generally kept behind a firewall, where network security has to be penetrated first.  Sure, you could possibly send my IoT devices into an amplification attack against each other that would make my house unhappy, but my traffic won't impact your house. That would require my devices to violate your firewall to get your devices to attack each other. Propagating the attack takes hacking the devices. Mirai hacked the devices, they were not ""performing as designed"".",Feb 7 '17 at 15:26
6,8,60,"One small problem with your assumption about firewalls - IPv6. Vary few of the modems sold in the domestic market support firewalls for IPv6, yet the majority of them now support IPv6 and an increasing number of ISPs now enable IPv6 by default.  The other problem is that many of these IoT devices are designed to allow external connections - either requiring port forwarding or using something awful like uPnP. Combine this with the high use of IoT in domestic and small office situations where IT skills are often low and you have a problem. Relying on the firewall is really just 'candy' security",Feb 8 '17 at 18:34
6,10,48,"Hi @Culme, the issue here is that the devices are visible to the internet, where economies of scale mean that dozens of hacked devices can be set upon thousands of other devices, which can then hack millions.  An insecure 433MHz RF connection can be exploited only by an attacker physically located within signal range of your house. And hacking your single IoT device doesn't grant him the ability to hack thousands of other RF devices, unless he drives to a thousand other homes.  The internet-facing vulnerabilities are the ones that lead to Mirai, not the RF facing ones.",Feb 7 '17 at 15:13
7,1,64,"Well, that kinda answers your question, doesn't it? I'd still collect all the info you have on your use cases and get in touch with Azure directly. They know what they allow users to do. (Also since the link to the Penetration testing overview page is dead...)",Aug 21 at 14:21
7,1,65,"This sounds good, one thing that might be worth checking if you do use Azure, is whether they filter any types of outbound traffic.  If you're trying to do something like 65K port scans or something more esoteric like SCTP scanning, you may find that traffic gets blocked :)",Aug 23 at 7:57
7,1,66,@jpmc26: thanks. I've fixed it.,Apr 26 '17 at 11:04
7,2,7,"If you are using stolen credit cards to pay for the VMs, aren't you flushing someone else's money down the drain?",Apr 25 '17 at 12:42
7,2,67,"I suspect Tor would not be very useful for DDoS attacks. Your traffic would first have to traverse a number of machines inside the Tor network, and then emerge at exit points. Effectively, you would be using Tor as a command-and-control system, and the exit nodes as the source of your DDoS traffic. This would probably be less effective than using a ""traditional"" malware-based botnet. You could probably craft an attack to DoS Tor itself, though.",Apr 25 '17 at 15:12
7,2,68,"@MichaelKjörling It still becomes someone else's someone else's money though, instead of remaining your someone else's money.",Apr 25 '17 at 17:26
7,2,69,"With a properly done attack, Tor could be rather productive.  You just need a magnification/reflection attack.  Take an old-school ICMP magnification: you send a few bytes over Tor to a vulnerable host claiming to be from the final target, they send a few hundred kB to the target.  You can use Tor to shotgun out to your amplifiers, which basically hides you behind 2 layers of obscurity from the target (vulnerable amplifiers, Tor, then you).  That also obscures Tor as being part of the attacker's vector (victim only sees packets from amplifiers who aren't greatly affected so don't report)",Apr 26 '17 at 13:03
7,2,69,"I might add, that is why good routers and firewalls are so picky about well formed ICMP packets, and why this isn't nearly as common an attack vector as it once was (also why I don't mind explaining it).  The first D in DDoS is for distributed, and while you got that from the attacker's perspective (multiple cloud instances to lay in the attack) you forgot that it isn't cost effective for an attacker to own the DDoS hosts, only the instigators.  So they can distribute the instigators in the cloud with Tor help, but the actual attackers are still gonna be vulnerable internet connected systems.",Apr 26 '17 at 13:06
7,3,71,"It's worth noting that Mirai isn't the first botnet used for ""DoS-as-a-Service"". Criminals use this monetization model for their botnets for years. The only new thing about Mirai is that it focuses on infecting IoT devices.",Jul 11 '17 at 16:12
7,4,71,Unfortunately there is also a flourishing black market for stolen credit cards and compromised online banking accounts which criminals can use to pay for cloud services anonymously.,Jul 11 '17 at 16:14
8,2,26,"I think this is an interesting comment, but I don't see that it would work for AWS.  AWS runs on virtual machines, so it seems to me that anyone with access to the host machine could simply find the key in the register.",May 4 '16 at 14:45
8,2,75,This comes close to a software-only solution. Its still not clear to me if this really works. I'm reading the references. Possibly it could be bootstrapped using a hardware module to ensure that RamCrypt has been booted securely.,May 4 '16 at 15:31
8,2,76,"You're right, it wouldn't work on AWS, since virtual machines trap access to hardware debug registers and emulate it. This is more about generally keeping secrets safe in memory. This is not possible on a virtual machine unless it is designed with this in mind (e.g. by isolating individual VMs with SGX).",Dec 1 '17 at 5:44
8,3,75,Not a random key but one entered by a human during run-time.,May 3 '16 at 7:47
8,3,77,"Usually humans enter passwords, not keys (although some key management routines may require direct entry of hexadecimals representing bytes of a key). Never confuse passwords and keys.",May 3 '16 at 8:05
8,3,75,"If you mean passwords to be alphanumeric, then I don't technically distinguish between a key and a strong password. A Base64 encoded 256 bit random key is also a password under this definition.",May 4 '16 at 3:38
8,3,75,"(maybe with some special security module that contains your program code) -- This might seem to work. However, isn't it 'turtles all the way down'? Because then we need to control the code that uses the program that uses the key.",May 6 '16 at 17:30
8,4,75,"Note that there is a subtle difference. In the DRM case, the device/application is bootstrapped in a compromised state. In my case, I can guarantee that my application (say, a custom made media player) was bootstrapped in a secure state when the key was supplied. Later at some point, the system is compromised. This is a weaker requirement than the pure DRM case.",May 4 '16 at 3:35
8,4,79,"@jus12 ""In the DRM case, the device/application is bootstrapped in a compromised state."" - not with secure boot!",May 4 '16 at 5:24
8,4,21,@Jus12 I don't believe that you can bootstrap to any safe state when the underlying hardware is controlled by a potentially malicious party.,May 4 '16 at 12:21
8,4,75,"@Polynomial That is one of the assumptions I am making. The underlying hardware was in a trusted state at the time when the key was supplied. It may later become compromised. I feel there is a difference in the attacker capabilities in these two cases, even though they appear to be similar.",May 4 '16 at 15:33
8,5,75,"Yes, for my application, the key is used consistently. If this can be done via HSM, this would solve the problem. How can we prevent the attacker from using the key inside the HSM?",May 4 '16 at 3:31
8,5,26,"@Jus12 I don't know that you can.  While the key is in use, it's in memory.  If it's in memory, it's at risk.  Think of the HSM as a safe.  If the secret is outside of the safe, it's not protected.  When it's ONLY in the safe, it's protected, but you still need to store the combination somewhere.  If the combination is in memory, you haven't really accomplished anything but misdirection.",May 4 '16 at 14:37
9,1,80,"Also there may occur a ""programming error"" causing all deletion commands to be ""ineffective"" and thus preserving all your data there. Happens. ;-)",Jul 7 '14 at 8:26
9,1,81,"Per Google's File deletion and recovery policy, ""you can contact us to help recover a deleted file or folder for a limited time"". The exact duration that the files are kept around to be recovered is not specified. According to the policy, recovery is only possible for consumer accounts; deleted files from enterprise accounts cannot be recovered.",Jul 7 '14 at 16:12
9,1,82,"It's known from recent leaks that NSA has been influencing and pushing weak cryptography standards through their relationship with NIST. Their MOU states NIST must consult with NSA on standards. It does not make sense that NSA would recommend algorithms they cannot break as it would be counter-productive to their mass surveillance mission. Thus if you use Suite B algorithms then you are likely not protected against the NSA. Public cryptographers have discovered a few weaknesses, but do not have the cryptanalytic capabilities of NSA.",Jul 7 '14 at 21:41
9,1,3,"@NDF1, quantum computers are only exceptionally fast at breaking RSA and factoring-related cyphers (Shor's algorithm).  Symmetric cyphers such as AES are not vulnerable, and ECC is not vulnerable.",Jul 7 '14 at 22:22
9,1,83,I would also note that it's not a requirement for the agency name to consist of three laters. Vide GCHQ.,Jul 9 '14 at 11:07
9,2,84,i thought Truecrypt has a security issue?,Jul 7 '14 at 12:28
9,2,85,The y do not have security issues. At least none that are publicly disclosed :-): The problem with TC is the fact that support is dropped by the two russian developers. They ended the development of TC in May 2014. TrueCrypt is now in the process of being evaluated by several crypto analysis teams. Phase 1 of the audit did not found any errors in the implementation. It's now in phase 2. You can track the progress here: istruecryptauditedyet.com  Security issues will arise if these audits detect flaws. Unless some development team picks up on the code and starts further development.,Jul 7 '14 at 13:21
9,2,85,In other words: TC is now not more or less secure than before the team decided to quit.,Jul 7 '14 at 13:25
9,2,86,Why does copying the file out of the container and then moving it back in add additional security? What is the concern? That they'll be able to see incremental changes?,Jul 7 '14 at 19:53
9,2,86,"Oh, perhaps I don't understand how TrueCrypt works on other platforms. On Linux, it mounts the encrypted drive as a filesystem, which means that all reads/writes are decrypted/encrypted directly to the container file, therefore there'd be nothing to do at all.",Jul 7 '14 at 23:46
9,4,88,"thank you for your recommendations. Honestly, I am looking for alternatives with similar functionality (e.g. automatic sync on mac, pc, android, + web browser ui) Can you recommend something like that?",Jul 8 '14 at 17:05
9,4,89,@gen: You might be interested in Software Recommendations.,Jul 9 '14 at 16:37
9,4,88,"@unor wow thanks, stack exchange is so good :)",Jul 9 '14 at 20:59
9,4,88,@unor; just posted a question there: softwarerecs.stackexchange.com/questions/7677/…,Jul 9 '14 at 21:16
9,5,91,"@to whoever downvoted, there's a lot of answers suggesting that encryption is the silver bullet on how to securely keep data in the cloud, its not - if you don't want your data to be accessible at some point in the future you will not upload it and one answer needed to say it",Jul 7 '14 at 18:39
9,5,92,"Encryption IS a secure method. BUT the question is: secure against what threat? No measure is ever a silver bullet, and in that way, there is no 'secure' method to do anything. It is always a question of the nature of the threat you are needing to secure against.",Jul 7 '14 at 19:44
9,5,91,"@schroeder, I agree, that's just misleading semantics when discussed in this context. For example: plain text is secure against a decent individual and pre-heartbleed OpenSSL communication was secure against people who didn't exploit heartbleed. Today's communication and data storage is also ""secure"" when you use ""industry accepted standards"", but same would have been said about OpenSSL traffic before heartbleed was announced. If your life depended on it in the long run, you would not trust what we today call ""secure"" communication.",Jul 7 '14 at 21:30
9,5,93,One cryptographic algorithm will be broken tomorrow. Just compute which one and avoid it :).,Jul 7 '14 at 21:53
9,7,88,"I have already considered numerous alternatives, but haven't find any suitable yet. By suitable I mean, trustworthy. I have plenty of problems with Tresorit:  ""You agree that Tresorit may also transmit any data stored by You to a third party if Tresorit has a reason to believe that it is required..."" that sounds pretty strange given their Zero Knoledge Policy.  Another problem with them: ""we might use trusted third parties, like Microsoft, to provide the Service."" Microsoft trusted party? :/ Those are some of my concerns with Tresorit. (These quotes are from Tresorit Eulas, etc)",Jul 8 '14 at 19:36
9,7,94,"What I do as a rule of thumb is use AxCrypt to first crypt the sensitive files on my local hard drive, and then I upload them to Dropbox (or Google Drive or whatever). This gets you as close as you're gonna get to ""true"" data privacy in the cloud. It doesn't matter whether Google keeps your files or not, because from a practical perspective nobody can decrypt them except you. notice I say from a ""practical"" perspective. Theoretically maybe someone can break your encryption, but when you consider all the variables involved, it's just not gonna happen.",Jul 9 '14 at 18:24
10,1,97,could you explain how DDoS mitigation on encrypted traffic works - doesn't it all just look like rubbish?,Nov 13 '13 at 17:03
10,1,98,"Traffic flow patterns, as I mentioned in the answer. Not content, which all looks like rubbish, as you say.",Nov 13 '13 at 19:38
10,1,97,"Thanks about the info, I think I have to read up on flow patterns :)",Nov 14 '13 at 9:50
10,3,97,Why should a provider have the SSL key if I use their appliance in my network? Assuming the appliance doesn't secretly phone home of course.,Nov 13 '13 at 13:33
10,3,101,"As you say @mohrphium, it could phone home. Given recent news it wouldn't surprise me if companies were collecting that data. They could encapsulate it in messages requesting software updates and you'd never know as it's all closed source.",Nov 13 '13 at 16:01
10,3,97,good point... thanks for the input :),Nov 13 '13 at 17:03
10,3,97,"Unfortunately I can't choose both your answers as ""the answer"". Thanks for your answer, especially the point of modifying configurations since I kinda tended to ""outsource and don't think about it anymore"". But of course we still have to take a look at our own configs.",Nov 14 '13 at 9:53
11,2,105,"No, AWS gives you a full paravirtualized server, for free for one year even. It's behind a NAT though...",Feb 12 '13 at 17:25
11,2,106,"@EricDong Thanks. Yeah, that won't work at all for port scanning, edited.",Feb 12 '13 at 17:28
11,2,107,"Yes, it's behind a NAT, but it's a 1:1 NAT. Should work just fine.",Feb 12 '13 at 17:38
12,1,111,"In this case you can't even run an offline search. You need to query google's servers that often, which makes is even more ridiculous.",Jan 21 '13 at 21:16
12,1,112,@CodesInChaos as if building a Dyson sphere around the sun to power an ideal computer sitting in deep space isn't ridiculous enough...,Jan 21 '13 at 21:21
12,1,113,"So a rubber hose is much more likely. I guess if I see someone building a Dyson sphere around the sun it's probably too late to worry about the guys with the rubber hose, though.",Jan 21 '13 at 21:52
12,1,114,"While I like your math, let me point out that you're overlooking the fact that the keyspace probably isn't a full 263 bits wide.  Whatever generator they use probably has at least a few rules to limit out stuff like a key of 11111...111; also, while brute-forcing a single, specific document is expensive, what you have to deal with is the possibility -- still remote -- of them randomly querying that link.  (This is of course nitpicking; your point is completely valid)",Jan 28 '13 at 5:48
12,1,112,"@RonLugge The effect of such rules may affect the numbers to several orders of magnitude, but it wouldn't affect the outcome. As for accidental stumbles; say each person on earth had 1 million documents on GA. That's what, 2^53 documents? So let's be generously inaccurate with our math and say that any guess has a 1 in 2^200 chance of accidentally stumbling on a real document. So if all he computers in the world do nothing but enumerate document links for the rest of eternity, the chances of a single hit are still indistinguishable from zero.",Jan 28 '13 at 6:25
12,2,115,And not forgetting the link hanging around in someone's browser history,Jan 21 '13 at 18:16
12,2,111,"Using a secret url is not security through obscurity if the url has sufficient entropy (And this one has around 256 bits). It's a viable form of authentication, even if there are certain associated risks.",Jan 21 '13 at 19:39
12,2,116,"It's not a valid form of authentication because the risk of someone leaking the url is higher than leaking their own credentials to log into the application. Authentication also requires proof of identity, while this does not provide that.",Jan 21 '13 at 20:24
12,2,116,"Plus I clearly stated that the guessing speed is very improbable, so please elaborate on why you insist to downvote my answer.",Jan 21 '13 at 20:27
12,1,118,"GiT has a great lab, I remember reading a lot of articles on it when it came out: Here is a whitepaper on it (unknown date, sorry. Also, PDF Warning): csc.gatech.edu/~copeland/6612/netseclab/… csc.gatech.edu/netseclab.html Description of lab and their methodology for grading",Jan 3 '13 at 17:06
12,1,119,If you are planning to go with vSphere and build the machine from scratch check the hardware compatability guide before you start.,Jan 4 '13 at 12:27
12,2,120,"Thanks Cristian, I think we can use the hackademic project for web pentest lab since it only require a server and LAMP or WAMP. if you have more information regarding what we are looking for that will be great.",Jan 4 '13 at 4:27
12,3,120,"The cloud service you mentioned is an interesting option that we might look into. Thank you and if there is more information from your source, do share. Thanks",Jan 4 '13 at 4:13
12,3,122,"A hosted service like Amazon would likely not serve your needs. When we looked into setting this same type of environment with them for use by our students, they informed us that the type of activities students would have to perform against the amazon network (portscans, network exploits, etc.) would violate their terms of service and they would probably have to shut us down. Keep that in mind as you make a selection. You may have to build something in house.",Jan 5 '13 at 3:45
12,3,120,"Thanks for the heads up queso, most probably some organization would agree and some won't. we would appreciate if you can share with us how did your institution setup the environment?",Jan 6 '13 at 10:51
12,4,120,"I am familiar with that site and its actually very good but we want to have control of the environment to add or edit the labs. Thanks, if you found more information for what we are looking for do share.",Jan 4 '13 at 4:31
12,4,11,"@KenAdams - the trick then is that you have to emulate a hack as opposed to actually doing it.  You could give each student their own instance, but assuming you want to be able to grade it, you need a way to report success or failure of the attempts.  A simple thing that one of my professors in college did was a binary bomb application that had various techniques for protecting a program and the goal of the students was to get the password out of it.  Incorrect attempts would trigger a notification to the teacher unless you intercepted the instructions and broke out of them.",Jan 4 '13 at 6:14
12,4,11,Not really sure exactly how they went about making it though.,Jan 4 '13 at 6:16
12,4,120,"Good point AJ, I agree it is a very important key to record or log the success of the student he/she pass a certain challenge. It would be very useful for practical quiz or challenge between students.",Jan 4 '13 at 7:19
12,5,120,"I have gone across NetWARS before but I was not sure, whether it function according to what we want. Thanks",Jan 4 '13 at 6:52
13,1,125,"Thanks for sharing that best-practice. It was hard to decide who gave the ""right answer"" regarding the original question - you or Thomas Pornin. I decided to give the tick to you, since your advice explains a practical workaround for the problem Thomas pointed out. For anyone who finds this post: Alexander's advice is to read and store encrypted data in the cloud but having the key to decrypt that data somewhere else.  As Alexander stated: That limits the abilities of such a solution in trade for increased security.  Thanks Alexander!",Oct 7 '12 at 9:10
13,2,21,Immutable Law of Security #6 - A computer is only as secure as the administrator is trustworthy.,Oct 6 '12 at 13:25
13,2,125,Are you saying that an encrypted disk (in the VM) would  have no effect on what the Host sees?  I thought this would make it at least a bit harder for an attacker to steal data.,Oct 6 '12 at 13:35
13,2,127,"@Emi If the guest can access the data, the host can access the data. For instance, a symmetric encryption key that allows the guest to decipher or encrypt blocks of data, must be held somewhere in the guest machines's memory for it to be of use. Since the guest's memory is really the underlying host's memory, the host can readily access the area containing the guest's key.  Now the attacker on the host has a copy of the key and can go on to read or modify the data as he pleases.",Jul 19 '16 at 8:36
13,4,125,"Well, the contract is just one side. When those paragraphs come into action, it is already to late, since the attack was successful. Are there any techniques to reduce the mentioned risk in any way?",Oct 6 '12 at 13:39
14,1,133,"Protect your encryption keys from both disclosure and loss. E.g., if your house burns down (floods, gets robbed, etc.), and takes your encryption keys with it, your backups are worthless.",Oct 9 '12 at 18:30
14,2,134,Thank you for this. It would also be nice to see what exactly can each of them do with your data.,Apr 7 '14 at 8:23
14,3,136,Illustrative way to highlight the differences between Public/Personal/Private.,Sep 26 '12 at 10:54
14,3,137,@OnTheShelf Would you provide a citation for SkyDrive running on Windows Azure?  I’ve been unable to find such reports.  Thanks.,Aug 24 '13 at 13:55
14,3,138,"@JCChu Azure is really a brand name for wide range of services, including very simple REST API access to MSFT global data centers, regionally or geo-redundant data (blob) storage, queues, identity and notification services, and a range of Windows Server hosting options (including much of the “fabric” which underlies Azure that is running on Windows Servers). It is not clear if you are looking to see the Azure brand name tied to SkyDrive, or have some concern that it may be less reliable because of some quantifiable difference. For example, while some SkyDrive data racks may be hosted in a MSFT",Aug 29 '13 at 19:16
14,3,138,"data center which pre-dates the Azure brand (for example the Bellevue DC’s which Bing, Windows Live and MSN used), MSFT Global Foundation Services (GFS) still runs them as they do Azure branded DCs. It is really a brand migration issue. Likewise Office365 is a separate brand, but the identity service it provides it is really Azure Active Directory, as SkyDrive Pro is really SharePoint Online.",Aug 29 '13 at 19:16
14,3,138,"Have you looked at their various SLA (service level agreements) to see if your concern is addressed? If it helps, SkyDrive (or whatever it is renamed to) is tightly integrated into Windows 8.1, so MSFT is HIGHLY MOTIVATED to ensure there is no data loss which might tarnish the global Windows brand.",Aug 29 '13 at 19:16
14,5,140,"The main players like SkyDrive, DropBox, Google Drive, don't encrypt in the cloud anyway. They only encrypt the transmission between cloud and client. They also are at liberty to scan contents, which is why there have been cases of individuals having content deleted because they break rules (copyright or in some way illegal).",Dec 14 '12 at 13:45
14,5,141,"Actually, Dropbox do encrypt at rest. See dropbox.com/help/7/en. Google don't, and Microsoft won´t say if they do or not.",Dec 17 '12 at 12:21
14,5,140,"Is that a recent change then as many articles on cloud encryption I'd been reading when reviewing them said they didn't and they only encrypted on transfer not at rest? Interesting, your point stands of course. They have the keys! and can (and probably do) look at the content, pass onto government authorities etc. It's as good as no encryption really.",Dec 17 '12 at 12:33
14,6,138,"Truecrypt is terrific for Private information, although often overkill for Personal information. The key task is to un-mount the encrypted volume so replication to the cloud can occur. SkyDrive, DropBox, and others handle that replication of volumes-in-use differently, so confirm that your updates are being pushed to the cloud as you expect them to be. Consider converting larger volumes into many smaller truecrypt volumes to ensure less data is delayed from replication.",Apr 25 '13 at 2:00
15,1,144,Thanks for your comment. I have not decided on DropBox but I would like to use a DropBox like solution. I want to share documents with other people over the internet. But I want to use personal keys for the encryption and not rely on encryption keys provided by the solution provider. I want a little program sitting on my site for the encryption (like e-mail encryption in outlook) based on the cert of the intended recipient. Because of file size e-mail is no option to use.,Jan 2 '12 at 19:43
15,1,145,+1 for 7zip (as long as you don't forget the password...),Jun 6 '14 at 20:07
15,1,146,"7zip is NOT secure - the protocol is secure as far as I'm aware, but the 7zip program (at least on windows) often leaves your archive out in plain-text in temporary folders and forgets to delete them. The creator refuses to see this as a bug and said he won't fix it - so I'd use something else. Don't have a recommendation tho - I still use 7zip for archives cause I haven't found a replacement : /. For single text files, I use andromeda.com/people/ddyer/notepad/NotepadCrypt-technotes.html - which is way better because your decrypted file is only in memory.",Oct 8 '15 at 22:27
15,1,147,"@BT that might not a security issue depending on your setup (or threat modeling). If you are sharing a computer then yes its a problem, if you only use that computer in a bunker 1 mile below sea level, and put the encrypted file onto a USB stick then its no issue at all.",Sep 21 '17 at 9:02
15,1,146,"@daniel Well, I suppose you have a point in the context of this question. I'm coming from bitcoin land where I was pretty upset to find that my keys were dropped in plain text on my HD without me knowing about it and persisting for months. That said, I don't trust an application where the author blatantly disregards these kinds of security issues. Doesn't make me confident the rest of it is secure, even for the OP's use case .",Sep 21 '17 at 22:52
15,3,144,Thank you for your suggestion. Creating a TrueCrypt volume and sharing the volume in a dropbox like solution might do the trick. But it still requires the other people to do something that is not familiar to them. I would like to have a transparent solution (that can also be used by people who are not technical skilled) in such a way that it cannot go wrong.,Jan 2 '12 at 19:51
15,4,151,Wuala has shut down in 2015.,Oct 6 '17 at 12:24
15,6,92,Thank you for disclosing your relationship with the tool!,Apr 29 '15 at 21:55
15,7,111,"But the point of this question is sharing it securely which implies client side encryption with a key the server doesn't know. You can use s3 as a backend behind a secure file sharing system, but it isn't secure by itself.",Oct 30 '13 at 16:35
15,7,155,Built in is a client side encryption service;   docs.aws.amazon.com/AmazonS3/latest/dev/…,Oct 30 '13 at 16:42
15,7,156,So basically just run your own service. This answer doesn't really help since the OP is looking for something similar to Dropbox. Having to develop a Dropbox clone first is not really what he was looking for I think.,Oct 30 '13 at 17:38
15,9,158,"Important point, boxcryptor is closed source  security.stackexchange.com/questions/63542/…",Jul 15 '16 at 9:42
15,10,160,"Are you affiliated with the linked software in any way? If so, please disclose your affiliation.",Mar 7 '14 at 10:46
16,1,163,"you also try asking google for the Sha1/Md5 digests. it is bizarre, how easy it is to find the right password by just submitting a digest to google!",Nov 16 '11 at 23:50
16,1,164,A simple google search has worked several times for me,Apr 5 '12 at 14:30
16,2,166,You should also consider the cost of unavailability due to EC2 failure. The probability of it happening again is small but not zero.,Nov 17 '11 at 20:16
16,2,167,Running a password-cracking job for a client is something that can wait 6-18 hours for an AWS service to come back up.,Nov 18 '11 at 2:34
16,2,168,@this.josh likewise the cost of replacing parts due to failure in the DIY model,Apr 5 '12 at 8:22
16,2,169,"@this.josh I think the cost of unavailability in a password cracker is pretty limited, and unavailability on Amazon is probably lower than on a self-constructed machine.",Jan 2 '13 at 15:52
16,4,172,Rainbow tables are limited only to non-salted hashes.,Nov 22 '11 at 21:07
17,1,177,"+1 on the ""if someone hated me that much"" point.  Like Chris Rock's riff about a world in which each bullet cost $1k.",Nov 2 '11 at 13:11
17,1,178,Thought it was $5K?,Nov 17 '11 at 16:06
17,1,179,"Nobody mentioned botnets. Nobody DDOS with one ADSL 10mbps. Hackers use botnets. Biggest botnets have millions of bots. This page is top google result for ""amazon s3 ddos cost"". I also consider if it is safe to Amazon as Amazon traffic is very expensive.",Mar 19 '14 at 23:35
17,1,180,"You can issue a large attack using Google docs, without hurting your humble ADSL connection.",May 24 '14 at 22:28
17,5,185,"But won't Amazon sue on me, if my card limit will be exhausted?",Jul 5 at 22:00
17,5,186,Amazon now has lots of limits and notifications you can have happen when things get out of control. docs.aws.amazon.com/awsaccountbilling/latest/aboutv2/…,Jul 9 at 19:58
18,1,188,"Smaller volume shops still need to be compliant, they just have an easier audit and approval process.",Sep 5 '11 at 13:31
18,1,107,"True... I did mean that they still have a bar when I said ""don't have to worry about a lot."" They do have to self-review and sign off on it, but they don't have to hire an auditor.",Sep 5 '11 at 13:33
18,7,194,"Hi, it wasn't spam - at least not an intentional one. Currently the above described solution is available via only one specific provider and so I figured I can mention him (it) by name... I do see your point. So, following your comment I`ve re-edited the post and removed all brand mentions.",Jul 17 '12 at 11:28
18,7,98,Thanks Igal - it just read a lot like an advert. This is definitely better - I have added a brief disclaimer just to let the reader know.,Jul 17 '12 at 11:46
18,7,194,"Thanks again, this all thing actually prompted me to go and have a look at infosecfrog so I feel it was a ""score 1"" for me :)",Jul 17 '12 at 12:23
18,7,98,"Well, I gave you an upvote for the revised version as well :-)",Jul 17 '12 at 12:37
18,7,195,@IgalZeifman - I find it hard to believe there is a single solution available and you just happen to work for them.,Jul 17 '12 at 14:26
19,1,197,"Don't want to be picky, but an ""infinite"" amount? ;)",Nov 14 '10 at 20:38
19,1,198,"@ Nev Stokes: Well we're still coming up with new security issues everyday in non-cloud environments, why not also cloud?",Nov 15 '10 at 1:43
19,1,175,"I'd be interested in seeing a real world comparison of risk between cloud and non-cloud deployments.  Since most risk is from insiders, one would think the cloud solution is more secure.  I doubt the local-non-cloud deployment will be as secure as the cloud deployment in most cases.",Dec 1 '10 at 21:03
19,1,98,"@makerofthings - I have a feeling your assumption that most risk is from insiders is outdated by a few years. Most real risk as measured at C-suite level is external (possibly with an element of internal collusion, but not always) as applications are more and more external. So far evidence proves cloud is definitely less secure, but to be fair, this could be mostly around misconfoguration :-)",Dec 30 '10 at 1:57
19,1,199,"In fact, the (very good) ENISA link lists 35 risks and 53 vulnerabilities - that's total of only 88 which was less than infinite last I checked. ""Infinite"" sounds a lot like paranoid scare tactics to me. Sure, If there was more content to the answer or to the indirect argument against cloud computing it contains, I'd be happy let the attack pass or would even join the crowd - but stated like this there just isn't.",Jan 10 '11 at 12:22
19,2,200,"Good points Avid although I'm not sure every item you listed falls into the security category, but still all very relevant to Cloud apps. I think your last point is a very important one. The individuals security (the user of your app) is at least as important as your companies security.",Dec 30 '10 at 2:51
19,2,188,"@Anonymous, actually I don't regard laws as protecting the individual's security - I can do that better than any vague and generic law. However, this is ""security"" because it relates to compliance to those laws.",Dec 30 '10 at 8:41
19,7,98,"the OP requested security issues specific to the cloud. What you have posted contains a reasonable list of security headings but reads as an advert. The link you added is also a marketing front page, not a source of security information.",Jan 10 '11 at 9:35
19,7,204,Adverts like these usually hurt the business more than it could do any good.,Sep 18 '13 at 4:22
19,1,98,Comments are not for extended discussion; this conversation has been moved to chat.,Sep 26 at 9:51
19,1,205,"Reminds me of the alleged habit of New York City inhabitants of the 1970s and -80s, when crime was at a high, to carry two wallets -- one with 20 dollars or so for a mugger and the other one with the real valuables. (Any parallels between police and muggers are, of course, entirely coincidental.)",Oct 4 at 12:35
19,2,207,"It's probably not illegal to have a crappy old phone., op would need to make very sure that is indeed the case.",Sep 26 at 11:53
19,2,208,"Be wary - my nokia 6310 supported Java, and stored up to 102 kbytes of JAR files.  And even worse, it was java.",Sep 26 at 11:56
19,2,209,@Criggie While possible that they've got a java version of the app... I'm betting they didn't get into that nightmare and just wave people on if their phone doesn't support the app.,Sep 26 at 12:00
19,2,206,"I agree with you. Getting this type of phone is the best solution IFF this won't draw suspicion from police even farther. I asked OP in comments if he can get simple phone or live without of phone at all, but didn't get reply and now my comment is deleted. Whatever. Regardless, additional ""benefit"" of keeping android phone with running app is for it to be ""red herring"". You give up a little bit of privacy in order to not get yourself into an even bigger trouble. What's better: government knowing exactly where you are at any time or sitting in jail?",Sep 26 at 13:10
19,2,210,"Only problem, they can still listen to all your calls, read your text and track your whereabouts through carrier surveillance. May be worth mentioning.",Sep 26 at 15:33
19,3,211,"There is one more risc too to concider - other channels used more less frequently - and it may not be for security, just for convenience. I can say, that I made application, which normally communicate in plain text each 1/2 hour, but 4x a day it also use other channel for other data and sometimes (like once a week to once a three months) use another channel for totally another kind of data. (And sometimes it update itself.) Lack of any of such communications is reported as big red error at central server. And it has nothing to do with spying or security, just with primary function of the app.",Sep 25 at 3:46
19,3,212,"There are a few more: sandbox the app + sandbox apps that you want to hide, off the top of my head.",Sep 25 at 6:05
19,3,213,"actually httpS is not very effective on neither Android devices nor iOS devices. the free version of Fiddler Proxy (+ this plugin) has everything needed to generate a fake certificate, install it on the phone, and perform MITM https-decryption, modifcation, redirection, and blocking. i've used this myself several times to study and cheat in mobile games. (and study the Facebook Messenger / friends API)",Sep 25 at 8:14
19,3,214,"@user1067003 Sure, performing a MitM on yourself is very doable.  I wasn't trying to imply otherwise.  However, it is still harder than simply sniffing network traffic for an unencrypted connection.  My point was that SSL is the first and most basic security step for web systems, and also very easy to do.  Anyone who is not bothering with HTTPS these days simply isn't trying, and SSL certainly does provide a barrier from simple snooping.   Add in HSTS and public key pinning and you're starting to get about as secure as possible on someone else's device.",Sep 25 at 10:33
19,3,215,"I'm not exactly an expert on mobile communication, but AFAIK any phone comes with both an IMEI (spoofable, but it's tricky) and an IMSI (not spoofable, as it's the ID of your phone in the network). Considering the capacities of Chinas surveillance I would be astonished if they couldn't detect a phone with an unique ID having the app active only sporadically. Let alone sniffing on higher levels of the system or examining the entire storage when the app is running.",Sep 26 at 17:52
19,5,217,"Whether this is possible is extremely dependent on the particular phone, even if Android is a given.",Sep 24 at 22:33
19,5,218,What stops them using the logs of the mobile phone network to check that app is running at all times the phone is connected?,Sep 25 at 8:08
19,5,132,@ThoriumBR Surveillance apps presumably do run all the time.,Sep 25 at 16:32
19,5,67,"@ThoriumBR A mobile phone doesn't go to sleep when not in use like a closed laptop; if nothing else, it will be constantly checking with transmitters to ensure it can receive incoming calls. It seems perfectly plausible to me for a background application to be logging many times a minute whenever the phone is switched on; saving to a local, encrypted, database; and periodically uploading reports to a central server. Gaps in that log might be viewed as suspicious, particularly if they can be compared against logs demanded from the network operator.",Sep 25 at 17:12
19,5,67,"@ThoriumBR The assumption that they want the app to be invisible and unobtrusive is also dubious. The Chinese government conducts surveillance by coercion, not subterfuge - they're not installing this app remotely without users' permission, they are (allegedly) demanding that they install it under threat of arrest. They have no motivation to hide what it does; anyone who gets angry and decides to bypass it can simply be publicly punished as ""subversive""; that's how totalitarianism works.",Sep 25 at 17:18
19,6,220,"Given how insecure the spyware appears to be, simply installing it will likely open you up to attacks from actors other than the Chinese government.",Sep 25 at 16:50
19,6,221,"@AndrolGenhald: Probably, but if you can't leave the country, what else do you want to do? Not complying is not an option, really.",Sep 25 at 16:52
19,6,220,"The situation certainly sucks. I just wanted to point out that even if you accept that it's ok for the Chinese government to do this, there are still other risks.",Sep 25 at 17:03
19,6,222,"This doesn't really answer the question. It's about ""I know I'm targeted. How do I defend?"". Your answer is basically ""How to avoid being targeted"" and therefore not really answering the exact question.",Sep 27 at 11:02
19,6,221,"@iBug: That's true, but sometimes ""Don't do it"" is the right answer. There's too much at stake, and chances that OP gets caught are high (I'd say 99%). The spyware transmits the IMEI, so they know exactly who isn't sending. They also know exactly who had the spyware installed. So... not good.",Sep 27 at 11:06
19,7,223,This will not help in case of keylogger spyware.,Sep 25 at 8:41
19,7,224,How can a keylogger affect this approach ? Please explain.,Sep 25 at 9:08
19,7,223,"Bare in mind that, keylogger can keep data inside the phone. So if the phone confiscated by the Big brother, the user still susceptible to phone activities forensic.",Sep 25 at 9:17
19,7,225,"I believe the first paragraph is the most critical one. OP is not alone in this, it's a big community of people affected and they will have found a workable solution. Just be aware that the more people fooling the system, the more likely the government will pick up on it and close the loophole. If you're using a method that gets closed there's a chance their net will catch you.",Sep 25 at 10:24
19,7,224,@Ruadhan2300 I mis read indeed your comment. I totally agree with you on that point.,Sep 25 at 11:28
19,8,76,There are certainly ways to defeat this spyware without raising red flags. It's not like the spyware's functionality is particularly secret (or particularly sophisticated).,Sep 24 at 13:45
19,8,226,"Police might not be information security gurus, but they are good at telling if I am hiding something in my other pocket. Then the consequences might be worse.",Sep 24 at 13:53
19,8,214,"I really doubt this is true, and even if it is correct you are not providing any evidence of that fact.  Rather, you are expecting everyone to just take your word for it.  Given the importance of this question to the OP, I think a little more effort is required.",Sep 24 at 16:00
19,8,227,"@forest But it might not be the same tomorrow as it is today, and that can make all the difference in defeating it or losing to it. When we're talking an oppressive government, can you, in good conscience, really tell someone you've never met to take that risk?",Sep 24 at 19:47
19,8,228,"Note that with the cooperation of network carriers, they will be able to tell if you are using another cellphone with the same SIM card, or if a subscriber has two SIM cards nearby, or the number of devices that are connected to your home WiFi or network. It may be unwise to use a second phone in any case.",Sep 25 at 16:58
19,9,230,"If I were trying to monitor everything, I would have code that flags packets going through the towers without corresponding reports from my spyware.",Sep 26 at 11:36
19,9,231,That would be very difficult to do.  Nothing is ever 100%.,Sep 26 at 13:41
19,9,230,"It would indeed be difficult to catch 100%.  It would not be difficult to catch 90%.  And if they weren’t already catching a huge percentage of what they want, threads like this would not exist.",Sep 26 at 16:45
19,9,232,"""Hang on, there are packets flying back and forth, but they are not connected to any running app ... Flag this phone as suspicious.""",Sep 27 at 11:37
19,9,79,@tripleee do people not use tethering in China?,Oct 1 at 2:34
19,10,230,"If you CAN afford a second phone, either they find out when you buy it or they find out when you use it.",Sep 30 at 23:43
19,10,233,"This is what I'm saying, the cellphone tower reports people in the area that aren't running the APP and then they can triangulate you and pull up a CCTV image of someone walking the path of the offending phone. Also, chances are this webpage is no longer available to the majority of the people there.",Oct 1 at 0:11
19,11,234,"your answer is good.   and is also just an example of how complicated it is to do monitoring and surveillence, which seemed like is an easy job to do.   your answer examplify the many variations of technologies that are available for monitoring and anti-monitoring - just like the end-less game of virus and anti-virus.   which is also why i hardly read all other solutions and techniques, which is not as technically deep as I wanted (from the monitoring/trojanizing point of view).",Oct 2 at 0:52
19,11,234,"talking about PC:   you also have chrome bugs reporting, windows telemetry etc all capable of sending back debugging information.   if they want to monitor, and you are not doing anything ""harmful"", just let them do it - it is like having a security guard near your house.   and you may be afraid that one day this security guard may come back and attack you?   then get multiple security guards.   Apps that can monitor other apps - like those of parental control apps which I used to install on my kids' phone.",Oct 2 at 0:55
19,11,235,@PeterTeoh Thanks. Variations as you rightly pointed out is the key to both sides. For those who care this is an endless game but sadly majority dint care IMO,Oct 2 at 5:13
19,12,235,+1. Unfortunately rooting and using niche tools like XprivacyLua is not for everyone ( I use).  Just as FYI am alternative in my answer security.stackexchange.com/a/194842/99059,Oct 2 at 5:15
19,15,232,Presumably then the app will alert that it cannot call home and display a big friendly red badge with yellow stars.,Sep 27 at 11:38
19,15,239,I'm not sure how the app works exactly. It could definitely be passed off as server-side error that wouldn't be your fault. You can also change it whenever you are about to be inspected and otherwise have it set to block traffic.,Sep 28 at 20:32
19,17,241,"Most of this answer is just saying ""lol you're f---ed good luck"", it doesn't really try to answer the question itself. Even if you factory reset your phone, if the police are on the streets, as the question says they are, they're just going to stop you and demand you install it again.",Sep 29 at 0:46
19,17,242,"@MatthewElvey people are sometimes being sent to ""reeducation camps"" for not having the software installed in this province, and they keep track of who has it installed. If it is suddenly not sending data anymore, they WOULD catch that. Not only is this answer not helpful, it is genuinely dangerous, especially if OP is Uyghur.",Sep 30 at 5:35
19,17,243,"Ok, thanks, user185163.  If the excuse/explanation:  ""I didn't remove it.  I was having trouble with my phone and the phone vendor removed it when they reset my phone.  Here's a receipt / record of the visit.""   won't work to avoid 'reeducation camp' then my ""idea to consider"" indeed was poor and I've just edited my answer to reflect that.  What do you think now, @user185163 ?",Sep 30 at 18:59
19,17,243,I've radically edited my answer; would appreciate more re-rates and/or more feedback.  I find it interesting that the playing dumb strategy is said to be sure not to work in China. I imagine it might be useful in other countries/other legal systems.  But then the only repressive regimes I have significant experience with are the relatively lighter touch ones in the US.,Oct 7 at 23:57
19,18,220,Transport encryption doesn't do any good if the endpoint is compromised.,Sep 24 at 15:13
19,18,244,They'll generate a report on him stating that he uses Tor/VPN? What a recommendation...,Sep 24 at 22:21
19,18,217,"The spyware is locally intercepting the data, making both TOR and a VPN more than useless.  Those change and somewhat protect the path your data takes through the internet, they don't change what your device is doing before that!  And if the spyware sends its report over one of these the government could easily notice that they're receiving data from a known TOR node or VPN service....",Sep 24 at 22:40
19,18,230,They also know what phones are using which towers and whether those phones are reporting.  And they shut down/block VPNs when they detect them.,Sep 26 at 11:45
20,1,246,"Another reason is usability. Sending an SMS to a new number is more of a hassle, and much more error prone, than receiving one and getting a short code from it. Users should also be rightfully wary of letting random apps send SMSes, so automating the SMS sending isn't that good an idea.",Sep 17 at 17:29
20,1,247,I'd also be concerned about that getting hijacked and causing me to subscribe/pay for a premium texting service unintentionally.,Sep 17 at 19:42
20,1,248,"Sadly, it's not super hard to send a fake sms from arbitrary numbers on certain carriers :(  Intercepting the user receiving a message at least requires you to be near the person physically to easily intercept.",Sep 17 at 20:52
20,2,250,"Further to that, it's usually impossible to tell in advance how much an SMS to a certain number would cost. ""Premium"" numbers can charge an almost-arbitrarily high amount for SMS sent to them on top of operator costs. Therefore, ""send us an SMS"" is rife for scams.",Sep 18 at 8:53
20,1,237,"Actually, I see how it could be set up.  Don't have a fake login, but rather a real but restricted login.  Apps and data would either be open or restricted, if you were in the duress login you would see only those things not marked as restricted.",Jun 2 at 0:33
20,1,252,"@Loren that's a neat idea. The duress login could include limited data (maybe a few old documents) and intentionally broken apps. For example, the fake login could have an online banking app that looks real, but that always crashes. Mobile data could be restricted (""Sorry, you've used all your data for this month""), and apps could then whine about how they won't work until they can connect to the Internet.",Jun 2 at 2:46
20,1,237,"@RobertColumbia The tactics would be known, you can't use things like that.  But have the baking app on the restricted list--with the duress code you simply don't see it.  So long as you use apps for the sensitive stuff even someone who knows how the system works can't tell if it's the duress code or not other than by rooting the phone.  If you want to make it even more secure there are two duress codes--if the second is used the entire sensitive dataset is deleted.  (Use the first on the snoopy official, the second if arrested.)",Jun 2 at 3:30
20,1,253,"That's not so difficult to achieve: ask the users to do it for themselves. For example, when you create a Facebook account  then FB can prompt you to create your ""dummy profile"" in case you are compromised. Still I think hackers will know it's fake and, since is a well known feature for all its users, it wont have any effect.",Jun 2 at 18:46
20,1,254,"Even when access is granted to obviously fake data, that data still has to be processed to determine that it is fake, making it take longer for the hacker to gain access to the real data.",Jun 4 at 7:02
20,2,76,I don't think that's what plausible deniability is. Honeypot != plausible deniability.,Jun 1 at 13:22
20,2,255,"@forest: The question is a bit confused, because it describes a honeypot but the use case (criminal pointing a gun at the phone's owner) demands plausible deniability.  This answer addresses the use case.",Jun 1 at 14:12
20,2,256,@BenVoigt that's still not what plausible deniability is,Jun 1 at 17:33
20,2,255,"@Kevin: It's exactly what the term ""plausible deniability"" means in the context of cryptosystems.  In addition to VeraCrypt which this answer mentioned, see also LUKS, TrueCrypt.",Jun 1 at 18:59
20,2,257,"@Kevin where it comes to crypotsystems, plausible deniability essentially means that when forced to provide access to content secured by a password/encryption, once I provide that access (give my account credentials, enter password/decryption key), I can claim that I've given access to the content I've secured and the adversary cannot reasonably prove otherwise. I can plausibly deny that the real data is still hidden behind yet another key/credential and that I've actually provided access to the real data (or all the data that's available).",Jun 1 at 20:00
20,3,259,"Yep! This is why, above all of your other passwords, regardless of your password system, your email password should ALWAYS be unique.",Jun 4 at 11:27
20,3,260,And always mean Not even with an account of an obscure phpBB forum from 2001. Or an android application thats ask for an username/password even if you used it for 5 minutes. Or an old torrent traker. Especially with Android apps when an apps can request the mail of all device account then check with the used password.,Jun 5 at 14:10
20,4,252,Will airport security in Oceania even allow you to fly to Eurasia? I thought Oceania has always been at war with Eurasia.,Jun 2 at 2:50
20,4,262,People keep devising increasingly clever technical means to defeat a potential request to unlock a phone/laptop/data carrier at a border/airport inspection but I don't see how any of this helps. You might just as well flat-out refuse to give them your password. You might end up in detention or being refused entry but that could also happen while deliberately trying to lock your phone and playing dumb won't help you. The real solution is to avoid taking any sensitive material over the border.,Jun 2 at 9:30
20,4,263,VeraCrypt is an example of a program which implements it - you can set up an alternate password which will uncover only fake part of the data,Jun 2 at 13:18
20,4,264,"In real life, it is however much more likely that instead of ""letting you go on your way"" they will confiscate the equipment and give it to their forensic analysts, detain you, and put you permanently on ""possible terrorist"" list. Or worse.",Jun 3 at 19:49
20,4,265,"@RobertColumbia ""I thought Oceania has always been at war with Eurasia"" They have. Until Oceania makes peace with Eurasia, then they will always have been at war with Eastasia.",Jun 4 at 9:16
20,6,267,Also interesting is Turris from NIC.CZ turris.cz/en,Jun 4 at 20:45
20,11,272,This answer is comedy gold! 😂,Jun 5 at 8:37
21,1,275,"Thank you. I'm Facebook linked. The scammer can know my first and last name from it, date of birth, and Gmail address. Is this sufficient information the scammer can use to do this ""social engineering"" thing where they convince a customer service rep that they're me and gain access to something of mine? I don't have an online account for bank services, so I think my money is safe.",Mar 29 at 17:49
21,1,276,"Technically, yes. But I doubt it would be of any use. It's not like they can magically take over your gmail account and click on activation links etc. But as I said, I think in this situation, their goal was a Telegram account. There's much easier ways to hack people than social engineering based on a handful of public info!",Mar 29 at 18:51
21,1,277,@Dooma You should make your birth date and email private on Facebook...,Mar 29 at 21:48
21,1,275,@Bakuriu Did it.,Mar 29 at 21:57
21,1,278,"@Nomad, Perhaps, they thought that Dooma had an account on Telegram (since Telegram doesn't have encryption turned on by default, then that means they could have accessed his private messages if he had any). thehackernews.com/2016/08/hack-telegram-account.html",Mar 29 at 22:05
21,2,279,"Sadly we cannot tell who has good intentions or not, so caution is everything, if someone asks for your contact ask them to send theirs first. You can easily know if its real or not at that point.",Mar 29 at 20:57
21,2,280,"Multiple applications can connect to the same telegram account, unlike whats app",Mar 30 at 14:31
21,3,275,Thanks. I'll see what I can do regarding a new number.,Mar 29 at 18:35
21,3,281,"Most automated attacks via MMS/SMS target a wide range of numbers. You're no more at risk to those attacks for having shared your number. If it is a targeted attack, then you may be in trouble, but this doesn't seem like a targeted attack. So changing your phone number seems a bit of an overreaction.",Mar 29 at 19:00
21,3,275,Interesting point.,Mar 29 at 20:13
21,3,282,"also, to protect against this, it's far more important to install system patches (aka updates) on the smartphone.",Mar 30 at 10:49
21,3,283,"The original poster should not change their number. There is no risk if they didn’t go past what was described in the original post. Had the original poster gone further and given up more info, then maybe that is a risk. But at this point the risk is silly at best. Many phone numbers are public in some way so changing a number is rash… It’s only advisable if that number is connected to something and the scammer can connect the pieces. As it stands, utterly no risk but a wee bit of sweat from the stress of realizing that one might have been scammed.",Mar 31 at 1:36
21,4,283,"100% correct. The vast majority of phone numbers are public for the most part. The risk only comes if that phone number is somehow connected to something nefarious or some two-factor authentication scam. Either way, this was a “nibble” at a scam and not a scam.",Mar 31 at 1:33
22,1,9,"@RafiRosa To be honest, I don't think you will ever be able to say for sure where it came from. But in the end, what you need to do is the same - a factory reset.",Mar 27 at 17:21
22,1,286,@RafiRosa You can sideload apps that have valid Apple-signed certificates. Otherwise they jailbroke your phone for you.,Mar 28 at 3:54
22,1,287,@Rafi Rosa It's possible the app was compiled directly from XCode to your phone or using TestFlight.  Other than jailbreaking this is the only way unapproved apps can get on your phone.  That pretty much means you should stop using your phone and wipe it ASAP.,Mar 28 at 17:29
22,1,288,"@Anders I have done a complete factory reset of my phone and changed all passwords that I used while using it. After that all of apps I have previously installed were restored by iPhone and all of my files were stored on iCloud, is it all I can do?",Mar 28 at 19:47
22,1,289,"@ray That's not a thing on iOS. Carriers do not have control over firmware updates, and cannot force-install apps.",Mar 30 at 19:40
22,3,291,"Unfortunately, it's pretty common for repair shops to ask for the PIN to log in and verify all hardware functionality after opening the case, just in case they knocked something loose (camera, GPS, bluetooth, etc) which isn't detectable on a lock screen. I go to a shop nearby that will do repairs while you wait so I can log in for them to check while I watch, but I've seen plenty of customers give up the PIN without a moment's pause.",Mar 28 at 20:35
22,4,293,"Unless the employee who didn't know was just working the cash register & did not know that the repairs guys in back routinely install helper apps & remove them after the repair is complete (and forgot to this time). In any case, restore from backup",Mar 28 at 10:58
22,4,294,Might be worth reporting it to the police also so that they can send someone in undercover to do an investigation if they have the will and resources (though they won't),Mar 28 at 12:18
22,4,288,"That was my first thought, that it's some leftover software to test the battery, but the guy who repaired it said that it was already there and didn't have anything to do with it.",Mar 28 at 15:22
22,4,56,"It's a problem if they unlocked the phone at all, even for testing.",Mar 28 at 19:31
22,4,236,"It's a problem for us security aware folks, but most people and most repair people don't see a problem there. And often they are right and not all persons with access rights do bad things. But when they don't tell the truth afterwards, the trust is gone.",Mar 29 at 7:20
23,1,228,"I might be wrong, but I think iPhone applications are sandboxed and a key logger cannot be installed except if the OS has been jailbroken/rooted, or an alternate on-screen keyboard has been installed (which the user can check).",Jul 28 '17 at 13:56
23,1,300,could potentially install full monitoring and install things like key loggers Without physical access to the phone. How would they achieve this? OP only said they pay the phone bill,Jul 28 '17 at 15:20
23,1,301,@users1 If they enrolled it in the orgs mobile management server.,Jul 28 '17 at 15:27
23,1,56,"In any reasonable world, there wouldn't be any way to ""enroll it in the mobile management server"" without explicit consent from the owner of the device, unlocking it and selecting an option to enroll it. However I wouldn't put it past phone vendors to put carrier backdoors in that allow the carrier to enroll the device without the owner's consent...",Jul 28 '17 at 17:34
23,1,301,"The question didn't mention physical access, typically the enrolment will require the user to click a link in an email, scan a QR code or something similar. In my experiance in a byod situation the user will typically be required to complete the enrolment. If the phone is issued then it will be pre-enrolled. Not all orgs will require it to be enrolled, but if it is then all of what has been said is possible. If the org is paying the subscription, then they may require it to be enrolled. This would be a fairly standard and reasonable request, especially if corp data is ever on the device.",Jul 29 '17 at 8:11
23,3,56,"And 4, buy yourself a personal device, consider your already-purchased device a loss and a lesson if you can't get your employer to pay for the BYOD they already duped you into buying, and start keeping work and personal devices 100% separate and isolated.",Jul 28 '17 at 17:36
23,3,228,"I know of no mobile provider that allows the customer to view which Internet sites they accessed (which requires a proxied connection or deep packet inspection), not even which IP addresses traffic was sent to. Can you point at some example(s)?",Jul 28 '17 at 14:00
23,3,101,"I don't know of any that would do it for an end user account, but all the big EU providers offer these types of services to enterprise clients. Vodafone, EE, etc.",Jul 28 '17 at 14:04
23,3,228,@GdG however I have searched and I couldn't find any web resource where Vodafone (or other operator) describes such facilities for business customers. And I'd really like to see it.,Jul 28 '17 at 14:49
23,3,7,"@GdD It would also seem to be a potential privacy regulations nightmare, even more so in light of the EU GDPR coming into effect next summer. A citation for your claim that ""all the big EU providers offer [detailed traffic monitoring] services to enterprise clients"" would much improve this answer. Even just a link to a single such provider's web site showing that such service is available in some location within the EU would be beneficial.",Jul 28 '17 at 14:56
23,3,101,"I couldn't cite that without violating agreements @MichaelKjörling, and I'm not going to do that. Regarding the GDPR, an organization can perform surveillance on employees if it has a legal requirement.",Jul 28 '17 at 15:04
24,1,303,"This is makes no sense. Both the hashed password or the password itself can serve as an authentication key. If an attacker can break your transport security then they can get your key and break the system. However, hashing on the user's end is a great idea because if this transport security is broken then the attacker only gets a hash instead of the user's password.",Oct 11 '16 at 3:10
24,1,304,So should I hash server side or client side?,Oct 11 '16 at 3:20
24,1,304,"I'm confused, some places say hash user side, some places say otherwise.",Oct 11 '16 at 3:34
24,1,57,"@David: the only thing proven by the client sending a hash is that the client knows the hash, not that the client knows the secret (the original password). If the transport layer security is broken, it doesn't matter if the attacker only sees the hash, because it's as good as the password. Better, in fact, since if the attacker got hold of the password, they would h ave to go to all the trouble to hash it with the correct algorithm and correct number of iterations before sending it. By hashing client side, you've done that work for them.",Oct 11 '16 at 4:47
24,1,305,"@Tobiq No, hash on server side ONLY!",Oct 11 '16 at 9:17
24,5,304,Will the client side hash match the server side hash??,Oct 11 '16 at 3:22
24,5,303,"If they use the same hash algorithm and salt, yes.",Oct 11 '16 at 3:55
24,5,57,"Which means you have to publish the algorithm, and the number of iterations. TLS isn't perfect, but if it's broken and the bad guys get the password hash, it's game over anyway, because in this scheme the hash is the password--literally no difference at all. The hash is the password. This is wrong. It sounds like you're just trying to mitigate blame on the server side so you don't have to take responsibility if you screw up your TLS configuration.",Oct 11 '16 at 4:52
24,5,57,"The only thing that sending a hash to the server proves is that the sender knows the hash, not that the sender knows the original secret (the password). A bad guy could intercept the hash and use it to login just as easily as they can intercept the plaintext password and use it to log in.",Oct 11 '16 at 4:57
24,5,57,"I believe we collectively have an obligation to provide complete and accurate answers to these kinds of questions if we're going to answer them at all.  ;-) The fact is that overall security in the context we're talking about is ONLY served by hashing on the server. Hashing on the client can augment security, but it can also dramatically decrease security if it's done wrong. Far too many answers seem to come out and declare that hashing on the client is better, and a replacement, for hashing on the server, and that simply is not true.",Oct 11 '16 at 18:30
25,4,312,"Could you add a source for your claim, that it is not recommended to change the base image?",Mar 22 at 12:34
25,4,313,"Changing anything from the base layer, which is generally a Ubuntu or similar (as @LieRyan said, Alpine is one of the most minimalist base layer out there), implies creating another layer in the final image to redefine the FileSystem, requiring to rebuild most part of the container (all the layers above the application itself) on any small change on the application or code. Creating a container (at least in medium-big projects) implies a previous planning on its layering, not just start deleting things trying to harden the deploy. Regards",Mar 22 at 17:45
26,1,111,"Can't you use the same encoding (<>""'& to their equivalent entities) for HTML, HTML attributes and XHTML?",Jul 7 '16 at 13:26
26,1,66,@CodesInChaos: If you have a pure (X)HTML context this should be ok. But there are slight differences in Javascript context in HTML vs. XHTML context. Try <script><![CDATA[ var foo='</script>'; alert(foo); ]]></script> within HTML and XHTML context.,Jul 7 '16 at 13:53
26,1,316,"What difficulties would there be with having a DOM object attribute which would indicate ""This object will never legitimately contain any 'dangerous' objects or attributes outside certain categories, so the effects of any such objects/attributes should be stifled""?  While ensuring safety with browsers that lack such a feature might be difficult, having a means of setting one string to create some text that includes bold and italic would seem much cleaner than having to assemble such text as a bunch of DOM objects.",Jul 7 '16 at 16:55
26,1,66,"@supercat: have a looking at Content Security Policy 2.0 which has nonces to mark parts where inline script is safe and can otherwise forbid inline script at all. But of course you need browser support for this, support in the frameworks and knowledge of the developers that this feature exists at all and why they should use it.",Jul 7 '16 at 18:44
26,1,317,@supercat: markdown is a safe way to allow user markup.,Jul 7 '16 at 20:05
26,2,7,"Another thing you may want to add while you are at it later, is overlong UTF-8 sequences.",Jul 7 '16 at 14:18
26,2,317,"I wrote my own sanitize function, and i thought it was easy, what am i missing? it's only hard if you try to implement 1,000,001 things yourself. I run marked on the sanitized text to get clickable links and allow markdown formatting, and from everything i've seen, it's safe and sound. It was harder back in the IE days, but most bugs have been fixed, so now it's only gaping holes that need patched up.",Jul 7 '16 at 20:08
26,2,9,"@dandavis I think the function works fine to stop XSS between tags. If you use it sanitize attribute values when you concatenate a HTML string it would not work, since it does not escape '. So understanding the context is key.",Jul 7 '16 at 21:05
26,2,317,"really good to know, thanks! you're right that there's not something equally simple for attribs, since new Option(0,str).outerHTML.split('""')[1] doesn't work in IE/Edge...",Jul 7 '16 at 21:59
26,3,318,Why is #2 relevant here?,Jul 7 '16 at 13:56
26,3,319,"Sorry, but my work day is 8 hours, not 12 hours. MAYBE 10 if I include my commute.",Jul 7 '16 at 14:56
26,3,320,"I think the use of the word ""stupidity"" in this context is rather extreme, insulting and simply incorrect. Programmers who leave their code open to such vulnerabilities are most likely not stupid, but instead (a) ignorant, (b) unskilled or (c) under a lot of pressure from management to deliver features fast and cheap (while security concerns are last on the list, or not at all).",Jul 8 '16 at 7:48
26,3,321,"@RaduMurzea I completely agree with you, you are more then welcome to edit my answer!",Jul 8 '16 at 8:14
27,1,324,"Thanks. What I meant by ""as secure as possible"" is ""as secure as possible given my knowledge and my capabilities"".  If I install an anti-virus on my system, I certainly made my system more secure. But can I say, I secured my system?",Mar 20 '16 at 13:35
27,1,116,A system can never be 100% secure,Mar 20 '16 at 14:22
27,1,325,"@othman I'm definitely not a security expert, but I think that it depends on many things, including what your system actually is (personal laptop with no credit card info,etc.;personal laptop with credit card info,...;corporate laptop;web server;...) and how much money/resources can you invest.",Mar 20 '16 at 18:06
27,1,92,@LucasKauffman no worries - just thought I'd give you a head's up,Mar 24 '16 at 15:02
27,5,281,"The question is about appsec, not the theoretical details of encryption. I know the word 'appsec' may isn't in the text, but it is the tag the OP chose.",Mar 20 '16 at 16:32
27,5,329,You think that cryptography is not related to appsec?,Mar 20 '16 at 16:33
27,5,281,I think you only partially (very partially) answered the question and provide no practical advice to the OP.,Mar 20 '16 at 16:38
27,5,329,"Yes I partially answered the question and I stated it ""In terms of cryptography"". Partial contribution, is a contribution anyway, right? I just added something which other answers don't have.",Mar 20 '16 at 16:40
27,5,281,"Yes, upon rereading the question, I see you did respond to it.",Mar 20 '16 at 16:44
28,1,330,"I agree that prompting for the password seems to be the most sensible solution when faced with user managed username changes.  However, some systems (e.g. Microsoft Active Directory) allow administrators to change usernames without user involvement.  In these situations the requirement for a user to provide their password isn't really compatible.  I suspect your other suggestion of hashing all variations may be the only workable option of meeting the requirement.  Otherwise we may have to be willing to allow for the risk of an admin-changed username matching a password.",Mar 7 '16 at 19:53
28,1,331,@PwdRsch why would an administrator want to change usernames without user involvement? I can not imagine a legit use case.,Mar 7 '16 at 19:56
28,1,281,"@PwdRsch - Perhaps you can do the uname/password check on every login? Or on the first login after a username change? That said, how about you just fail to meet the requirements in those edge cases? They hardly seem worth worrying about.",Mar 7 '16 at 20:03
28,1,332,"@emory brings up a good point. If the admin changes the username, what do you do if your policy is violated? Just not change the name? Use a different - incorrect - name? That doesn't make sense. (when the user changes it themselves, you could require a password change, but letting the admin change the password doesn't seem desirable; if it were, you could just make a password change mandatory and not have a problem)",Mar 7 '16 at 20:11
28,1,333,"If the admin changes the username, you could set a flag that the password needs to be changed. A link is sent to the user, notifying the change. The very next time that user logins, the password has to be changed. In my case, I always try to force the use of paraphrases which are way longer than usernames. Even better, ditch the password and use keys instead.",Mar 8 '16 at 1:26
28,2,330,"I do agree that a determined user can choose a weaker password than we might like, despite the policy rules or other controls we use to prevent bad choices.  However, I don't feel like this requirement (as stated) is taking things too far.  Pair that technical control with education as you suggest and hopefully we gain the security advantages of both.  However, just because most attackers will make guesses beyond a password matching the username doesn't mean that we shouldn't attempt to enforce this rule. We still need to eliminate the low hanging fruit.",Mar 8 '16 at 16:55
28,2,157,"@PwdRsch I don't disagree, my point, I suppose, is that you don't need to hide what you're doing from the user - explicitly requiring them to enter their password when making a name change, or running the same check the next time they log in after an admin changed their name, actually improves the education because it gives them a reason to pay attention.  That said, if an admin is able to, essentially, accidentally guess a user's password when selecting their username, then that's a reason to offload the education onto the user anyway because that was a horribly chosen password.",Mar 8 '16 at 20:59
28,3,332,"Depending on the hashing and the hardware, it may take around a minute for that. If an admin changes the username that might be fine (if it is clearly displayed that this is a slow process), if a user changes it, a minute might not be acceptable. It may result in problems, eg users resubmitting forms and then not knowing with what username they ended up with, or users closing the window before they get the message that their new username is not acceptable.",Mar 8 '16 at 14:32
28,3,334,"@tim It needs to be slow. Otherwise, an attacker who takes over the server or has a replica of the server could simply keep trying to change the username until they figure out the password (in practice they could make something much better than the server). You can trade speed for space though: en.wikipedia.org/wiki/Scrypt",Mar 8 '16 at 17:00
28,3,157,"If you (assumed to be a non-expert password cracker) can brute force it, an attacker can do the same much, much quicker.  If you are an expert password cracker, then you already know the futility of what you're doing.",Mar 8 '16 at 21:00
28,3,334,"@Jason you don't need to know the password, just make sure that the username isn't the password.",Mar 8 '16 at 21:01
28,4,335,"Brenda Utthead would have a colorable objection to your proposed policy, especially if usernames are used in public communication.",Mar 8 '16 at 5:11
28,4,331,@DamianYerrick To be clear it is my understanding that the OP has a strict requirement that userids be derived formulaicly from legal names and not match passwords.  I think users should be able to pick their own userid which need not resemble their legal name.  Brenda's objection has more to do with OP's requirements than my policy.,Mar 8 '16 at 8:44
28,4,331,"@DamianYerrick in comments, the OP said that if Brenda Smith (userid bsmith, password butthead) married Rick Utthead (userid rutthead) and took Utthead's name, then the admin would have to change Brenda's userid to butthead but that would be a problem because now her userid and password are the same.",Mar 8 '16 at 10:33
28,4,331,"@DamianYerrick but if you believe that the userid matching the password is not the big problem in Brenda's scenario, then I have to agree.",Mar 8 '16 at 10:36
28,4,336,"@DamianYerrick Cisco Systems actually did that, and seemed spectacularly unlucky with their staff names, along the lines of Chris Rapherty, Simon Hitchin, and so forth. I believe they also truncated their usernames to 8 letters. Much amusement (outside Cisco) ensued.",Mar 9 '16 at 8:25
28,5,330,This was one of the early answers offered as a seemingly good option that the poster then later deleted once people chimed in with the warnings you list. ;)  I agree that the tradeoffs in security don't really make this worthwhile.,Mar 8 '16 at 17:22
28,5,337,"@PwdRsch Oh, thanks - I didn't realize. This answer, for once, I'd be perfectly fine to see getting uncommented downvotes :)",Mar 8 '16 at 18:11
28,5,19,@DewiMorgan You could make it CW... that way you wouldn't lose rep for the downvotes.,Mar 8 '16 at 18:16
28,5,337,"Ooh, thanks, @wizzwizz4, I didn't know that. Done! Feels kinda... naughty and exploitatious, though :(",Mar 8 '16 at 18:27
28,1,338,"Thanks for the long description ! But do you know if there is HIPAA equivalence for England ? I'm not encrypting data with SQL command but via my app. So in theory it's harder to decrypt ? I didn't really understand fully what you describe, will try to look into it.",Nov 3 '15 at 21:51
28,1,339,"HIPAA is a U.S. law so it does not govern healthcare data in England.  However, the Data Protection Act (DPA) and the soon-to-be-adopted EU GDPR will govern data located in the UK.  I am no expert int he GDPR, but it does include provisions similar to HIPAA regarding the use of encryption.",Nov 3 '15 at 22:01
28,2,338,Thanks for the answer ! This is more like a worst case scenario plan than anything else.   There is many things to do before getting to steal the DB data but I'm not well aware of security requirement (To make it more funny : It's not the same requirements depending on the country...).  But don't you think the solution I provided on the original post (optimius package) would be kind of weak to secure the data ?,Nov 3 '15 at 15:38
28,2,340,"I was not able to follow the link to the optimus package, but you sound quite correct that obscuring ids will still allow for a pattern recognition. If you change one id to another equivalent id then you still have matching ids. If someone accesses your entire DB, it is reasonable to believe that they may also have access to the controlling files including the methods of obfuscation and encryption.",Nov 3 '15 at 16:00
28,2,338,github.com/jenssegers/optimus here is the link :),Nov 3 '15 at 16:03
28,2,340,"The Optimus could work if you only used it on only one table (patient or doctor table for example). Then, if someone got the entire DB but not the Optimus constructor values they would not easily make any direct connections (perhaps comparing appointment times could be used to circumvent this entirely). It still, however, adds a layer of difficulty to building and maintaining the entire system and the payoff is not encryption, but rather security through obscurity. It's merely a more sophisticated obfuscation than using base64 or another encoding method.",Nov 3 '15 at 16:19
29,1,265,"If I remember correctly, some of the initial ""jail-breaking"" methods for Sony's Playstation Portable (PSP) used a ""specially crafted"" image file that broke the PSP's decoder and allowed code embedded in the JPG to execute.",Aug 27 '15 at 12:28
29,1,343,"""attacker could potentially execute arbitrary code"" is that boilerplate for any buffer overflow bug?  Elevating privileges from the user-mode thread would be another problem.",Aug 27 '15 at 16:25
29,1,35,"@JDługosz, yes, that's a standardized description.  Most CVEs and descriptions of security holes use a set of standard phrases like ""[local|remote] attacker could potentially execute [arbitrary] [commands|code] [with [user|elevated] privileges]"".  The re-use of succinct keywords and phrases (""boilerplate"") allows defenders to quickly assess risk - for example, the [local|remote] keyword is important in assessing risk.  The phrasing used in the GDI+ announcement tells me the code runs with the privileges of the user opening the JPEG - in 2004-2006 Windows, often an Administrator!",Aug 27 '15 at 16:48
29,1,344,"This exploit would only be possible if the decompression algorithm in question had a bug in it that allowed arbitrary code execution, correct?",Aug 29 '15 at 3:19
29,1,345,"@TripeHound yep, rainbow colors, ghost in the shell cover picture and tiff format to use chickHEN. I still have those somewhere around here. Edit: yep, chickHEN but not tiff :/",Aug 29 '15 at 13:18
29,2,346,"Actually, the media framework is called ""Stagefright"", but the name is already catchy enough to name it ""Stagefright bug"". /offtopic",Aug 27 '15 at 19:02
29,3,348,"Yes... sooo hard with unmanaged code -.- If one would just code in managed code, buffer over/underflows would reduce to below 1% of their current impact on security...",Aug 28 '15 at 11:35
29,3,316,"If C compiler writers were interested in promoting robustness, C could outperform Java for many tasks where the semantics are ""Given valid input, produce correct output; given invalid input, produce loosely-constrained output"".  Unfortunately, compiler writers seem to have no interest in that, and prefer to optimize out logic which would prevent security-critical forms of UB if it doesn't prevent what would otherwise be non-security-critical forms of UB from occurring in those same situations.",Aug 28 '15 at 21:45
29,3,316,"@Falco: Managed code isn't free; on the other hand, since hyper-modern C is eliminating many of the performance advantages C used to have in cases where programmers didn't care about precise behavior in cases of things like overflow, the only way I can see C remaining competitive is to officially catalog behaviors that weren't guaranteed by the Standard but were widely implemented, and allow programmers to specify them.",Aug 28 '15 at 21:50
29,3,349,"@Falco Unfortunately, managed runtimes also have their share of buffer overflows. The people who wrote Java did a horrible job of using defensive programming to guard the runtime's weak spots. In fact, I just ran into one in the latest Java (and reported it to Oracle, who confirmed it). It all boils down to an ill-advised pursuit of premature optimization. I wonder if we suddenly have a breakthrough and can build 20 GHz chips, will programmers finally embrace bounds checks and such. Or are they too fn stubborn.",Aug 29 '15 at 10:41
29,3,350,"@AleksandrDubinsky I wouldn't hold my breath - we've had a few increases in the order of magnitude of processing speeds, and so many still cling to avoiding bounds checking. The reasons they had so far will still be the same if CPUs get 1000x faster. There is hope, though - for example, Microsoft Research had been working on a full blown managed OS from the ground up - it wasn't designed for performance but rather safety and security, but for a research project, it still performed well enough. And when the whole OS is managed, you avoid the cost of communicating between managed and unmanaged.",Aug 31 '15 at 8:20
29,5,353,"While the technique is possible against a buggy JPEG decoder, this doesn't appear to be an example of such. This is simply encoding a configuration file in a JPEG to hide updates to an existing infection. OP appears to be asking about JPEG images as a vector for transmitting new infections.",Aug 26 '15 at 19:20
30,1,354,"Couldn't you hash it twice?  Once on the client side, once on the server?",Nov 10 at 22:33
30,1,355,"@NathanMerrill - Hashing the password on the client side just makes the hash the password (absent some scheme to include extra information).  However, only securing the password is worthless - you have to at least authenticate the channel, or an attacker can impersonate both ends of the conversation, even without knowing the password.",Nov 11 at 4:55
30,1,356,"This is misleading. Yes, you can. This question asks for how to secure passwords when you can't use HTTP. A bad company policy, a misconfigured firewall can all force HTTP to be used. In situations like this, exchanging certificates (IPsec TLS SCRAM etc) through a side-channel is possible and should be the answer. Answer the question instead of giving advice that was not sought after.",Nov 12 at 1:17
30,1,332,"@noɥʇʎԀʎzɐɹƆ I did mention that there are alternatives when a secure side-channel can be used (which is required for the alternatives mentioned in other answers). But that's not really what the question is about (""The method should be usable in any browser""). There are definitely use-cases for these alternatives, but ""we can't use HTTPS because our infrastructure is too broken"" shouldn't be one of them.",Nov 12 at 10:40
30,1,9,"I agree with the main poin - it can't be done. But I'd add that even if you are Dave and roll your own crypto, it would not help. The code that does the crypto is delivered over HTTP, and can therefore be tampered with.",Nov 13 at 14:44
30,3,357,"You can safely do this with a fat client (a desktop or mobile application) that is distributed in a safe manner. However, with an in-browser thin client, the client code itself is delivered over HTTP as well, and as @AndrolGenhald pointed out, attackers in the middle can intercept and change it to send the password to them.",Nov 9 at 19:07
30,3,358,"@Zoltan That's very true, thank you for the clarification. The original question doesn't specify whether they need a thin or fat client, so my answer wouldn't apply in all cases. But even over HTTP, I think this provides some additional security. The attack has gone from just snooping traffic to modifying code. Nothing insurmountable, so it wouldn't be secure, but maybe less bad? And I think having both HTTPS and SCRAM is very beneficial.",Nov 9 at 19:17
30,3,357,"If you agree, you may consider mentioning this restriction in your answer. Otherwise I really like your answer as challange-response was my first thought too and none of the other answers mentioned it.",Nov 9 at 19:29
30,3,359,"@Melanie You are absolutely correct that even with just HTTP it's better. There are attackers only capable of passive attacks. That being said, there's no reason not to use HTTPS nowadays when it's free.",Nov 10 at 4:30
30,3,360,"@IanF1 The server only needs to know a Hash of the password. Also, all Browsers I know implement a similar mechanism: HTTP Digest Authentication, so even with a thin client one can use this method. On the other hand, HTTP digest is based on the obsolete MD5 hashes, but I am not sure how insecure it is due to this (MD5 is not broken for every application).",Nov 12 at 5:59
30,7,363,"Then some attacker can inject some code to get the password directly from the <input>. A crazy idea: ""Sadly it's just a little bit hard to support HTTPS on Reserved IP addresses. Please run this code on your terminal and paste the result HMAC were."" (of course disable copy pasting to prevent pastejacking in the long run).",Nov 10 at 10:34
31,1,83,How's that voluntary? Didn't you mean involuntary?,Nov 5 at 15:43
31,1,369,@d33tah because those helpful security probes are volunteering their resources to pen test your website.,Nov 5 at 16:22
31,1,219,"I mean voluntary. They are testing your site for free. Sometimes they even send you a damage report, but don't count on that...",Nov 5 at 17:34
31,1,248,"@ThoriumBR: Ah. The ""attacker"" is volunteering. Got it. That's also only questionably legal, last I checked. Not outright illegal, but a grey area.",Nov 5 at 18:50
31,1,370,"Nice to see these generous people for their volunteer work. Maybe they would even crack my site and create backups of my customer data, for free! It is very helpful. :-)",Nov 6 at 4:53
31,2,371,A great plugin for Wordpress is Wordfence. It automatically blocks suspicious requests. Also it makes it easy to view all traffic and block in one click.,Nov 6 at 3:04
31,5,373,Blocking the whole country will prevent all its people from accessing the website. Is this really a good practice ?,Nov 5 at 16:37
31,5,374,"No, it is definitely not a good practice ....",Nov 5 at 16:48
31,5,375,"No, but it's good security.",Nov 5 at 16:49
32,1,377,The current time must also be sent in any HTTP response.,Jun 8 at 9:36
32,1,378,Does it become a problem when the server time is not accurate?,Jun 8 at 10:26
32,1,76,"@ToddSewell If the server time is not accurate, an attacker can abuse that in various ways. TLS and certificates in general rely on accurate system time.",Jun 8 at 10:27
32,1,21,"Related, I wrote a guide to a bunch of different ways you can determine the time on a remote server.",Jun 8 at 11:33
32,1,379,"""as long as it is accurate"" This seems to imply that server time being inaccurate would be a security issue. Is it? If so, how?",Jun 8 at 22:23
32,2,380,"I think you misunderstood the ""To explain more.."" part. In contrary, I'm already assuming mobile app users are more likely to change the device time to cheat, that's why I need the server time for counter-checking. If there's a more correct way of doing this, I'm all ears. But thank you for your input as well.",Jun 8 at 10:51
32,2,381,"@Manny: send every command to the server. Have the server verify every action. You can assume in the client code that the server will approve and carry out consequences. If it turns out the server rejects an action (one second later e.g.,), revert on the client. This way, your server is the authority. Your server is (should be) 100% under your control and there you can trust things like system time.",Jun 8 at 13:58
32,2,382,"""Leaking"" system time should never be fixed. It is required to be revealed for proper operation of TLS and HTTP.",Jun 8 at 18:00
32,2,383,@OrangeDog exactly what I said in my answer.,Jun 8 at 18:07
33,1,377,"According to MDN, SRI only works for <script> and <link> subresources. What about other subresources like images, frames, etc.?",May 8 at 12:39
33,1,387,"@BenoitEsnard I don't know of any clever way to make that work for iframe or img, but it looks like they plan to extend SRI to other resource types soon (as I added to the answer).",May 8 at 13:06
33,1,388,"@BenoitEsnard eventually, you can load the image with javascript and check the signature.",May 8 at 13:32
33,1,389,"You could load the images without waiting for the JS, and only display them once the JS loads.",May 8 at 19:14
33,1,387,"@CandiedOrange Well, the main point is that flipping any single bit isn't sufficient to bypass SRI and inject a malicious script. Against a MITM threat, you'd obviously have to serve the original document over a secure channel (but not the script).",May 9 at 11:04
33,2,390,"Quick lower bound math. 32 sites. Let's say 10M hits a day. Lets say each website's homepage loads 200 resources (sampled homepages for wikipedia, Amazon, and facebook). Let's say each month has 30 days. Seven months. That's 13 Trillion requests. That is 0.386% * 10^6 requests experience this or one in a quarter billion. So yeah, I'd not worry about this unless OP is CTO for Twitter. Neat exploit nonetheless.",May 8 at 14:40
33,2,71,"@usr-local-ΕΨΗΕΛΩΝ Infrastructure problems are in the scope of the article. I quote: ""While a bit-error in the memory of a PC or phone will only affect one user, a bit-error in a proxy, recursive DNS server, or a database cache may affect thousands of users. Bit-errors in web application caches, DNS resolvers, and a proxy server were all observed in my experiment. For instance, a bit error changing fbcdn.net to fbbdn.net led to more than a thousand Farmville players to make requests to my server."". It does not really matter for this attack where and how the bitflip occured.",May 8 at 15:10
33,2,76,@Lan One in a quarter billion actually seems really high.,May 9 at 2:37
33,2,391,@Philipp I'd expect the server gear to have ECC memory to avoid exactly this scenario,May 9 at 8:46
33,2,392,"@ratchetfreak, while ECC can help, if your RAM is faulty it may be spitting out more error bits than the ECC can repair, even worse if it's your ECC chip itself that's faulty... However, the same argument applies, if the server even boots in this situation it'll be fairly unstable. Multi-bit errors that are too much for the ECC do occur, but at an even rarer rate than already noted.",May 10 at 16:58
33,3,393,"The author addressed point 2 by showing the fraction of source referral domains that were set at the original (the last figure on the page). Further, there was evidence of programmatic access to the bitsquat domains (Windows Update).",May 8 at 15:04
33,3,394,"Underrated answer: the article’s conclusion is very obviously bogus. Things like “several bit errors per request” are a dead giveaway that these are not, in fact, bit errors but some other source of errors (or, as mentioned in another answer, seriously broken pieces of hardware). Other than that, bit errors virtually don’t happen. The other answers follow red herrings: this isn’t a real threat, there’s no need to defend against it.",May 11 at 14:32
33,4,396,"àpple.com is not the result of bit-squatting, that's a different type of attack.",May 8 at 19:14
33,4,397,"@Barmar That seems like it is a vicious and undeserved attack on us poor souls that sometimes work in France, on those damn azerty keyeboards, but write only english... =(",May 9 at 11:03
33,4,277,"@Barmar I don't see where I implied that àpple.com would be a bitsquatting attack. Bitsquatting attacks are just a subclass of the more general ""similar-domain attacks"". The only difference between bitsquatting and things like typosquatting is that bitsquatting might happen due to bit errors in the computer/network. However my answer provide an effective defense for all such attacks. If the attackers cannot own the bitsquatted domain, the bitsquatting attack cannot take place.",May 9 at 16:22
33,4,396,"Yeah, sorry about that. I was mostly reacting to your last paragraph. Bitsquatting is not likely to be used for phishing, since the resulting name doesn't look like the original. It's only useful for capturing traffic that was intended for the original domain.",May 9 at 16:36
33,4,395,"Registering all bitsquat domains requires is O(n) domain registrations, with n the length of domain name. You can multiply n by ~254 factor. We are assuming at most 1 character flips and 0x0 not allowed. Retain any illegal DNS char to find the correct figure.",May 10 at 13:19
33,5,398,"I'm not sure how much this would help for bitsquatting. If a bit gets flipped somewhere in the network code while preparing a request for a resource, the CSP would still match OK because it gets checked before the request is started.",May 11 at 19:00
33,5,399,"Ah, it seems I didn't read into the question enough. Still, it can help by doing the same thing for IPs.",May 11 at 20:23
34,1,296,"To emphasize Peter's point on maintenance with some personal experience: it is already hard to work on old code or code that somebody else wrote. Adding a foreign language to the mix would be nightmarish. Doubly so if comments aren't in English. If your staff speaks a language besides English, OK, then do whatever you want. Otherwise, I'd give the idea a hard ""No"".",Apr 30 at 19:14
34,1,401,"It's a common misconception that security through obscurity is a ""bad idea"" per se but that is not correct. What's a bad idea is to rely on security through obscurity. If you're following best practices elsewhere then it can be fine as an added component to defence in depth. Often such tactics are useless at worst and marginally useful at best. A good example is running SSH on a non-default port. (I'm not saying that the OP's example is justified however).",Apr 30 at 23:18
34,1,402,"""The enemy knows the system.""",May 1 at 8:52
34,1,403,"I feel you're downplaying the last two points. Obscurity of this sort will make it harder for others to spot weaknesses in the system, no? Seems to me we can expect security to be actively weakened by this practice.",May 1 at 13:37
34,1,296,"@dandavis Fixing vulnerabilities is an important part of the software lifecycle. Anything that complicates that process is generally bad, and this is especially true for zero-days. If you slow the development process, you extend the window of zero-day vulnerability. I don't see a significant improvement from such an approach. Plus, just because your programmers are unfamiliar with a language doesn't mean your adversaries are too. I would assume there are adversaries fluent in any given language, which is actually a handicap if your programmers are not.",May 1 at 15:15
34,3,405,"To add, people can reverse engineer code from machine code. People have figured out how to hack complicated games by just looking at how their memory changes when they do actions. And that's without how the front end of the web forces you to give actual source code (even minimized, that's considerably higher level, and thus patterns are more evident). There's also anti-obfusification tools that try to somewhat undo some of the trickier obfusification techniques (and of course, code formatters also help).",May 1 at 22:30
34,3,406,"While this is correct in the case of Java / JavaScript, there are also some programming languages that use a non-English language for their built-in functionality. Though the obscurity of those languages may be more relevant to security than their function names.",May 3 at 6:43
34,3,76,"Not just reverse engineer games from runtime analysis, but even create completely working source code that compiles into exactly equivalent bytecode, turning a closed source game into a multiplatform game!",May 5 at 7:29
34,4,76,"It wouldn't be more secure, especially as reverse engineers (for example) often don't even have the original symbol names to work with, so are already used to working with completely made-up names or identifiers.",May 1 at 5:50
34,4,25,"We are talking about a REST, i.e. a web application. An attacker is far more likely to analyse the web interaction than the Java bytecode.",May 1 at 6:00
34,4,76,"My point is that reverse engineers are already used to this kind of thing, even if they're not doing actual decompilation. I wrote an answer to that effect, with C reverse engineering merely as an example.",May 1 at 6:01
34,4,408,"Naming things after their opposites would be more likely to introduce bugs than naming in a foreign language. ""And then, we call create_user and... Wait, why does it keep saying 'account does not exist'? Of course it doesn't exist -- that's why I'm trying to create it!"" But +1 for your more general point.",May 1 at 12:40
34,4,25,"Of course it's a silly idea and I don't recommend it. But from a purely security perspective, it would be more secure. :-) (not every secure idea is a good idea)",May 1 at 20:51
34,5,409,"Sure, I never intended to use language as a security measure. I was just curious about the community's thoughts on the matter.",May 1 at 22:24
34,5,410,This. Either your application is secure or it isn't. The language you use for naming parameters has zero effect on making it more secure.,May 2 at 12:59
34,6,92,"Your comparison has severe problems. Navajo was extremely rare and not a written language. The OP could simply be asking about a common language in his/her geographic location (i.e. the available dev talent pool speaks it). Also, translations could also be maintained on the dev end.",May 1 at 14:21
34,6,411,"@schroeder My choice of an oral language was perhaps poor, but the historical aspect made for an interesting analogy.  I carefully read the question for any hint about the developers' language, but even then there are major business aspects in terms of future out- or even in-sourcing. e.g. take the stereotypical case of outsourcing to India, and use Hindi.  Then when the bosses decide to bring the maintenance in house for political reasons you have to find fluent developers.  I did say it was extreme, to make a point",May 1 at 14:38
34,10,408,This is just rules-lawyering. The scheme would so obviously be pointless if the language chosen was the one spoken by most of the users that we can be sure the asker meant to exclude that.,May 1 at 12:46
34,10,415,"Yes, but presumably there are not many scenarios where the dev team can be relied on to always know the same non-English language and the community that uses the application don't know that language.",May 3 at 9:38
34,10,416,"Actually there are plenty of bilingual communities and markets. A lot of developers for the italian market are in Albania, so they can make the development in a different language. Same for developing in Hindu for an english speaking app, etc. All I wanted to point out is that the language of the users/targets will play a roll on how much ""security"" this factor can provide.",May 3 at 14:23
35,1,417,"The exception would be if a domain has been subdivided. E.g. user1 has control over example.com/user1 and subdomains, user2 has control over example.com/user2 and subdomains, etc. And theoretically, if the string ""example.com/test"" is generated dynamically, that could open an injection vulnerability.",Apr 12 at 18:18
35,1,418,maybe? but a redirect doesnt automatically grant you permission ... if I get redirected from /index.html to /superTopsecretKittys.html ... im still going to get a 401 Unauthorized,Apr 12 at 20:14
35,1,417,"Yes, but it raises phishing issues. If I can get do an injection attack that gets a website to redirect users to my website, then I be like ""Whoops, there's an error, you need to re-enter your credentials"".",Apr 12 at 20:26
35,1,418,thats a completely different issue ... if you inject something into someones website ... they have bigger problems then a simple redirect.,Apr 12 at 22:21
35,1,227,I wouldn't mention HTTP to HTTPS here. There are some weak spots in doing so that aren't relevant to the OP's description.,Apr 13 at 8:42
35,5,421,Sadly the edit does not improve the answer.,Apr 12 at 18:31
36,1,424,"""In the end, it all comes down to trust. How much do you trust this person"" It's beyond that - in the end, it all comes down to risk. How much wreckage could this person create with this trust.",Nov 20 at 22:02
36,1,425,"+1, but don't forget Poste Restante - it is free, in some areas even more available than boxes, and offer similar protection to PO box, you only reveal general area where you live, or post office that's convenient for you. And this does not even have to be post office near your home, depending on country you may be able to select one near your work or at arbitrary address, or it may be one post office available for poste restante in whole city. Sender will not know anything more than the fact you can drive to this particular office.",Nov 21 at 10:15
36,1,426,"Or you could have it sent to your office, if this is something which is allowed/common where you live.",Nov 21 at 10:22
36,1,425,"@WoJ exposing where you work is arguably more risky, as it gives a fast and easy way for blackmail ""Do what I want or I send ___ to your employer"".",Nov 21 at 10:23
36,1,426,"@Mołot: maybe. This really depends on the risk context (""I do not want the guy to know where I live so that I am not robbed"" vs. your example)",Nov 21 at 10:32
36,2,428,"Short of renting a PO box at the post office, this is the best option, the disadvantage being that you will not receive notification of reception, you just have to check in with the post office until it gets there.",Nov 21 at 6:08
36,2,429,"@DrunkenCodeMonkey Depends on the country and system. For example Australia Post now offers a ""Parcel Collect"" option which is effectively a form of Poste Restante with notifications (when addressed with a customer number you sign up for). Check what your local postal services offer.",Nov 21 at 7:23
36,2,430,@DrunkenCodeMonkey Agreeing with Bob. In Germany we also have the option to receive SMS or eMail notifications upon receiving mail which was delivered to a post office.,Nov 21 at 16:32
36,3,431,"""Pay it forward"" great advice. Just because I do a favour for a stranger, doesn't mean I now have to trust that stranger. It's called a confidence trick, not because I give the trickster my confidence, but because he gives me his. He asks me for a favour, to make me trust him.",Nov 21 at 11:13
36,3,432,Here is some info on 'pay it forward'. en.wikipedia.org/wiki/Pay_it_forward,Nov 25 at 10:59
36,3,433,The OP could use customs complications and lack of familiarity with international mail as tactful reasons to prefer pay-it-forward to a physical gift.,Nov 25 at 16:54
36,6,427,Downvoted because in my opinion (and as explained in other answers below) there are risks involved.,Nov 21 at 11:10
36,6,437,Give three examples of where people have got into trouble after ONLY giving out their postal address and where sending this information to an outsider was the culprit.,Nov 21 at 11:21
36,6,427,"Read the answer of fluffy down below for some possible risks. I'd like to add postal fraud to that as seen in the answer that Lithilion gave, which is a common thing in the Netherlands to do for example.",Nov 21 at 11:24
36,6,438,"@d-b even if an address associated with a name itself were not in any way misusable by a motivated player, we still don't know what other information that person already has from other sources about OP, so handing out the address might only be one further puzzle piece they require to achieve their nefarious goals. Not saying there is anything nefarious going on though, to gauge that is ultimately up to OP.",Nov 21 at 17:21
36,6,439,"I live in 2018 so I haven't seen a ""white pages"" in at least a decade",Nov 21 at 17:47
36,8,312,What does this add to the other 6 answers?,Nov 21 at 14:18
36,8,440,"You can find the registered keeper's name and address from DVLA provided you have ""reasonable cause"": gov.uk/government/publications/…",Nov 21 at 14:59
36,8,441,"@MartinBonner Ah, I didn't know that! Probably has been the case since long; this was when Altavista still held sway, so it wasn't that obvious for us to find out from outside of the UK.",Nov 28 at 11:27
36,8,441,"@TomK. It adds that I describe a feasible way of avoiding the risk in the first place without exposing a neutral/friendly party (the Cornershop). Then I try to weigh the newly-taken risk --- it's still nonzero, so why not ""don't do it!"" as answer? --- with the background noise of fraud risk, using the parking fine example. My focus isn't on the particular case and whether to do/not do it; my focus is on once you've decided to do it, how to minimize the risk.",Nov 28 at 11:37
36,8,440,@user3445853 Ah.  Altervista.  Yes.  Right.  a) The form would not have been on the government website (there wasn't a government website then); b) the rules may well have changed since then.,Nov 28 at 12:38
38,1,449,European-based sites shouldn't store full IP addresses under GDPR. Specifically in Germany it was forbidden even before GDPR.,Sep 13 at 17:33
38,1,450,"@kubanczyk, if european websites weren't allowed to store IP addresses, then they wouldn't be able to report any crimes to the police or block malicious traffic. Investigations without knowing the IPs would probably be too hard. As ThoriumBR said, I would say that logging the IPs is definitely a ""legitimate interest"" allowed by the GDPR.",Sep 13 at 18:07
38,1,26,"How could someone that's not the ISP track an IP address to a home address?  Unless you mean someone with access to something like Amazon.com logs, and can somehow search for an IP address associated with an account (or similar common website)",Sep 13 at 18:08
38,1,451,"I upvoted this answer.  Just wanted to add Re: the Am I safe question, the answer is almost certainly not.  The OP took an action based on something they ""saw on the internet"" with what appears to be no knowledge of the risks VPN use is to mitigate, if the chosen service will fulfil that need, or the OPSEC behaviours users need to adopt to make such a service useful as a privacy aid.",Sep 13 at 20:23
38,1,219,"That's why I said A few, very few sites won't log any information....",Sep 14 at 11:11
38,2,452,"Thanks for the tip on Privacy Badger.  I have been interested in AdBlock, etc., but they always required too much fiddling with configuration.  This part of the PrivacyBadger goals caught my attention: ""...which could function well without any settings, knowledge, or configuration by the user...""",Sep 13 at 19:57
38,2,453,"It may be a different question, but - how come an attacker gets my home address by hacking into my modem/router?",Sep 14 at 12:26
38,2,454,"@Wildcard: uBlock Origin, which is the technical leader in ad blocking, don t require any fiddling with configuration",Sep 14 at 12:47
38,2,453,@amccormack Thank you very much. Haven't thought of those vectors at all.,Sep 14 at 13:38
38,2,262,(+1) I am using Privacy Badger and I guess the fact it comes from the EFF gives it some additional credibility but I can't help but note that it's a piece of software too and it's free of charge...,Sep 16 at 11:00
38,3,456,How can you trust your VPN provider tho?,Sep 13 at 17:53
38,3,457,"@BaileyS Basically the choice is ""trusting your ISP"" vs. ""trusting your VPN provider"". Either of them could turn out to be evil, but maybe you should choose the one that gets most of its business and reputation from respecting privacy and not keeping logs.",Sep 13 at 18:31
38,3,456,@FedericoPoloni Are you saying there is a reputable VPN provider?!?,Sep 13 at 18:43
38,3,76,"On TV, all you need is a GUI in Visual BASIC to track an IP in real-time!",Sep 14 at 0:41
38,3,76,"@uom-pgregorio Even the ones that are ""reputable"" do not operate on reputable ISPs, which have the same capabilities to correlate and deanonymize you as the VPN you use. The fact is, even if a VPN service does not log, their ISP does. See security.stackexchange.com/a/175186/165253.",Sep 14 at 0:42
38,4,459,"Well i assumed when i clicked the link it came up straight up before going on to the page, if they do have my IP do they get any of my personal info from it ? like my name etc?  if you want to check out the website i think they used its here grabify.link   Im just really worried thats all, thank you for the help though!",Sep 13 at 14:13
38,4,9,"@A.james No, they don't get your name or any personal info.",Sep 13 at 14:49
38,8,462,"The IP isn't yours - its your providers. that's being overly technical. My telephone number also isn't but my phone provider's. But people associate it with me. I associate it with me. Even my phone provider associates with me. The phrase ""my IP"" still holds up though - it already means ""the IP I am using at this point in time"" - whether other people are also using it or it's going to change.",Sep 14 at 7:35
38,8,463,"@vlaz If you change to a different phone provider, you can keep your phone number. Your IP address might change at any time (for a typical home user who doesn't have a static IP address). If I look up a phone number, I expect to find who's number it is (though I might not succeed). If I look up an IP, I'll generally only find the ISP.",Sep 14 at 18:14
38,8,462,"@IanD.Scott so? Point was that ""my IP"" is perfectly reasonable and commont thing to say. Nobody would or  should be confused by what that phrase because it's not 100% precise. That's how language works - we use shorthand even when slightly incorrect because we all understand the right thing.",Sep 14 at 18:24
38,8,464,The last sentence is partly incomprehensible. Can you fix it?,Sep 16 at 10:09
39,1,467,"Excellent I understand it now. Basically it's just a measurement of the complexity of a password, but not password strength since hash tables, dictionary checks, common information checks and such exist. Thank you for the explanation. :)",Sep 5 at 10:11
39,1,220,"""you only need to get 1/2+1 possibilities to gain the correct answer"" - That's not what the birthday attack is, that's just a 50% probability of guessing correctly based on having searched half the space.",Sep 5 at 13:37
39,1,220,"@ConnorJ Good correction, I actually missed that one. You're still mistakenly applying the birthday attack though. When you say ""1/2+1 possibilities"" (idk where you're getting that +1) you mean trying 50M out of 100M of the potential passwords, correct? That's not what the birthday attack is, and it doesn't guarantee finding the correct password, it's the average # of guesses required.",Sep 5 at 14:45
39,1,468,"@ConnorJ The birthday attack would apply to two plaintexts having the same hash, not finding an input that has the same hash as a specific plaintext; ie, the birthday attack cannot be used to find a collision with a known hash.",Sep 5 at 14:58
39,1,256,"How is this the accepted answer?  It's not how password entropy is calculated at all, and it doesn't even answer the OP's question of why different checkers come up with different entropy levels.",Sep 6 at 13:38
39,2,469,"Great example, I updated my answer to direct here since this is an excellent description about the contents of a password, and not just the entropy of it!",Sep 5 at 11:34
39,2,379,"""Entropy is determined not by what the password looks like but by how it is generated"" This is the key. You should make that a bold statement, so that it stands out more. +1",Sep 5 at 19:29
39,2,470,"This reminds me of this Dilbert comic, too: dilbert.com/strip/2001-10-25",Sep 6 at 7:53
39,2,214,@ilkkachu my favorite Dilbert ever :),Sep 6 at 14:26
39,2,471,"Could you argue that the entropy of your password decays to the probability that you are using the rot13 method you described? For a random user, that probability is quite low. The probability that they use 123456 or password is much higher. Or do you assume that an attacker can identify you personally and knows your password generation method from leaks (e.g. the leaks listed on haveibeenpwned.com)?",Sep 19 at 19:06
39,4,23,"""There is no way to judge whether a sequence of numbers or characters happens to be random."" Yes, while checking randomness of past values against any possible pattern is bad, it's fairly easy to check whether a future trial meets basic patterns.   I can't say 1111111 isn't random, but I can design a test so that if a generator spits out 1111111 during the test then I will, with high certainty, reject  the null hypothesis that the numbers are random and independent.  Regardless, here's a relevant Dilbert comic: dilbert.com/strip/2001-10-25",Sep 7 at 16:26
39,4,316,"@CodyP: For any practical N, the number of theoretically-possible non-random ways of generating a list of N numbers will exceed the number of possible lists of N numbers.  If the sole criterion one uses to reject a list is whether 11111111 appears more than it should, one would erroneously accept most non-random lists.  If one would attempt to reject 60% of lists that could be might conceivably have been produced by non-random means, one would also reject 60% of random lists.  The best one do is hope that certain non-random means of generating data are much more likely to be used than others.",Sep 7 at 17:06
39,4,23,"While that's factually correct and you bring up good caveats, my main point is that the intuitive idea that 1111111 is a sign of a bad RNG has merit, despite academic considerations like false negatives and obscure patterns. I don't think anyone would suggest you set your p-value at 60% or check only for repeated 1's. Given mature tests like the NIST test suite or the zxcvbn password checker, we don't have to pretend that rejecting 1111111 is a hard problem.  This is especially true for passwords where we have a good idea of what patterns are common.",Sep 7 at 21:07
39,4,316,@CodyP: My point is that assessments of whether particular passcodes are more likely to be chosen via high-entropy method than a low-entropy method are predicated almost entirely upon guesses as to the likelihood of various low-entropy methods being employed.,Sep 7 at 22:50
39,6,220,"+1, but I believe your H(X) should be log_2(n) not log_2(1/n). And I'm not sure why you say other answers don't use the information theory definition of entropy, some of them don't but most do.",Sep 6 at 19:39
39,6,473,"@AndrolGenhald I fixed the H(X) error. I forgot the minus signs. Other answers go straight to how many bits of strength a password has, but they skip the formulas. Maybe I didn't read closely enough. Skipping the nuance of entropy being defined based on a probability distribution leads to misunderstanding. Someone could easily take away, instead, the idea that strength = length * alphabet_size, which is only true for uniform distributions.",Sep 6 at 19:53
39,6,23,"Some suggestions for possible improvements: ""And may be harvesting passwords."" could be clearer if you linked examples of known good and known malicious entropy checkers. Also note that non-uniform (discrete) distributions are not preferred in password or especially cryptography because some outputs are more common than the entropy alone would suggest (in exchange for other outputs being less common).  Finally, most password strength checkers provide an upper bound or ""blind"" entropy.  Good checkers provide a smaller upper bound based on realistic scenarios.  I don't view that as disingenuous.",Sep 7 at 16:39
39,7,67,"While it's true that the entropy of a password depends on the creation scheme used to generate it, I don't think it follows that the strength does. Firstly, it requires the creation scheme to be known: F9GndpVkfB44VdvwfUgTxGH7A8t and  rE67AjbDCUotaju9H49sMFgYszA are only weak if the attacker knows that there is a scheme which selects those two strings. Secondly, different schemes may generate the same password: if I use a Geiger counter to select a sequence of 8 Unicode code points, it might select ""password""; clearly, the strong randomness hasn't led to a strong password.",Sep 7 at 8:54
39,7,474,"In security you should assume that the attacker knows the system. And the people who do seriously try to crack passwords know more about the schemes that people use than anyone else.  So yes. You can get strong passwords out of low entropy schemes by using schemes that are unknown (and don't produce the kinds of common results from common schemes). But think about what these means for strength meters. Once a scheme is known, the meter needs to magically adjust.",Sep 10 at 22:03
39,7,67,"The sentence I am challenging is ""The strength of a password ... is a function of the scheme that was used to create it."" Yes, attackers know the schemes generally used to generate passwords, but they don't in practice know the specific scheme used to create any particular password. The meter doesn't need to ""magically adjust"", it just needs to be based on the techniques attackers are likely to use. I would say the strength of a password is a function of how likely an attacker is to guess it, regardless of how it was actually created.",Sep 11 at 9:09
40,1,98,Comments are not for extended discussion; this conversation has been moved to chat. Any further comments here will be deleted.,Aug 30 at 18:53
40,2,98,Comments are not for extended discussion; this conversation has been moved to chat.,Aug 30 at 18:52
40,2,475,"In Australia, Microsoft give schools free software licenses for use by students and staff. Coincidentally (?) staff essentially only learn how to teach the use of Microsoft software, and students only learn how to use Microsoft software. This practice may better explain why the school has access to MS products to install on student laptops.",Sep 1 at 1:32
40,2,475,@RyanTheLeach It may  be that the state education department was charged for the use of the software in schools - I don't have any details. My short observation was that in the school environment it was apparently free - teachers were able to install MS software made available to the school on their personal laptops and home PCs if they chose to do so.,Sep 3 at 2:20
40,2,216,"Also: Do you want a child to become interested in hacking things? Then try to limit/lock down their internet access or computer usage. But hey, that's actually educational!",Sep 3 at 7:00
40,2,188,"@NathanMerrill this is different because a library computer (or a computer lab) is owned and managed by the school. In the school only. During school hours. With expectation of school involvement. My laptop, that I've bought and paid for, there is no such expectation or limitation. The child would be using the laptop at home, outside of school hours, in the their bedroom, and not just for school work - their entire online digital lives.",Sep 4 at 7:51
40,3,98,Comments are not for extended discussion; this conversation has been moved to chat.,Aug 31 at 12:16
40,3,476,"I don't know what you want to inspect the certificates for. I think we can take it 99.9% for granted that it is a CA cert to allow their proxy to MITM all https traffic. (It would really surprise me if it were ""only"" the code signing certificate needed to accept their Word macros in a secure configuration ...)",Sep 5 at 19:19
40,3,296,"Throwing their CA directly into the Trusted Root store is exactly what I would oppose. They can filter web content at the proxy/firewall without HTTPS decryption, and they have no business seeing private data.",Sep 5 at 20:16
40,3,477,"Just in case people skim over that link and don't realize what it was about - and it's the only reason I was planning on commenting here, so it's disappointing it barely got a mention in any of the answers - a school district was already caught spying on kids bedrooms through their webcams.",Sep 6 at 15:22
40,3,478,"@Izkata That link is immensely relevant, and I was going to post an answer myself if it hadn't already been brought up. For additional context, the school district in question is in a very affluent area, and nationally both schools involved are listed among the best public schools in the country (at least they were when I attended). Lest anyone think ""well, my school is too good to do something as dumb as this"".",Sep 6 at 17:54
40,4,98,Comments are not for extended discussion; this conversation has been moved to chat.,Aug 31 at 12:17
40,4,479,+1 for being the first answer I saw that mentioned the absolutely enormous problem of them wanting to install certificates. You can sail an aircraft carrier through that security hole... especially if the school system doesn't have a particularly advanced IT department... which they usually don't.,Sep 6 at 3:04
40,5,481,"I tend to agree. The right way of thinking about what's happening here is the school is requiring you to pay for a work-only laptop for the child that they administer. You have a good argument against paying for it, but not a good argument against them administering it. Adults don't expect their work laptop to be usable as a full-time personal device either. (Of course if you can get them to agree not to install anything, that's even better.)",Aug 29 at 19:28
40,5,482,Or dual boot.  It's a bit cheaper than another laptop,Aug 29 at 21:15
40,5,225,"Well yes, though if possible I'd argue for the isolated work hardware. I remember how devious I was when I wanted to do something my parents didn't allow, giving me a dual-boot laptop with my games on one and my work on the other? I'd just boot up on my personal system at every opportunity, it'd be far too tempting.",Aug 30 at 8:27
40,5,483,"Great idea, it will also teach the kid the difference between ""my computer"" and ""computer of my employer"" that many adults lack.",Aug 30 at 9:18
40,5,484,"@Agent_L As usul points out, the huge difference between ""my computer"" and ""work computer"" is that $EMPLOYER paid for the latter.  It's the idea that the school can mandate that you pay for it and then they act like its their property that sticks in my craw.  If the school bought the laptops and issued them to the students, I'd say ""School property, so they write the rules.  Put a piece of electrical tape over the web cam so they don't spy on you, and live with the rest of it.""",Sep 6 at 18:50
40,6,98,Comments are not for extended discussion; this conversation has been moved to chat.,Aug 31 at 12:22
40,6,485,"+1 for the Switching schools option, this is your last resort but should give you pause to consider just how important it is to you as they may refuse and you will have to change schools.",Sep 8 at 9:22
40,7,379,"Parents should give GNU+Linux laptops to their children with encrypted LVM in place. Should a shady IT dept choose to take the laptop anyway, that will be a great way to say ""screw you"". Using LibreOffice over MS Office should be suggested to schools... why are kids being ""educated"" into getting locked-in with a the product of a specific company?",Aug 29 at 20:25
40,7,486,@code_dredd because that's how Microsoft ensures the next generation of customers.,Aug 30 at 3:36
40,7,379,"@barbecue I know, hence ""educated"" being in quotes. The really dumb part is schools paying for licenses when they could've saved the resources for other things.",Aug 30 at 3:43
40,7,156,"@code_dredd Microsoft gifts licenses to schools, or at least gives huge discounts. So unfortunately, they're not really ""paying for licenses [the money for which could be used differently]."" I do not understand how this is any different from a bribe. If someone emailed the school and went ""could you train your kids in using our software and in exchange I'll give you tens of thousands of dollars worth of licenses"", how should parents hope the school responds? Apparently the software is so prohibitively expensive that people need to be given licenses to get them started... It should be illegal",Aug 30 at 17:26
40,7,379,"@Luc You're probably right. I guess to avoid getting locked-in into MS you actually need parents to do the ""marketing"" themselves, i.e. I don't think school admins are necessarily aware of the fact that there are good alternatives that do a better job at following standards and respecting the freedom of their users.",Aug 30 at 18:01
40,8,488,"I think that most of the school's concerns could be addressed by teaching the kids to use cloud storage and by the school providing laptops for use at school. They should just provide a list of requirements, such as ""connect to Exchange server"", ""create and edit Word/Excel/Powerpoint compatible documents"" and leave it at that. Then we could choose what software we wanted to install. Right now the school is getting the best of both worlds and we're getting a loss of privacy and control, which may not be worth the presumably licensed software the school is providing at no cost.",Aug 28 at 22:00
40,8,489,"@Sushil I agree that the BYOD nature of it is the sketchy part. It also raises accessibility issues for families that can't easily just buy a laptop, or parents who aren't ready for their kids to have their own computer at home. I agree that there are better ways the school could have designed this, but I can also understand some school board person probably saying ""We don't have budget to buy a fleet of laptops, so put it on the materials list"" and then the poor IT guy was stuck figuring out how to do BYOD securely.",Aug 28 at 22:22
40,8,489,"I don't know, I don't feel comfortable making judgments about what the school should have done without knowing what kind of limitations they're working with, both technical (how their networks are set up, how much budget they have), political (mandates for tech-enabled classrooms coming from higher-level governments), and legal (legal responsibility for protecting children against online threats, and protecting their networks against incompetent kids). I think you're doing the right thing by raising the questions -- you should go talk to someone at the school and get answers.",Aug 28 at 22:26
40,8,490,"I would think their primary concern as a school is that the laptop is usable for educational assignments set by the staff, and if they have a 1990s IT mentality as they appear to then that may well include installing Microsoft Office. Another concern may be technical support: they don't want kids asking the teacher about how to use software that the teacher has never encountered.",Aug 29 at 8:36
40,8,156,"So you've broken it down into each party's potential concerns, but now what would you advise? I agree with what you wrote so far, but you don't really answer the question.",Aug 30 at 17:30
40,9,452,"""There is no reason to give IT admin access when you can just install it yourself, its easy.""  This shows a total disconnect from the actual reality of parents' technical literacy.  I'll wager you're inside the ""tech bubble"" and have forgotten how clueless most of the world is.",Aug 30 at 2:26
40,9,491,"Sorry i think you have misunderstood my point, you are completely right that is why IT are asking for admin to make it easy for people who don't know how. But clearly the OP does not want to give them admin and I am saying that there is not actually a requirement to do so if they are willing to spend 5 mins learning how to do it themselves.",Aug 30 at 10:18
40,10,98,Comments are not for extended discussion; this conversation has been moved to chat.,Aug 30 at 18:51
40,11,493,"Multi boot is fine if you encrypt the os, which you should do anyway. Virtualization sets you up for a whole load of trouble: What happens if they are supposed to use non-standard peripherals (in my secondary school we had CNC machines, Lego Mindstorm and some toy factory equipment like a miniature conveyor belt), does USB passthrough actually work reliably? What if they are supposed to use some 3D graphics program for and art project or CAD for some architecture or technology project? And you don't know about that in advance, something might come up 2 years from now.",Aug 30 at 20:10
40,11,494,"@Nobody USB passthrough works almost universally for even the weirdest hardware as long as you pass a whole internal USB controller or an external USB hub to the machine before plugging the actual thing in, vs filtering it on connection event.",Aug 30 at 20:56
40,11,494,"@Nobody as for encryption, are you encrypting the bootloader? Yes, your files won't be read in the period since you were attacked until you voluntarily enter the key, but the modified bootloader will be waiting to transmit the key offsite (or just inject a payload into the decrypted system)",Aug 30 at 20:58
40,11,493,That's not the threat scenario here. I seriously doubt there is malware out there trying to attack random (!) people's encrypted non-running os. That would need a significant amount of work for negligible gain. The only way that's a relevant threat is if they are being targeted by a skilled attacker with connections to the school.,Aug 30 at 21:09
40,11,494,"I am speaking of this happening in a purely automated fashion, yeah. On one hand, sure, there's lower hanging fruit. On the other hand, you can't really make a judgement on what kind of stuff you'll encounter in that much of a cesspool.",Aug 30 at 22:04
40,13,496,"This sounds like a personal opinion, rather than an answer to the question.",Aug 29 at 13:16
40,13,236,"These are some arguments for the question in the OP. It is nothing definitive, as there is no definitive answer to a ""should I ..."" question. If you want to nitpick, you could flag the question as ""opinion based"", but I think the answers do the best to be general arguments instead of just opinionated suggestions.",Aug 29 at 13:22
40,13,496,"I think your answer could be improved by rewording some of your arguments, and leaving out others. For instance, the Office/LibreOffice is argument may not be opinionated, but the question isn't about which one of these should be taught. Outlook was never a good e-mail program is definitely opinionated. AV is disputed anyway (source?). Do you trust teachers: Who said teachers are the ones safeguarding private keys, the question is about the IT department.",Aug 29 at 13:34
40,13,225,"At risk of more ""opinion based"" responses...My experience of school IT departments has been largely unimpressive. Maintenance and monitoring rather than info-sec. There is no way I would grant admin-access to my personal device to a school IT dept in any lasting capacity. By all means provide the software and I'll install it for my kid. Hell, I'll even sit and watch while IT does it on my login. But nobody gets admin-rights over my property but me. That's the first rule of secret-keeping right there. ""A secret is only secret if nobody else knows it.""",Aug 29 at 14:42
40,13,370,"@Berend If the m$ office would be a free, open-source software, it would be acceptable. But it is not. Next time you will be obligated to use exclusively volkswagen cars, it will be indoctrinated in you from early childhood, would it be okay, hm?",Aug 30 at 15:02
40,14,497,VeraCrypt can be installed on all Windows versions.,Aug 29 at 18:44
40,16,431,I do not think windows defender and a good network firewall are sufficient to protect a child. How do you want to configure that firewall? And windows defender isn't the most reliable protection I've ever seen to be polite.,Aug 30 at 5:18
40,16,267,"""Some courses have a specific requirement to use Microsoft Office"": such courses would be a poor teaching experience and there's no reason for the parent to facilitate such assault on their children's education.",Aug 30 at 16:11
40,16,156,"""This is mainly because the laptop is paid by the parent.""  What difference does that make? If they are being invasive with monitoring software or whatever, I don't care if it's a company system or my system: it's invasive and I don't want that. It could be a (partial) reason to leave the company or school, depending on what they do exactly. It's not hard to not be creepy, and that does not depend on the ownership.",Aug 30 at 17:52
40,16,493,"@Ben Those two are a good amount of software protection measures against software attacks. The security impact of additional AV can be either negative or positive depending on whom you ask (I have reason to belief negative). Much more important are human protection measures, like educating the child about common threats and how to avoid them. If you intend to use spyware and/or censorship programs to raise your kid then that's an entirely different topic (I'm in favour of fucking talking to the child and doing computer activities together).",Aug 30 at 20:01
40,16,498,"@Ben From my experience at school, there isn't much you would want to do that could give you malware. As long as you don't open random email attachments or download sketchy files, you'll be fine.",Aug 30 at 20:19
40,18,25,"Installing certificates is a SOP in any corporate environment. They probably have self- or PKI-signed certificates for their internal systems, and they might install a certificate to enable SSL-interception (which has its own discussion of merit, but is also SOP).",Sep 5 at 11:26
40,24,92,"Unfortunately, most of this answer is already covered in the 24 other answers.",Sep 5 at 12:29
40,25,505,"I give -1 to this answer, reason: administrative access can be used to make further changes to the computer, e.g. modifying firmware. While this may be high complexity attack vector, it still is possible that your computer will be compromised even after changed the drive to a physically new drive.",Aug 31 at 8:57
40,25,497,"@vakus: Good. If the school pulls that off, call CNN. That school is done for.",Sep 6 at 15:20
41,1,507,"So, you're saying that if it's a personal number, that it is PII, because someone might recognize it?",Jul 3 at 14:03
41,1,508,"No, what I am saying is if it can be used to distinguish or trace an individual's identity then it is PII! This is the case if a mapping from number-> person exists. Even if no one could recognize it but it belongs to a individual, it is PII.",Jul 3 at 14:05
41,1,92,@Michael the case is where the number by itself is enough to act as an identifier,Jul 3 at 20:07
41,1,262,"@Michael You can use that number to track an individual across a number of 'contacts' (in the radar sense): That number contacted this number at this and this time, that number registered to this cell tower at this time, etc. With enough observations, this pattern characterises a single individual, even if you do not happen to know their name. In fact, that's exactly the way IMSI-catchers on drones are being used. As another analogy, consider a photograph of one's likeness: It can clearly be a personally identifiable information, even if you don't have a way to look up the person's name.",Jul 3 at 20:21
41,1,509,"@Relaxed Gotcha... it seems to be more of a case of, ""this number is PII at such time that we can cross the gap of mapping it to an individual before which it's PII just without a name"" which may be done via inference given enough other points of data associated with it.  To look at it from another point of view, if you send your attorney to contest a photo traffic violation and the company issuing the ticket doesn't have access to associate your face with a name, they can't prove the two are related, but if you show up to court yourself that association is revealed.",Jul 3 at 20:27
41,2,426,"Your first paragraph exactly describes the situation. But then you assume that at some point there will be a mapping between a specific, named individual and the number, which according to WA is not the case. On the other hand - the number is unique to a person, which means that WA knows what user87989 is doing, without knowing that user87989  is actually John Brown. Which, per literal reading of the PII and other answers still means that this is indeed a PII.",Jul 3 at 15:47
41,2,510,"Yes. The definition of PII is intended to be expansive- because it's about privacy. And once permission is given to the app to retrieve contacts information, the fact that the app at this moment in time decides not to retrieve contact name, only number, is immaterial. Once it has permission, it can retrieve name and anything else at any time.",Jul 3 at 15:54
41,2,510,"The other point is- the name a user has entered into their contacts for a given number is often a  nickname or shorthand or something that uniquely characterizes the relationship, but is not authoritative from an identity perspective. There are plenty of services that FB can give a number to and get quantities of authoritative identity data for. So if the assertion that names are not pulled from contacts, only numbers, is made on privacy grounds, well, that's at best deceptive.",Jul 3 at 16:18
41,3,92,"""based on the statement from European law makers"" can you link or quote the law?",Jul 3 at 20:07
41,3,511,@Schroeder I've proposed an edit to add the citation and link to the EU Regulation,Jul 4 at 4:02
41,3,512,ec.europa.eu/info/law/law-topic/data-protection/reform/…,Jul 4 at 10:42
41,3,512,Thanks to the person that took his time editing my post.,Jul 4 at 12:47
41,4,499,How is birth date you have collected from a person NOT personal information?,Jul 5 at 11:15
41,4,513,"@DmitryGrigoryev, I am not implying that, am I?",Jul 5 at 14:56
41,6,508,"A phone number is not intrinsically linked to a person. There is no passport number which doesn't belong to a single person, but there are many phone numbers not linked to a identifiable person.   And if you cite a law, it has to be interpreted in a legal context.",Jul 4 at 12:20
41,6,515,"Removed the citation. But arguing that a phone number is not intrinsically linked to a person sounds the same as the advertisement industry has been doing for cookie-ids and IP-addresses, saying it is not a person. I think the new european laws have the intention to make any data that can re-identify a person personal. I truly believe phone-numbers should fall in the exact same category, that is why I linked to article 4: gdpr-info.eu/art-4-gdpr",Jul 4 at 13:28
41,6,92,"You are trying to fit the situation to the definition. An ""identification number"" is a number used for identification. There is more than enough in Article 4 (and its recitals) to justify phone numbers as being PII, but you do not need to stretch an existing definition to get there.",Jul 4 at 13:34
41,6,515,"Maybe. I might be confusing an ID used for a person and an ID to identify a phone, both are an identifier, but not an ""identification number"" according to you. I am having a hard time finding the definition for ""identification number"", maybe in a English based culture it is very obvious that those words only mean things like EIN or SSN. Reading the Dutch translation and definition of the words still makes we feel a phone number would fit perfectly. It describes any number that can be used to identify people. When my wife calls me I can see it is her (phone number), that meets that definition.",Jul 4 at 14:30
41,6,516,"@NielsvanReijmersdal I can offer my perspective as a native English speaker: ""identification number"" usually means a number created for the purpose of uniquely identifying a person or a thing. There are many things that you could probably use to identify a person that wouldn't typically be called identification numbers. For example, a phone number isn't an identification number because its purpose is to contact a person (or a business or so on), not to identify them.",Jul 5 at 3:24
42,1,517,"There's been excellent information about cookies, here, that I did understand before. Thank you to everyone. If I had a do-over I would have framed my question a little differently, but this answer helps me the most. Thank you, @IMSOP",Jun 19 at 14:46
42,1,517,"""We use cookies to associate your browser with our website."" I like that!",Jun 19 at 14:54
42,2,517,"Yes, this is accurate, but it's not just a box that is open for everything and anything poor into. If the cookie doesn't actually ""request"" data from the client there must, at least, be a gatekeeper to restrict what enters the box (sent back to the server), so to speak. Login credentials, times, referrers, ect.",Jun 19 at 3:56
42,2,518,"""Login credentials, times, referrers"" per se has nothing to do with cookies. The application developer chooses what to store. It is very unusual to store referrers in cookies, but a developer can chose to store whatever.",Jun 19 at 5:33
42,2,79,"@StackNoFlow One use of cookies for analytics is that you can set one with essentially random data, and then if you see the same random data again you know it's the same user. The cookie is neither requesting or collecting data, it's a tool being used to collect data. When I put a sticker in someone's hair saying ""valuable customer"" so I remember they're a valuable customer, is the sticker requesting data or collecting it?",Jun 19 at 5:47
42,2,519,@StackNoFlow does the sticker ask the customer anything? No. It's you who are doing the asking.,Jun 19 at 7:39
42,2,520,"@StackNoFlow Did your browser ask you about all the cookies security.stackexchange set? I have currently 26 cookies set by this site, you probably have the same amount. There's your answer. There's also no ""gatekeeper"" who decides what you can put into cookies.",Jun 19 at 9:58
42,3,517,"Very nice description! And useful..thank you! What I'm trying to determine is do websites ""collect"" or gain ANY information from a client without making some kind of request for that information? Whether it's passive or direct. In short, if I got this right, it sounds like no. Which means the user/client must authorize the data/info transfer, which is typically done by the user either implementing ""Block third party cookies"" or not. So, if a user/client is NOT blocking third party cookies then they are essentially authorizing data ""collection"", the transfer of data/info back to the server.",Jun 18 at 22:37
42,3,79,"@StackNoFlow I highly doubt that your opinion of ""by not turning off this obscure checkbox in their browser they authorized the data collection"" will stand up to GDPR.",Jun 19 at 6:02
42,3,517,"@immibis, I agree. I'm more interested/concerned about the proper, accurate language I'm using in my Privacy Policy. A lot of these responses are pulling me away from that, although I'm still trying to address them. It's also still interesting how cookies and browsers interact.",Jun 19 at 7:09
42,5,499,Just because cookies are under full control of the web browser doesn't mean the OP can assume every user knows that.,Jun 19 at 6:37
42,5,522,Ignorantia non excusat. Judging from the title it seems like OP wants to put blame on servers for using cookies.,Jun 19 at 9:55
42,5,523,"""Servers don't have to do anything"" - that is just plain wrong. The server has to set the cookie, otherwise there would be nothing for the browser to send back.",Jun 19 at 11:50
42,5,522,"Server doesn't set anything, server sends back to the client the cookie and the client can and doesn't have to save it and send it during future requests.",Jun 19 at 11:54
43,1,525,"Worth mentioning for fun and profit that old services (like ICQ) were indeed peer to peer. Also, if you establish a WebRTC connection you will be able to see the IP of the user using system tools since you have a direct connection.",Oct 19 '17 at 15:21
43,1,265,"And even if you get the IP address of the user themselves,  that often won't tell you much reliable info about their location, depending how their ISP/mobile provider routes things.",Oct 19 '17 at 17:19
43,1,221,"Plus, IP geolocation currently places me at 228 km from where I am located. Yeah I know, 228 km is nothing in the USA, but here it's approximately 1/2 across the country...",Oct 19 '17 at 18:47
43,1,526,"All that being said, geolocation, even with its laundry list of issues and caveats is better than nothing, and it is possible to narrow down where someone's accessing the internet from.  Sometimes you're off by a few hundred kilometers, sometimes you can narrow it down to a precise location.",Oct 19 '17 at 22:18
43,1,227,Obligatory article about geolocation problems: splinternews.com/….,Oct 19 '17 at 22:25
43,2,10,"Absolutely, and don't even get me started on proxy/VPN connections...",Oct 20 '17 at 5:31
43,4,529,"Is peer to peer a blunder though?  If I were to phone a landline number, that number is fixed to a location, and a reverse lookup can find me their address.  This might be behaviour that you don't want, but I don't think I would call it a security mistake.  Typically, you would only chat to people you would want to talk to anyway.  Third parties knowing where you are... that would be more of a problem.",Oct 19 '17 at 15:56
43,4,19,@Baldrickk It's a blunder for Facebook - they make their money by knowing lots about you and real-time chat is the perfect opportunity to harvest data.,Oct 19 '17 at 16:08
44,1,531,I'd suggest on top of DuckDuckGo using a well regarded ad blocker (I use u-block origin personally) and a privacy add-on like the EFF's Privicy Badger. This will stop 99% of tracking.,Oct 11 '17 at 11:43
44,1,531,Somewhat As would *.doubleclick.net. An ad blocker would handle all of this for you.,Oct 11 '17 at 12:40
44,1,531,"@ThomasYates - Nope. You can fingerprint browsers by pulling lists of installed fonts, add-ins etc. It works out to be surprisingly unique - have a look at amiunique.org/fp",Oct 11 '17 at 13:47
44,1,56,"@S.L.Barth: This is also known as the ""I love phishing"" option, since constantly having to login to every site you use will condition you as a perfect victim for phishing.",Oct 11 '17 at 19:15
44,1,79,@Hashim Yeah but you get a lot more chances to screw that up.,Oct 11 '17 at 20:55
44,2,531,"They may not know the exact search term. But they know that you came from a search on DuckDuckGo - on a search for ""test"" and clicking the test.com result I see in the request header ""Cookie:DOAAuthReferrer=https%3A//duckduckgo.com/; DO..""",Oct 12 '17 at 8:03
44,2,532,"@Hector true, I'll add that",Oct 12 '17 at 8:04
44,3,533,And how can I prevent this? Because then using DuckDuckGo doesn't even make sense.,Oct 11 '17 at 11:34
44,3,531,See my answer. Using DuckDuckGo helps with sites that don't have advertising arrangements. Ultimately the only way to stop yourself being tracked is to use an ad-on that wipes all local storage on leaving a site and does things like randomise lists of presented fonts/add-ons to confuse fingerprinting attempts.,Oct 11 '17 at 11:37
44,3,534,"Google Analytics tends to be much more privacy-conscious. This is from several years ago, but the cookies it drops off are actually for the non-Google domain. Anything Doubleclick or Adwords related is a different story.",Oct 12 '17 at 5:01
44,3,531,@MooingDuck - not at all. Look up EverCookie - any local storage available to a site an be used to store information to identify you for tracking purposes.,Oct 12 '17 at 7:59
44,3,535,"@P.Yntema Using DuckDuckGo does make sense, because DuckDuckGo doesn't keep track of who you are and what you have been searching for - as Google does.  Just searching for something with Google, may result in customized ads (from Google) later... But more importantly, Google will make a profile over you, containing everything you've searched for.  However using DDG doesn't mean your surfing anonymously - nor does it mean that the sites listed by DDG all will respect your privacy or that they don't contain ads with trackers.",Oct 15 '17 at 18:57
44,4,92,thanks for adding alternates to a specific extension - it sort of looked like an ad for Ghostery,Oct 13 '17 at 13:27
44,4,537,@schroeder Yes thats what I realised and gave alternatives,Oct 13 '17 at 13:48
44,4,538,"Ghostery itself is a tracker.. If not disabled then, among other things, this information is collected: standard web server log information like your web request, the data sent in response to that request, a timestamp for the request, page And this information is always collected: web browser, operating systems, and opt-in settings to share Tracker information with the Company, when an installation, upgrade, or uninstallation occurs, and whether the GBE is active or engaged by you. (VI + VII in the privacy policy)",Oct 14 '17 at 15:42
44,4,539,"Upvoted for good explanation of third-party tracking and how users can protect themselves.  I had been using Ghostery for a couple of years but due to privacy concerns, I switched to the EFF's Privacy Badger. Instead of using a preset list of trackers, it continuously analyses third-party requests to determine whether or not they're tracking you. It's been working well for about 18 months and encouraged me to donate to the EFF.",Oct 16 '17 at 12:24
44,6,531,"IndexedDB is in most major browsers these days and is normally part of a ""clear application data"" option in the clear history checkboxes. Its also not little known - its regularly used by web applications.",Oct 12 '17 at 15:24
45,1,543,"Yes, there is a commercial tool (won't say names) out there that got some attention because they had an option to upload files and attachments to virus total, some companies realized some of their sensitive data was being exposed. I know some companies will just upload and check hashes instead",Aug 18 '17 at 5:16
45,1,66,@nd510: For a more balanced view on the issue you probably refer to see KrebsOnSecurity: Beware of Security by Press Release.,Aug 18 '17 at 6:03
45,1,544,"@SteffenUllrich, it would be good to add this one: support.virustotal.com/hc/en-us/requests/new - in case if someone uploaded something private/personal, there is already pre-generated subject: I have accidentaly uploaded something private",Aug 20 '17 at 6:26
45,1,66,"@Mirsad: good suggestion, I've added it to the answer.",Aug 20 '17 at 6:43
45,1,545,"first check if the hash already exists at VT before uploading a file - if file with same hash is there, then uploading or not will make no difference AFAICT",Aug 21 '17 at 12:52
46,1,546,"Thanks for these links. As feared, what my IP says about me reveals: Host Name:  lastname.university.com",Aug 17 '17 at 7:24
46,1,396,You could try asking the network helpdesk if there's a way to hide your name. You're probably not the only student concerned about privacy.,Aug 17 '17 at 7:31
46,1,546,This is exactly what I am doing.,Aug 17 '17 at 7:42
46,2,547,"I think your answer is correct, but what would be the security/privacy consequences of either option?",Aug 16 '17 at 18:09
46,2,548,"If it's not an RFC 1918 address, your DNS name likely does show up externally - Why?  You can split horizon reverse DNS zones just as easily as you do it for forward zones.",Aug 16 '17 at 23:19
46,2,35,"@Zoredache simply because RFC 1918 implies one-to-many or pool-to-many NAT, either of which would make publicizing reverse data relatively useless.  While it is possible to have one-to-one NAT, and to use split DNS to publish name mappings both inside and outside, in practice that's a highly improbable setup... I'll update the answer to clarify this.",Aug 16 '17 at 23:41
46,2,549,"I think @Zoredache's question was more about the opposite situation: if it's not an RFC1918 address, then you can't assume the name will show up externally - it's easy enough to set up DNS so that internal and external IP-to-hostname lookups get different answers.",Aug 17 '17 at 11:42
46,4,550,"it turns out in this case that it was public, and there was a PTR record with his name.",Aug 17 '17 at 9:56
46,5,546,-1: this doesn't answer my question at all.,Aug 18 '17 at 8:40
47,1,65,"in General I'd agree that VMs are more likely to be secure, due to smaller attack surface, however in regards to point 1. in reality VM escapes don't have to exploit the VM kernel, they tend to attack the device drivers which are provided by the hypervisor and the attack chain can be pretty simple.  E.g would be venom which exploited the floppy disk driver and allowed for VM escape.",Sep 18 '17 at 10:02
47,1,310,"I think #5 is a strange point to be there. Nobody in their right mind would forward their /var/run/docker.sock to untrusted containers, just as nobody in their right mind would route their VM Hypervisor API endpoint to untrusted VMs or run untrusted kernels as Xen dom0. Being able to run management applications within VMs are features that can be done with VM as well. Software is not a fix for idiocy, is what I'm saying.",Sep 18 '17 at 16:50
47,1,552,"One of these days people will learn... there is no magic bullet for security. VMs, containers, microservices, monoliths, firewalls, air gaps, flux capacitors, doesn't matter. You need to continue to make smart, security conscious decisions no matter what you are working with. The greatest firewalls in the world can be undone with a single post-it note on a monitor, or a stupid help desk employee empathizing with a crying baby in the background. There is no sorcery that makes one technology more secure than another. So let's get back to being smart, security conscious people, eh?",Sep 18 '17 at 18:54
47,1,553,@LieRyan: Lost of people in this industry aren't in their right mind,Sep 18 '17 at 19:04
47,1,553,"@corsiKa: They won't learn because they WANT to believe in it, and Security Companies will ALWAYS claim to offer it.",Sep 18 '17 at 19:06
47,2,554,Nice balanced answer.  One thing I would add is that the one major advantage of standard containerization is that you only run one thing.  You don't need to worry about things like whether ssh is running and whether it's configured right.,Sep 18 '17 at 17:32
47,2,555,Docker doesn't emulate or virtualize the kernel. Containers are implemented by the kernel itself. Docker is a tool for configuring and managing them.,Sep 21 '17 at 16:48
47,2,310,"@AndréParamés: Good catch, I've edited the answer to be more precise on how the actual containerization itself is done in the kernel. Do you think it's good enough?",Sep 22 '17 at 3:28
47,2,555,"@LieRyan much better, thanks!",Sep 22 '17 at 6:07
47,2,556,It's well known that VMs provide better isolation having a smaller attack surface. Claiming that VMs are generally more secure is not on oversemplification.,Apr 5 at 13:08
47,3,557,"Also a docker container can access to the Host, just a bad container configuration can put your environment in a big trouble.",Sep 18 '17 at 0:56
47,3,456,"I am a Linux fan and see chroot as something that provides cosmetic isolation but is so steeped in ancient Unix lore, with so many obscure gotchas, that it can not be trusted in any way at all. Is Docker really that bad?",Sep 18 '17 at 8:10
47,3,558,"docker is based on lxc containers, a modern reinvention of tbe old unix chroot. so its up to you.",Sep 18 '17 at 8:12
47,3,559,"@BaileyS no, chroot is just a basic comparison, Docker is actually much more sophisticated than a simple chroot (which hs no resource limits, for example) See: LXC for the actual technology used",Sep 18 '17 at 13:23
47,3,560,"@Bailey S chroot is a very simplified way of looking at Docker. The actual functions Docker uses includes cgroups, namespaces, and OverlayFS. Recent versions make use of libcontainer with libvirt, and LXC.",Sep 18 '17 at 16:38
47,4,449,"It's a sensible real-world answer. Anyone who has ever been compromised knows that there is an unnerving hour (or a day... or a week...) between the ""aha, I know how to automatically detect we've been hacked"" and the ""aha, I devised a workaround that blocks this particular attack, so we can run the service while we analyze the root cause to find a vulnerability"".",Sep 24 '17 at 21:17
47,4,561,"I'd add that because Docker containers are lightweight, they're also more likely to be used in practice than VMs. And, of course, they're often used on top of VMs as an additional layer (if you're running Docker containers on AWS, for example).",Sep 25 '17 at 9:00
47,4,562,"Huh? Thats really weird way to look at it.Yes, boss, all our data has been leaked/deleted/vhatever, but hey i can spin up a new docker with clean code.",Sep 27 '17 at 8:40
47,4,283,"@SandorMarton Security is not just protecting against data leaks. It’s also about preventing incursion, limiting damage and figuring out how to recover while keeping systems up and running. If data is lost it is usually due to bad application architecture and a failure to patch. In a case like that Docker, VMs or bare metal cannot save your ass.",Sep 27 '17 at 13:42
47,4,562,"Yes, but you aren't preventing incursion by redeploying a new docker with clean code. I mean that clean code was compromised somehow. My problem with your answer, that most of the less experienced users will conclude that docker is best for security, since you can quickly redeploy clean code. Redeploying clean code doesn't resolve anything.",Sep 28 '17 at 20:34
47,6,555,"The second point is not always true anymore, thanks to user namespaces. You can map the root user inside the container to a regular user outside.",Sep 21 '17 at 16:57
48,1,566,"just make sure you don't share folders or drives between the host and the VM - or if you really have to, just use it as a temporary folder (copy in and move out)",Jun 21 '17 at 10:57
48,1,567,Using email in VM and document work in the host without file sharing seems highly impractical.,Jun 21 '17 at 11:16
48,1,425,"@zakinster and security at cost of usability often costs security? Something like that, as far as I remember.",Jun 21 '17 at 13:24
48,1,71,Are you sure you mean phishing in the second paragraph? Phishing is a social engineering attack. This is one of the threats where a virtual machine isn't offering much protection.,Jun 22 '17 at 12:24
48,1,568,"@Philipp if the phishing attack convinces you to download a dodgy file that then attempts to hold your system for ransom, it will end up holding the guest VM hostage rather than the host VM. If you sign into a fake site though and enter your bank credentials, it won't help against that ;)",Jun 22 '17 at 18:59
48,2,569,"Thanks so much guys- I just took a look at qubes and I really think that may work for me. My issue is when I'm hunting for small business leads I usually end up getting tangled up in adware, especially when I'm mentally fatigued. So I'm really just looking for a way to separate browsing from everything else as seamlessly as possible. Thanks again great suggestions",Jun 21 '17 at 5:53
48,2,570,"Suggestion for your last point on backups - make sure you setup a PULL backup on a system that runs headless by itself, and that your main computer cannot access without you initiating an action - an SSH key, or a password.",Jun 21 '17 at 16:29
48,3,499,"If you're afraid a malicious PDF could compromise your reader, why do you think it's safe to open with a browser?",Jun 21 '17 at 8:54
48,3,572,"Good point. Exploits are usually software specific. If the browser's PDF reader is targeted, the approach won't work. Yet, if Chrome (and other browsers) implement their sandboxing well, there is still that extra layer.",Jun 21 '17 at 9:11
48,3,499,"FYI, PDF readers use sandboxing as well.",Jun 21 '17 at 10:07
48,3,456,@DmitryGrigoryev Adobe Reader has a longstanding and well earned reputation of being highly insecure with little apparent concern from Adobe. Chrome contains a hardened PDF reader in a sandbox environment that is well regarded. Many online cloud services actually display PDFs converted to images as well.,Jun 22 '17 at 22:16
48,3,456,"@DmitryGrigoryev I actually do think that Adobe has cleaned up their act with respect to security significantly in recent years, and trust their products much more now. The better updater for Reader was a huge step. Chrome is a very popular piece of software as well with a more venerable and proven sandbox environment.",Jun 23 '17 at 23:55
48,5,92,this looks like a summary of all the other answers,Jun 22 '17 at 21:17
48,5,574,"Thank you for your previous comment @schroeder. I'd agree except none of the previous answers mentioned macros, VM encryption, exclusive storage and manipulation of documents in a VM and, especially, that data/business-sensitive risks may directly come from clients.",Jun 22 '17 at 22:29
48,6,203,"I feel like this is not really answering the specific situation mentioned in the question.  As the question says ""I run a small business out of my home..."", ""I just bought a cheap laptop..."", etc.  Somehow I think suggesting enterprise-level solutions, with multiple servers for physical redundancy, isn't really tailored to this particular question.",Jun 23 '17 at 0:26
48,6,575,Haha and of course a 2 drives in Raid 1 + a backup per machine :),Jun 23 '17 at 1:25
49,2,578,I saw the clean MEMZ run in the VM without harming host computer. Is clean MEMZ safe in VM? But I also saw destructive MEMZ in VM. They then showed their host computer and it was fine. Can someone at least post destructive MEMZ code just to make sure? I don't want to take risk of downloading,May 17 '17 at 14:25
49,3,92,"WannaCry: except an old, unpatched XP version on the VM ...",Jan 16 at 16:09
49,5,92,"Why is it ""safe""? Do you have any references? How do you counter all the other answers saying that it is not safe?",May 22 '17 at 6:24
49,5,582,As most VM share some network with the host. NAT or Bridge well your are not probably safe !,May 24 '17 at 22:27
50,1,584,"We use and recommend an approach using what we call PAWs (privileged access workstations) or SAWs (secure access workstations.)  Users who need access to prod have one workstation/laptop for daily use and work, and a second locked down workstation/laptop for production access.",Aug 30 '16 at 17:21
50,1,585,"@Xander - so you're a real life example of this ""rare in practice"" approach. Good on you! Can I ask what sector you're in? I've mostly seen this in government suppliers and aerospace.",Aug 30 '16 at 18:45
50,1,584,"@paj28 I work for Microsoft.  And yes, not only do we teach it, but we've fully implemented it here as well.  :-)",Aug 30 '16 at 18:51
50,1,586,I wonder.  What if the development work is performed by the same people as the sysadmin work (another common scenario in startups).  I guess every developer should get one PAW and one SAW.,Aug 31 '16 at 2:18
50,1,587,"@JonathanPullano: There is no practical way to prevent a determined developer from walking off with the source code.   You would have to cut all internet access and even perform x-ray body searches ( in and out) to prevent drives being smuggled through.  You'd have to disallow all printing - and watch the trash bins, etc.  Next, you'd need to ban all ways of taking pictures; which means no phones, cameras, etc while also using video cameras to actively monitor what everyone is doing.    This would create an environment that few developers would be willing to work in.",Sep 2 '16 at 20:56
50,2,484,"Sorry, but you can't have ""Some level of admin access to the production servers"".  The best I'll let you have is you get on a WebEx (etc.) with me or shoulder-surf at my desk, and you tell me what you want, then I give it to you.  Developers don't get to touch QA or production servers. You give us admins the code, we deploy to QA, then let the testers beat hell out of it before doing a production change.  If I let a dev touch one of my QA or Prod servers, he's likely to make undocumented changes I can't replicate.",Aug 31 '16 at 17:00
50,2,484,"The reason why this extends to QA is that the QA environment must mirror the Prod environment as closely as possible, so that any hard-coded ASS|U|ME-tions that work fine in Dev but will break in Prod will first break in QA so that I can tell you to fix that mess and try again before it ever gets to Prod..",Aug 31 '16 at 17:04
50,2,552,"Monty's philosophy is key to keeping a pristine production environment. The key word he used was ""replicate"" - often times, devs (I know devs: I was afflicted with development for over ten years and am slowly being treated for the condition, though I occasionally relapse) will find it's broken and fix it. Yay they fixed it! But how did you fix it? What else did you break? Nuh-uh. Getting back up ASAP will cost us more than getting us back up with a defined change plan. Admittedly, these practices are only tangentially related to ""security"" but they're still very important.",Aug 31 '16 at 18:46
50,2,484,"@corsiKa I can argue that separation of roles is a security matter. Just because the developer isn't a malicious attacker doesn't mean he can't do damage to my production servers on the same (or worse) scale as that attacker.  The central point is that it enforces a true knowledge transfer from dev to admin. He can't ""just know what to do""; he has to document it in writing so that any member of my team will be able to read ""what to do"".",Aug 31 '16 at 20:52
50,2,588,"I believe the PCI-DSS spec says that devs don't get access to production.  We had a separate team that accessed production and committed changes back into the code base.  If you are in a PCI-DSS environment (processing credit cards payments, for ex), you would probably not get prod access.",Sep 1 '16 at 11:52
50,3,92,"Except it's the Business that defines your role and restricts your tools according to their needs and goals. If they want you to use pen and paper, then that's their call.",Sep 1 '16 at 6:25
50,3,590,"@schroeder - and if you want to find another job, then that's your call.",Sep 1 '16 at 10:33
50,3,227,"@schroeder True. Businesses are entitled to be as stupid as they want, but stupid businesses shouldn't expect anything but stupid developers and a lot of broken software.",Sep 1 '16 at 23:24
50,3,591,"If a stolen laptop is a concern, shouldn't the disk be encrypted?",Sep 3 '16 at 1:08
50,3,132,"@Andy yes, disk encryption is absolutely another good sensible measure.",Sep 5 '16 at 3:29
50,4,586,"I need to say that I really like the idea of providing training instead of locking computers.  Good developers are interested in technology, and a good training in how security threats may affect their machines may just be just the right thing to catch their interest.  The tricky part is how to construct this training, it certainly cannot be the same training as the one provided to other parts of the company.",Aug 31 '16 at 1:12
50,4,592,Do you have a citation for your Riot Games comment? I suspect itll be in their engineering blog,Aug 31 '16 at 11:15
50,4,593,"Signed binaries for containers? Haha, I wonder how many people are doing that in practice. I bet most containers involve downloading a shell script from a random third party website over plaintext HTTP to setup some kind of new-fangled node.js mess.",Aug 31 '16 at 11:22
50,4,116,@DanPantry part of the talk they gave at Brucon,Aug 31 '16 at 13:02
50,4,227,"@MattiVirkkunen Better yet, copy/pasting from SO.",Sep 1 '16 at 23:20
50,5,586,"I wish more people had so much confidence in their developers, since confidence is a two sided relation.  Of course, that requires a very good hiring process, you simply cannot afford to hire incompetent developer.  Then again, you should always aim to hire only competent developers.",Sep 1 '16 at 22:11
50,7,595,"""nothing wrong with whitelisting every technology source related to your development effort""... You'd spend all your time appending websites to the whitelist, until the dev decides to find a place where there's less friction.",Aug 31 '16 at 14:19
50,7,484,"Give your rockstar a separate admin account to be used solely to administer his workstation.  That way it's isolated from the account he uses to browse SE (and God knows what other sites, some of which might carry malware).",Aug 31 '16 at 17:06
50,7,596,"@LucasTrzesniewski  - If a developer can't be bothered to document the sources of their code, I'm happy to see them go.   The good developers I've worked with tend to prefer to know that their peers aren't pulling in stuff from random git repos with dubious histories and unposted licenses.  BTW, I am talking about development platforms here, not their workstation.",Aug 31 '16 at 21:01
50,7,595,"That being said, developers tend to use a lot of libraries for any non-trivial project, and (that's important) they have to try even more libraries before choosing the ones they'll be using in the end. I'm all for having clearly defined and reviewed code dependencies, but access to development resources on a case by case basis would be a major PITA and an impediment to the development cycle.",Aug 31 '16 at 23:46
50,7,227,"""developers usually don't use GUI access to those machines"" This only applies in the Linux world.",Sep 2 '16 at 0:03
50,8,586,"And let's not even start on how zero-trust networks are important when IoT devices are around.  That ""mug that tweets"" is often so badly constructed that it breaks any sensible security measures.  I just wonder how the user and device information will be managed to give access to a system.  Passive fingerprinting (akin of openBSD's PF maybe?)",Sep 2 '16 at 16:01
50,8,60,"Yes, IoT is a concern and is certainly something which will spped up the move to zero-trust networks. The challenge is user authentication - how do we make it both usable and secure and avoid 'honey pots' of valuable data. Some sort of bio-metric input almost certain. Authn is the holy grail for ICT in the same way power storage is for solar energy. Once we crack those nuts, a lot will change.",Sep 4 '16 at 1:14
50,9,139,"This is clearly a ""letter of the law"" solution designed to bamboozle idiot rules makers.  Good news is you can get work done, bad news is that if the idiots acquire a clue, someone gets fired.",Sep 1 '16 at 3:33
50,9,588,"I had a job briefly where you had no admin access to your computer at all.  To get any software installed, you had to put in a ticket, hope it was on their approved list, or justify it in some fashion if it wasn't, and then wait for their security team to remotely log on and install it for you.",Sep 1 '16 at 11:57
50,9,497,I heard believable rumors of an environment where the standard procedure in devops was to immediately buy more RAM and then P2V the original system image within itself. The inner machine only gets used for company email; everything else is on the outer machine. They ran cables between the cubicles for their own LAN.,Sep 2 '16 at 21:43
50,10,586,"It was a lot of effort to write that (+1 for effort), but I need to argue that you're lucky that I'm fluent in portuguese.  I saw this kind of concordance mistakes over and over, I probably fixed most of them.  The answer starts pretty well but then goes downhill with the source code stuff, and then improves a little at the end.  Yet, most importantly, you forgot the main issue why people use company provided computers: what if a developer gets a trojan?  10.1, 10.2, 10.3 subnets will certainly not protect you from a competent attacker in that scenario.",Sep 22 '16 at 2:11
50,10,598,"Thanks grochmal. That happens in portuguese too, my first drafts tend to be a little confusing in some parts because I write them too fast. Thanks for the edit.",Sep 22 '16 at 8:46
50,10,598,The network separation is to have exacly the same configurations in both networks except for the second number of the IP. Predictability allows better firewall rules and better scripts to move things arround. Sort helps against trojans in the test and production networks if combined with linux servers and policies to avoid external components.,Sep 22 '16 at 8:49
50,10,598,"A trojan is not a developement specific risk, if the developer has the access to screens of your application a trojan will have that. Same as any other user. To mitigate the risk of trojans I personally make my component prospection inside a VM.",Sep 22 '16 at 9:07
50,11,592,"Holy crap, those employer rules are crazy.",Sep 2 '16 at 19:35
50,11,599,"@Dan Pantry Yeah, no kidding...I wish I could say it's because I work someplace cool like the NSA but no, we're just on the rusty edge of innovation.",Sep 4 '16 at 14:14
51,1,601,"Thanks for your reply.  - What does ""disabling incoming networks"" mean in this case? I should connect to one of them at least for doing home banking..  - I'm running Whonix (Linux) on VM and it recognizes both the physical keyboard and the virtual one ""on screen"" (I mean that one provided by windows on tablet and phones): is the latter safer than the physical keyboard? In other terms, if I use the keyboard on screen only when I'm on VM could I avoid to run the risk of being intercepted by a keylogger?",Jan 12 '16 at 10:19
51,1,310,"@Locutus: ""regular channels will be blocked"" you can't be any more false. If you run your virtual machine hypervisor as your own user, which means your user account have a write access to the entire virtual disk, a virus could insert itself into the virtual disk image without being admin/root in either the host nor the guest VM.",Jan 12 '16 at 13:15
51,1,601,"@LieRyan what about using Whonix instead than a generic operative system running on VM? Could a virus be dangerous that way?  (quoted from Whonix documentation: ""DNS leaks are impossible, and not even malware with root privileges can find out the user's real IP. "")",Jan 12 '16 at 15:21
51,1,310,"@robertalrp: VM-based solutions like Whonix protects you in the scenario where you don't want personal data/metadata in your host operating system to be stolen by applications running in the secured guest environment. Whonix does not have any magic that will allow it to run securely when the host operating system is compromised. Running the banking website inside the secured environment isn't the right approach for your use case; if your bank is trying to illicitly steal your personal data, you probably shouldn't put your money with them.",Jan 12 '16 at 15:33
51,1,310,"@robertalrp: what you want is to secure your trusted banking applications from the potentially malicious daily browser. What this means is that you want to move your daily browser into the secured environment, not your trusted banking application. You can either run the trusted banking application in the host or in its own separate environment and use the VM host as dedicated hypervisor.",Jan 12 '16 at 15:37
51,2,603,Where should the vpn be terminated?,Jan 12 '16 at 4:58
51,2,601,"Ok, tank you. So isn't https encryption sufficient to prevent the attacks you mentioned?",Jan 12 '16 at 10:34
51,2,604,@RolfRander You could terminate the VPN at your own VPN server at home or use a VPN provider like openvpn.net.,Jan 12 '16 at 11:45
51,2,603,So data would be transmitted through a VPN to a VPN-provider and from the VPN-provider to my bank over internet (hopefully using https). How does that make me safer than communicating with the bank directly?,Jan 12 '16 at 11:47
51,2,604,"Https should be sufficient if and only if it's the only protocol your bank is using which is not always the case. Also you should be using DNSSec for resolving your bank hostnames. If you don't use a VPN you're trusting your bank to handle the encryption well.  Generally it's best practice to use a VPN when connected to a public network. Once your VPN is established DNS spoofing isn’t possible anymore and if an attacker would use ARP spoofing to become the default gateway, they couldn't read the traffic passing through them.",Jan 12 '16 at 12:12
51,3,281,"I think it depends how the Windows host gets infected. For example, the VM will be protected from browser plugins/addins on the guest OS.",Jan 11 '16 at 23:16
51,3,601,"@Natanael: yes, actually my first solution was doing home banking within a live distro booting from an usb stick, but as I wrote I cannot (because of a hardware incompatibility with my wireless adapter, moreover an additional problem is the impossibility to install the drivers I need without an internet connection, and/or to install them permanently on the system. Actually I'm also looking for external adapters to solve the problem, meanwhile I need a temporary solution)",Jan 12 '16 at 9:56
51,4,281,"I'm not really sure that you answer the question. The OP states that they need internet connection via the ""e-commerce"" tag. They are worried about malware installed on their computer, something that none of your plugins will help with.",Jan 11 '16 at 23:14
51,4,606,"I agree, it won't help much if the computer is infected, but will increase security during everyday web access.",Jan 12 '16 at 8:20
51,5,310,"I don't VPN would add anything but latency in this particular use case. As long as your bank use HTTPS encryption, and most banks would use EV certificate, and you verify their certificate, a VPN would add nothing much. VPN is good for keeping privacy of who you are visiting, and keeping the website operator from knowing who you are; the bank already hold much personal information from you, and you already advertises who you bank with every time you make card purchases.",Jan 12 '16 at 0:05
51,5,281,"@LieRyan - I think mk444 is referencing this answer which says to use VPNs when using public (ie: insecure) networks. A VPN will add security in that specific situation. Though if you are specifically accessing your bank over HTTPS and you confirm that the browser approves the cert, you should be OK accessing your bank via a public network.",Jan 12 '16 at 3:47
51,5,601,"Do banks and sites like Paypal let users connecting through VPN? Many of them do not let access within Tor because of security measures, isn't the same while using VPN?",Jan 12 '16 at 9:25
51,5,607,@robertalrp Yes and I doubt they'd have any idea that you're connecting via a VPN. I'm not sure how they would detect it.,Jan 12 '16 at 9:29
51,5,607,"@robertalrp This is a difficult area. It's always best to read the ""Terms of Service"" very carefully before choosing a VPN provider and ensure the provider does not keep any logs.",Jan 12 '16 at 9:59
52,3,610,"NAT,BRIDGED .... please, make explanations of terminology too. thanks",Jan 2 '17 at 19:53
52,4,497,?!? And if the hostile application caries its own copy of vmware tools?,Apr 30 '14 at 17:23
52,1,296,"To emphasize Peter's point on maintenance with some personal experience: it is already hard to work on old code or code that somebody else wrote. Adding a foreign language to the mix would be nightmarish. Doubly so if comments aren't in English. If your staff speaks a language besides English, OK, then do whatever you want. Otherwise, I'd give the idea a hard ""No"".",Apr 30 at 19:14
52,1,401,"It's a common misconception that security through obscurity is a ""bad idea"" per se but that is not correct. What's a bad idea is to rely on security through obscurity. If you're following best practices elsewhere then it can be fine as an added component to defence in depth. Often such tactics are useless at worst and marginally useful at best. A good example is running SSH on a non-default port. (I'm not saying that the OP's example is justified however).",Apr 30 at 23:18
52,1,402,"""The enemy knows the system.""",May 1 at 8:52
52,1,403,"I feel you're downplaying the last two points. Obscurity of this sort will make it harder for others to spot weaknesses in the system, no? Seems to me we can expect security to be actively weakened by this practice.",May 1 at 13:37
52,1,296,"@dandavis Fixing vulnerabilities is an important part of the software lifecycle. Anything that complicates that process is generally bad, and this is especially true for zero-days. If you slow the development process, you extend the window of zero-day vulnerability. I don't see a significant improvement from such an approach. Plus, just because your programmers are unfamiliar with a language doesn't mean your adversaries are too. I would assume there are adversaries fluent in any given language, which is actually a handicap if your programmers are not.",May 1 at 15:15
52,3,405,"To add, people can reverse engineer code from machine code. People have figured out how to hack complicated games by just looking at how their memory changes when they do actions. And that's without how the front end of the web forces you to give actual source code (even minimized, that's considerably higher level, and thus patterns are more evident). There's also anti-obfusification tools that try to somewhat undo some of the trickier obfusification techniques (and of course, code formatters also help).",May 1 at 22:30
52,3,406,"While this is correct in the case of Java / JavaScript, there are also some programming languages that use a non-English language for their built-in functionality. Though the obscurity of those languages may be more relevant to security than their function names.",May 3 at 6:43
52,3,76,"Not just reverse engineer games from runtime analysis, but even create completely working source code that compiles into exactly equivalent bytecode, turning a closed source game into a multiplatform game!",May 5 at 7:29
52,4,76,"It wouldn't be more secure, especially as reverse engineers (for example) often don't even have the original symbol names to work with, so are already used to working with completely made-up names or identifiers.",May 1 at 5:50
52,4,25,"We are talking about a REST, i.e. a web application. An attacker is far more likely to analyse the web interaction than the Java bytecode.",May 1 at 6:00
52,4,76,"My point is that reverse engineers are already used to this kind of thing, even if they're not doing actual decompilation. I wrote an answer to that effect, with C reverse engineering merely as an example.",May 1 at 6:01
52,4,408,"Naming things after their opposites would be more likely to introduce bugs than naming in a foreign language. ""And then, we call create_user and... Wait, why does it keep saying 'account does not exist'? Of course it doesn't exist -- that's why I'm trying to create it!"" But +1 for your more general point.",May 1 at 12:40
52,4,25,"Of course it's a silly idea and I don't recommend it. But from a purely security perspective, it would be more secure. :-) (not every secure idea is a good idea)",May 1 at 20:51
52,5,409,"Sure, I never intended to use language as a security measure. I was just curious about the community's thoughts on the matter.",May 1 at 22:24
52,5,410,This. Either your application is secure or it isn't. The language you use for naming parameters has zero effect on making it more secure.,May 2 at 12:59
52,6,92,"Your comparison has severe problems. Navajo was extremely rare and not a written language. The OP could simply be asking about a common language in his/her geographic location (i.e. the available dev talent pool speaks it). Also, translations could also be maintained on the dev end.",May 1 at 14:21
52,6,411,"@schroeder My choice of an oral language was perhaps poor, but the historical aspect made for an interesting analogy.  I carefully read the question for any hint about the developers' language, but even then there are major business aspects in terms of future out- or even in-sourcing. e.g. take the stereotypical case of outsourcing to India, and use Hindi.  Then when the bosses decide to bring the maintenance in house for political reasons you have to find fluent developers.  I did say it was extreme, to make a point",May 1 at 14:38
52,10,408,This is just rules-lawyering. The scheme would so obviously be pointless if the language chosen was the one spoken by most of the users that we can be sure the asker meant to exclude that.,May 1 at 12:46
52,10,415,"Yes, but presumably there are not many scenarios where the dev team can be relied on to always know the same non-English language and the community that uses the application don't know that language.",May 3 at 9:38
52,10,416,"Actually there are plenty of bilingual communities and markets. A lot of developers for the italian market are in Albania, so they can make the development in a different language. Same for developing in Hindu for an english speaking app, etc. All I wanted to point out is that the language of the users/targets will play a roll on how much ""security"" this factor can provide.",May 3 at 14:23
53,1,613,"Captchas will only help in preventing users of the app to not rapidly/accidentally submit multiple post requests and not help in any way from preventing someone from sending POST requests from external tools such as fiddler, for example (once they are able to intercept the token).  Right?",Nov 13 '17 at 17:25
53,1,531,@ska-dev No - you can either require one captcha per request for certain request types (either server side  or using the captcha to give a request token to the client which is required on the restricted request) or you can integrate it with rate limiting - I.e a captcha is required to remove limiting after 5 posts in 10 minutes. For services with radically different user usage you can integrate an average request rate for the user to reduce false positives.,Nov 13 '17 at 20:29
53,1,614,Captchas are being broken as we speak.,Nov 14 '17 at 15:55
53,1,531,@Worse_Username - They are also continually evolving. Old captcha systems are basically useless. Modern versions of advanced captchas like reCAPTCHA are fairly reliable. For example in this recent paper - cs.columbia.edu/~polakis/papers/sivakorn_eurosp16.pdf - whilst they had a >70% success rate it took an average of 19.2 seconds to defeat. At that speed automated attacks will post no faster than a human could.,Nov 14 '17 at 16:05
53,1,614,@Hector unless they increase the throughput through parallelization.,Nov 14 '17 at 16:07
53,2,552,And certainly nothing stops them from using an emulator to run the app and capture it on the computer...,Nov 13 '17 at 19:40
53,2,615,I don't know for iOS but it's very easy on Android. The Packet Capture app on the play store can do it without root.,Nov 13 '17 at 21:00
53,2,616,"@GrekKo On iOS, you can mess with the proxy settings and install the mitmproxy CA cert. If the app has app transport security, a jailbreak tweak can fix that. If there is jailbreak detection...you get the point. It's not your computer anymore. :P",Nov 14 '17 at 7:51
53,2,531,@AndrewSun - assuming they are even actually using the app at all. Users can easily enough decompile it and look at what it does.,Nov 14 '17 at 11:15
53,3,618,"You could add a requirement for proof of work, but that does slow down legitimate users and you still need to receive and check the messages.",Nov 15 '17 at 7:07
53,4,613,Yes I have it set up with expiration time that is verified on server side.  As in JWT.   Thank for that second part of your answer that was my main concern with this question.,Nov 13 '17 at 18:46
53,4,620,Shortening the token lifetime won't get you closer to your goals. Nothing prevents the malicious user to scrape your token service too and generate tokens from his bot.,Nov 14 '17 at 11:57
53,4,621,The bot script could re-authenticate automatically when the token expires.,Nov 14 '17 at 17:54
53,8,626,Re: your salting scheme attack. I've seen a similar approach of hooking the random functions so they always return 0. This way you can identify the segments of a key that are random.,Nov 15 '17 at 13:18
53,10,531,Authenticating every request with a password makes no difference. This can be automated on every request. Storing the password in the client and re-sending is identical to storing a session token - except requires hashing the password on every request which is expensive for the server.,Nov 13 '17 at 20:34
54,1,629,This is incorrect. Have a look at my answer.,Mar 22 '17 at 0:51
54,1,362,"@Tim if the app is available in the store and is able to talk to the service, people can download the app, observe its network traffic, and mimic whatever it does (such as authenticating) in their own client. Justin has it quite correct.",Mar 22 '17 at 0:59
54,1,629,"I guess this is the right answer to the question asked. I don't think the question asked is quite the right question. You usually want to restrict access to information, rather than the access method.",Mar 22 '17 at 1:16
54,1,354,"If Google offered the service, wouldn't it be possible for the app to use the google account to provide a token to the server that the server could verify with Google?",Mar 22 '17 at 16:01
54,2,631,"But, will Fiddler be able to intercept the traffic if I have just an Android app, and not a web app? I didn't find any app like Fiddler for Android, and I don't know if setting it up on PC as a proxy in my local network would work. Also, I could hardcode server certificate in my android app. And what about SOAP WS-Security?",Mar 22 '17 at 0:36
54,2,632,Yes it can. Check out my first link.,Mar 22 '17 at 0:48
54,2,633,@AnaMandic So many ways to do it. With fiddler no less. There are more options if we don't restrict ourselves to fiddler. I could put the Android phone on a hub/forwarding switch/router. I could put the Android on a VM. I could replace the JVM https module to send clear text. etc etc,Mar 22 '17 at 5:19
54,7,637,"""An attacker could still reverse-engineer your client to extract the shared secret"" = ""No, this can't be done"", NOT ""yes, this can be done"".",Mar 22 '17 at 9:55
54,7,638,"Reverse-engineering requires higher skills, but there are many people with the required skills out there. And if ONE of your users does the job, they can spread the knowledge to everyone else.",Mar 22 '17 at 11:15
54,7,25,"@OlegV.Volkov - I stand by ""yes"". You can make the process of extracting the secret reasonably complex, definitely enough to thwart most attackers. It all depends on your threat model, of course. But from the information given, it doesn't seem the questioner is up against government entities. It's a solid, commonly used approach with reasonable effort that provides adequate protection against most threats.",Mar 22 '17 at 12:28
54,7,25,"@StigHemmer - knowledge does not magically spread. Even if someone successfully reverse-engineered the app, someone looking to write his own client is not guaranteed to find that information. Other than cracked software, this kind of data will not be on a well-known torrent site. It will stop most people from implementing their own client, it will not stop the most dedicated attacker, but then again, if you're up against the NSA or the Chinese Mafia, you need better security advise than stackexchange. :-)",Mar 22 '17 at 12:29
54,7,639,"@Tom, im am a decent Java Developer and that is the core knowledge which is needed to Develop a Android Application. And with the given Tools (Android Studio from Google/IntelliJ ) I can take the App, put it into my IDE and have fun to read every line you try to do in cleartext.",Mar 22 '17 at 13:32
54,8,640,"This is not a solution. If anyone has a username and password for the original app, they could easily use them to make their own client app - which is exactly what the OP is trying to avoid.",Mar 22 '17 at 6:35
55,1,642,"While I do acknowledge the legitimacy of 'security by obscurity' as a barrier to entry (i.e. kicking out script kiddies), I think it's so widely overused that it's severely detrimental to the actual application's security. Of the two related fields - cryptography and information security - one relies on 'obscurity', while the other does not. Incidentally, the one that does gets pwned easier most of the time. Furthermore, obscurity applies to all parties (including pentesters that you pay) and introduces further complexity, ergo attack vectors.",Feb 10 '17 at 15:31
55,1,643,"@K.Steff ""cryptography relies on obscurity""? Did you mean to write ""steganography""?",Feb 11 '17 at 21:26
55,1,54,"@K.Steff   Every government that uses classified cryptographic algorithms uses ""security by obscurity"" in cryptography.",Feb 12 '17 at 2:11
55,1,10,+1 for the mention of developers. When I make a change to a system and suddenly get a 404 where I previously got a 200 suddenly I have a game of whack-a-mole identifying where the decision was made to send a different response. All I can say to OP is if you decide to do this please please please document it properly or your name will be mud some time in the future,Feb 12 '17 at 19:16
55,1,552,"I think this is a very practical answer. It makes me angry when someone puts down security by obscurity because they read that it was bad on a blog or something. In the real world, it definitely can be useful. It just can't be the only trick in your bag, that's all.",Feb 13 '17 at 1:01
55,2,644,"Harsh, but just. I like it :) . It puts the nature of the weakness into perspective.",Feb 8 '17 at 18:37
55,2,645,"This question is about a scenario where security by obscurity is the only possibility. Your first paragraph is good, but your second one is irrelevant.",Feb 8 '17 at 22:09
55,2,646,"@Nacht how is the second one irrelevant? It's very relevant. He's saying that if you're going to use security through obscurity, it better be damn good obscurity. He's saying this particular defence isn't going to slow anyone sophisticated down by very much at all",Feb 9 '17 at 14:28
55,2,645,"@Cruncher, no, security by obscurity is never going to slow anyone down hundreds of years. He's saying you need ""proper"" security, which is impossible with the OP's current design.",Feb 9 '17 at 22:30
55,2,54,"""When designing a system like this, you should be thinking about slowing down an attacker by hundreds of years, not tens of minutes - otherwise you're still going to lose."" Against a dedicated, determined, skilled attacker? Yes. But to defeat automated attack programs or human attackers just looking for the easiest & most vulnerable targets to take advantage of?  No. They will likely move right along. And that, BTW, will in turn often provide you with better visibility to spot more intent threats as they face defeating the best ""real"" security measures you have the ability to deploy.",Feb 12 '17 at 2:34
55,3,497,A long time ago I wrote some code that launches an attack on anybody who tries this kind of thing. I ended up learning it's not the wisest of ideas. Far more sane might be bad request -> IP banned for 100 hours at the firewall level.,Feb 11 '17 at 5:26
55,4,646,I'm confused though. Everyone is saying that OP needs real security and NOBODY has mentioned how to do that yet. The problem is they don't want the end point to be called unless an ad was watched. How do they accomplish this?,Feb 10 '17 at 11:31
55,4,647,"That is an entirely different question from the original one, and also still difficult.  You would need some server side mechanism to determine if the user has really and truly watched the ad.  Maybe you send a digitally signed token which includes the timestamp when the request for the ad was received, and length of the advertisement.  Then, that token would have to be resubmitted and validated when the user wants to request the protected endpoint.  I would research DRM solutions. Rolling this one on your own without cryptography experience would be difficult to do securely..",Feb 10 '17 at 22:49
55,5,648,The obscurity of the phrase security through obscurity refers specifically to obscurity of the design of the system as opposed to key material. It's a way of referring to Kerchov's principle.,Feb 9 '17 at 12:20
55,5,408,"Your claim that ""security by obscurity"" isn't a useful concept isn't really valid. I guess your point is that having, e.g., a secret key is just security by keeping the key obscure. However, if I find out your secret key, you can just replace it with a new key, get back up and running and try to be more careful with your new key. If I find out your secret algorithm, then you have to build a whole new system, which is much more work. Also, you can give much better bounds on how long it will take me to figure out your key, versus how long it will take me to figure out your algorithm.",Feb 9 '17 at 13:14
55,5,646,"@DavidRicherby I want to upvote this comment 100 times. It's not useful at all to bucket all security into the same bin with differing degrees. We invented the terminology ""security through obscurity"" for a very good reason.",Feb 9 '17 at 14:36
55,5,408,"@Evi1M4chine ""For a very good [but unstated] reason"" isn't an emotional argument. But it is argument by obscurity. ;-)",Feb 17 '17 at 18:02
55,5,408,"@Evi1M4chine No, I'm not agreeing with you. You said that the concept of security by obscurity is ""a fallacy"". I said that it is not. It is an extremely useful concept.",Feb 17 '17 at 18:10
55,6,646,"Well technically this is to try to HIDE the fact that they need to get the private key from the app. That is, this happens first.   However, anyone able to get the key from the app, will not get held up by this at ALL",Feb 9 '17 at 14:30
55,6,25,Any non-idiot attacker would observe the legitimate traffic first and would immediately see that the requests are encrypted. It would literally be the first thing that he notices.,Feb 10 '17 at 8:58
56,1,51,"If they are using TLS, then replay detection is already covered. Isn't it?",Dec 11 '16 at 3:49
56,1,35,"@Limit, remember that the fundamental condition driving this question is how to protect the content of a request given that logs and caches may reveal the data even with TLS in place - and if it were to be revealed, it could be replayed.",Dec 11 '16 at 6:07
56,1,554,"""One that I've run into is that DDoS mitigation services often like to have a copy of your web certificates and keys""  If that's the case, wouldn't the entire communication be at risk?  The content that would be returned in the response is far more sensitive than the keys in the URL and would expose what those keys were in many/most cases.",Dec 12 '16 at 18:11
56,1,554,"@Limit The replay concern is that if someone can grab the URI, they could do a GET on it and get the response data which would likely identify the sensitive keys and much much more.",Dec 12 '16 at 18:15
56,1,51,"@JimmyJames if you are worried about leaking private information, you should implement a role based access system. Just replay detection is not a solution. There can be multiple legitimate requests and if you don't use probabilistic encryption, the encryption output will be the same always.",Dec 12 '16 at 18:19
56,1,657,"The downside of using a tried and tested algorithm to protect something that is inherently un-protectable is that tried and tested algorithms are more likely to have existing reversal algorithms.  In traditional security, protecting the algorithm is unimportant; the goal is to use an algorithm that is safe (unless the key is known), even if the algorithm is public.  If no such algorithm exists (in this case, because the key must be held on the client-side), security through obscurity is less unreasonable; there are no good choices.",Sep 20 '13 at 18:29
56,2,659,"Thanks, Tom. Sadly, I don't control the means of distribution for the app. However, I'll keep this in mind for future projects.",Sep 19 '13 at 21:43
56,3,659,"Thanks, Brendan. I should have been more specific: the reason I am not using captcha is a business requirement to reduce friction on sign up.",Sep 20 '13 at 19:52
56,4,659,"Is that all there is to it? Have a hard-coded key in my application that is also stored on my server and then send it along in the header on every request?  That seems to be what is implied by: security.stackexchange.com/questions/19809/…  However, I want to make sure that I don't miss something. Also, I'm not sure how I would keep that value safe on the client side.",Sep 18 '13 at 16:56
56,4,204,What if someone sniffed your keys and used them to authenticate his own app or script?,Sep 19 '13 at 4:05
56,4,659,"Exactly, and that's why I'm asking what precautions need to be taken. HTTPS should prevent the sniffing in transit. However, I would like to know what steps need to be taken on the client side.",Sep 19 '13 at 15:04
56,4,204,Thant is why API keys and secret should only be used for authenticating the application and not authorization for any functionality. For that a valid user account must be used.,Sep 20 '13 at 7:28
