Post ID,Answer ID,User ID,Comment,Date
1,2,1,"Right, staying offline prevents a lot of problems. How about being on an intranet with other devices that do connect to the internet? For example, how much more vulnerable is an IoT system if it has a raspberry pi as part of its internal network, which in turn is connecting to an internet connected smart phone via bluetooth?",Feb 3 at 3:58
1,2,2,"@cr0, ""device hopping"" is a real concern.  But consider, the bad actor would have to get through internet, bluetooth, and then exploit the RPi and finally exploit the IoT device.  This isn't any different than issues faced by non-IoT intranet devices.",Feb 5 at 19:48
1,5,5,"P.S. I know that that's not how ""Build a better mousetrap"" is usually used.",Feb 5 at 20:36
1,5,1,"This is helpful about physical security - all good things to consider. In my case I'm somewhat new to the area so I don't know risks first hand. Neighbors report theft in the area due to local teenagers. I see teenagers hanging out in the neighborhood but haven't had problems yet. As you said, it's about making targets ""not worth it"" to potential attackers",Feb 6 at 16:36
2,1,6,"Recently, one such doll was found to be so insecure that it was classified as ""hidden espionage device"" in Germany (and banned), see e.g. discussion over at IoT iot.stackexchange.com/questions/1074/… (one of the two referred to in the 3rd paragraph of the #toyfail quote)",Oct 31 '17 at 19:52
2,1,7,"...and if you absolutely must have them, do the sane thing and at the very least segregate them on a network segment all of their own, ideally with no access (beyond that of any untrusted device on the big bad Internet) to anything else. At least that way, if something happens, you are limiting the potential damage somewhat.",Oct 31 '17 at 19:52
2,1,8,"@Michael Kjörling, no, just NO. Anders just explained that this ""doll"" is a spy device, that needs to have access to the internet to work. Your privacy seems to be the last thing on the doll makers list to take into account. The sane thing here is to not have one!",Nov 2 '17 at 8:18
2,1,7,"@Flummox Why do you think I started out my comment the way I did, including the formatting? I agree with this answer, and there's no way I'd buy one myself (for this and for other reasons as well), but if and only if someone has a genuine need for something like this, then there still are steps that can be taken to mitigate the risks a little bit. In such a situation, not at least doing that would be the height of irresponsibility, both toward yourself, others in your household, and others on the Internet.",Nov 2 '17 at 8:26
2,2,7,"Also, keeping in mind the distinction about what a remote attacker is trying to access. Assuming you aren't a high-profile target (and if you are, you probably know better than to trust random strangers on the Internet for security advice), it's fairly unlikely that a remote attacker who gains access to an IoT device (even one that can remotely be turned into an active microphone and speaker, or camera, in your home) is particularly interested in you specifically. It's all the more likely that they are interested in the device itself, e.g. for its computational power or network connectivity.",Oct 31 '17 at 20:16
2,2,7,"In response to your edit, in fairness, I wasn't necessarily thinking of using the device as an attack bot, though that's an obvious thing that could happen (think Mirai and the DNS overload attack against Twitter and friends recently, for one). Think also e.g. bitcoin mining, or sending spam e-mails. Sure, a toy like the one exemplified in the question probably doesn't have enough computational power to make a major difference, but if the cost to the attacker is next to zero, it doesn't need to do much in order to turn a profit, especially if you've got thousands of them working for you...",Oct 31 '17 at 20:21
2,2,10,"There was a recent documentary (BBC if memory serves me correctly) showing the story of an elderly woman who answered the phone to a scammer and was convinced to transfer them a large sum of money. Key to the scam was their use of the camera and microphone on her laptop during the call. If such a device as this ""toy"" is easier to break into than a (presumably) windows machine, then this becomes just one example where an exploit of this type increases the risk surface area",Nov 2 '17 at 4:47
2,3,12,"Never mind the threats to National Security. If every conversation in a large enough sample of homes is recorded and digitised, it does not really bear thinking about that data being used in future prosecutions for crimes against the state. If it is being sent upstream for AI language learning (sold to Google or AWS, say) there may be some value in preserving languages that die out in future?",Nov 1 '17 at 3:21
3,2,19,"Even better - provide a (large) prize for security vulnerabilities, with more severe vulnerabilities (measured in maximum damage they can cause) earning a larger prize. This will hopefully convince some wannabe crackers to disclose the details (certain prize) as opposed to trying to exploit them (uncertain, possibly greater but probably smaller prize, plus risk of being caught).",Sep 1 '17 at 20:53
3,2,20,I would even encourage to make the firmware free software or open source.,Sep 2 '17 at 7:06
3,2,21,"@wizzwizz4 Many businesses do not have the capital to operate a fully-fledged bug bounty program, particularly SMEs and self-funded startups. In general I've seen these businesses offer alternative recompense, such as free or heavily discounted products, t-shirts, swag, etc. depending on the nature of the business and brand. Bug bounties do not necessarily need to be formal and costly.",Sep 2 '17 at 10:53
3,2,19,"@Polynomial Many businesses don't have the capital to not operate a bug bounty program. If a large breach is found, surely it's worth that $x for it not to be found when your clients are suing you for damages caused by a breach.",Sep 2 '17 at 11:33
3,2,21,"@wizzwizz4 I doubt that the lack of a bug bounty program would ever be the confounding factor in a breach. Bounties are great, but they're an optional layer in almost any business' defence budget, perhaps with the exception of highly public organisations. If the goal is to avoid a breach, the cost and time involved with running a BBP can be better invested in more direct defence measures such as staff training and improving blue team capabilities. BBPs are great if you've already got everything else covered and have spare budget, or if the perception of security markets well in your vertical.",Sep 2 '17 at 12:20
3,3,21,"Open source may be a step too far for a commercial product, and the ""many eyes"" principle is generally flawed (see: the state of OpenSSL before Heartbleed). That said, if the project uses any GPL licensed code without special agreement from the author then the full source must be made available anyway.",Sep 1 '17 at 14:30
3,3,7,@Polynomial If the project uses any GPL licensed code then the parts that directly touch the GPL code must be made available as source code. Not all of it. Mere aggregation still applies.,Sep 2 '17 at 23:05
3,3,22,"I can see how that might be an issue with fully Open Source. Also, it usually comes down to semantics when it comes to Open Sourcing on GPL code. I'll look into the OpenSSL matter as well, thanks for that!",Sep 4 '17 at 5:24
3,3,23,"I really think a good answer should address the issue of ""if my software has to be proprietary, is it worth encrypting/obfuscating"".  There may be plenty of reasons to keep software proprietary that have nothing to do with security (contracts with customers, red tape by management, valuable algorithms).   I also believe that publishing your source code isn't a good way to fix up an insecure software development process and shouldn't be overemphasized by dedicating the entire answer to it.",Sep 6 '17 at 21:36
3,5,19,You could always make it illegal to distribute the decryption key! Making numbers illegal definitely works...,Sep 2 '17 at 11:51
3,8,7,"Encryption and signing are orthogonal. Both may have value, but they solve different problems and do so separately.",Sep 2 '17 at 23:10
3,8,28,"Both are very hard if you don't use some crypto library properly, and easy if you do. If you do one, doing the other adds very little effort. And both solve the same problem: Helping to keep the hardware safe.",Sep 2 '17 at 23:43
3,8,29,"What you are missing is that the encryption in the anecdote you mention is only even relevant because the code is encrypted everywhere but inside the trusted execution unit.  For an ordinary processor, even if the update is encrypted in flight or in storage, it will have to be decrypted by something stored on the device to execute.  It's fairly hard to make it so that someone in possession of the a copy of the hardware can't get at the decrypted code, and only in the unusual situations where that is done effectively does encrypting the update in flight matter.",Sep 3 '17 at 19:28
3,8,30,"@gnasher729 Actually, the longer to first hack, the worse. Three years later, it's much harder to fix the bug -- the manufacturer may not even still be around and who knows if they still have the tooling. And three years later, the device might be forgotten about and unmaintained. Three years later, there will be more devices in the field.The sooner flaws are found, the sooner (and more likely) that they're fixed. (And how do you know that one really bad guy didn't know about the flaw and had three extra years to exploit it?)",Sep 4 '17 at 4:23
4,1,32,"(+1) If ISPs implemented NIF (tools.ietf.org/html/bcp38), that would help.  Although, I'm not sure whether playing wack-a-mole with IPv6 is really feasible unless you are considering ""hard coding"" IPs into devices like MAC addresses.  Otherwise, you are back to, get your IP blocked, get new one, and be back in business.",Oct 26 '16 at 19:38
4,1,33,"@Shackledtodesk I have to agree - I just think at least being able to uniquely, if only temporarily, ID the actual devices has to be a step forward.",Oct 26 '16 at 19:40
4,1,34,@Shackledtodesk are we assuming that IPv6 hard-coded addresses won't be spoofed the way MAC are right now?,Oct 26 '16 at 19:44
4,1,32,"@Mindwin, you make a perfectly valid point about spoofing.",Oct 26 '16 at 19:55
4,1,34,"I once heard a joke about IPv6 in the university, I can't recall it fully, but it ends with ""Fine, I'll just use my lightbulb's [IPv6] address instead."" @Shackledtodesk =) - heck, even iphone's IMEI are being spoofed now.",Oct 26 '16 at 20:01
5,2,33,"A lot of the time, that root password is in the firmware / boot image and cannot be changed without reflashing, unfortunately.  Still worth a try - but if you do try it, make sure you fully power cycle the camera to see if it stays (ie, unplug for 30 seconds to ensure the memory is cleared, plug in again, see what root password it is using)",Oct 25 '16 at 15:18
5,2,40,@crovers edited ;),Oct 25 '16 at 15:19
5,2,41,"I tried changing the password, but it resets at reboot",Oct 26 '16 at 7:21
5,2,40,It's probably embedded in the firmware then. You'll need to use the other mitigating controls to reduce the risk of compromise.,Oct 26 '16 at 12:18
6,1,43,Note that with IPv6 the devices would be accessible by default without even needing UPnP nor opening ports (most consumer-grade routers don't firewall IPv6 from what I've seen).,Oct 25 '16 at 3:58
6,1,44,@AndréBorie It is probably not a good idea for routers to have no firewall by default. I think a large number of consumers have a (possibly unjustified) expectation that the router will protect all the insecure devices on the LAN. And I think those who really don't need the firewall will know how to access the configuration and change the firewall setting.,Oct 25 '16 at 7:22
6,1,45,"@AndréBorie On some level, that expectation is a hangover from IPv4 and NAT, where two devices couldn't communicate unless ports are explicitly opened on routers. It seems likely that as IPv6 adoption increases, and brings universal addressability, a lot of vunerabilities will emerge in software that opens TCP ports and trusts the data received on them.",Oct 25 '16 at 11:20
6,1,46,"@AndréBorie, most consumer-grade routers that support IPv6, e.g. Linksys, do firewall IPv6, but they don't NAT IPv6. Those are two very different things.",Oct 25 '16 at 18:44
6,1,47,"@AndréBorie I've never seen a consumer grade router that didn't firewall IPv6, though I'm sure one must exist. Of course, then you have the additional problem of figuring out the IPv6 address...",Oct 25 '16 at 19:51
6,2,49,"I think OP is interested in knowing how SSH/Telnet would be accessible when the device is connected to a private home network, which would normally have an inbound NAT firewall.",Oct 25 '16 at 3:11
6,2,30,"That is a common misunderstanding. They typically have NAT devices that have firewall capabilities that vary from minimal to none at all. Where there are firewall capabilities, they are almost never enabled.",Oct 25 '16 at 18:44
6,2,46,"@tlng05, don't confuse NAT, a kludge to extend IPv4 addressing, with firewalls. You can have a very secure firewall that doesn't have NAT enabled, and you can NAT on a device without having a firewall. The firewall/router combination is just a convenient place to NAT, but it is not a firewall.",Oct 25 '16 at 18:46
6,2,50,"@RonMaupin Still, if it's behind NAT, how would a telnet request on port 23 ever reach the IoT device? How would the router know to forward to the camera? I've heard stuff about UPnP on here, but why in the hell would the manufacturer forward port 23 through UPnP? Doesn't make sense!",Dec 4 '16 at 22:48
6,2,46,"@RenéG, a firewall protects your network, not NAT. If you have no firewall features, it is possible to take over the router by its public address, Then NAT does nothing for you because the router knows how to get to the internal network. Also, if a different port is open, it is possible under some circumstances to get through NAT to take over an inside host, then all bets are off. NAT doesn't really provide security, firewalls do.",Dec 4 '16 at 22:53
6,3,52,"Its accesible from the wider Internet, there you are correct. I won't say that is wide open. I think for over 20 years the basic routers are closed on the common ports. You cannot connect over port 22 to each ip-adres of something like that. But as stated above. UPnP removes this security big time. Never enable that, that makes your router insecure",Oct 25 '16 at 9:35
6,3,30,"@AdamSitemap The only security UPnP removes is accidental security. If a port is filtered by a firewall, enabling UPnP won't unfilter it. If a port is not filtered by a firewall, any security is accidental and unreliable.",Oct 25 '16 at 18:45
6,4,54,"I think this adds a valuable point: my understanding is that a lot of these crappy IoT devices that have been compromised have actually been placed outside any firewall perimeter a user might have, directly connected to the Internet. (But then, of course, in addition you do have port-forwarding and UPnP scenarios where a device is inside the router/firewall but still vulnerable.)",Oct 25 '16 at 15:04
6,4,30,"@halfinformed Most likely, there is no real firewall to speak of, just a router whose job is to make things ""just work"", not provide protection.",Oct 26 '16 at 17:26
6,4,55,"@halfinformed Yes this is the case but only sometimes, mostly as David said there are no firewalls and routers don't do anything.",Oct 28 '16 at 5:13
6,4,54,"By ""firewall"" I mean even any lousy SOHO router or ISP distributed router with some basic firewall-like functionality. (Meaning basically any device that doesn't just let arbitrary inbound  packets from the Internet through to a user's internal network.) I certainly did not mean to imply that ordinary users are typically utilizing discrete firewall devices.",Oct 29 '16 at 18:53
6,5,56,"But there's no indication that's what's happening. The vuln is in the devices and the crappy upnp-enabled routers, not the vendor's central servers. If it were the latter it would be easy to fix.",Oct 25 '16 at 16:29
6,5,57,There have definitely been hacks into devices through vendor websites.,Oct 25 '16 at 16:54
6,5,48,"The MIRAI botnet and malware is not hacking the vendors' servers or website.  It is directly connecting to the end-users' webcams and other IoT devices by connecting to well-known ports that the devices have exposed using UPnP, then testing a set of 66 different default credentials on those ports.  Yes, someone could theoretically attack the vendor's site, but that hasn't been true for any of the recent massive DDoS attacks.",Oct 25 '16 at 21:40
6,5,57,"The OP's question didn't specifically name the MIRAI botnet (the body of the question did allude to it). The heading is: ""Does the local network need to be hacked first for IoT devices to be accesible?"" Based on that heading, the answer is no, the attacker doesn't even always have to make any effort to breach your router at all. If they can get away with social engineering the IoT device vendor's company, they can get into all of the devices at once since, often, all those devices already made outgoing persistent connections to the IoT vendor. There's more than one IoT threat vector.",Oct 26 '16 at 0:29
6,8,59,"In other words, similar in principle to a DNS reflection attack.",Jan 23 '17 at 4:11
6,8,60,"Yes, in the sense that these IoT devices can be used to perform the DDoS reflection attack on an unsuspecting 3rd party. There are other significant security issues with many IoT devices simply because manufacturers have not designed security into their systems. However, using them to perform DDoS reflection attacks is one of the highest concerns as it provides the potential to impact on large numbers of unsuspecting victims. The other security issues associated with IoT tend to only affect the individual/site running them,so less potential impact.",Jan 24 '17 at 9:33
6,8,48,"@TimX, you said ""In many cases, the devices have not been hacked at all - they are performing as designed."" Except an IoT network is generally kept behind a firewall, where network security has to be penetrated first.  Sure, you could possibly send my IoT devices into an amplification attack against each other that would make my house unhappy, but my traffic won't impact your house. That would require my devices to violate your firewall to get your devices to attack each other. Propagating the attack takes hacking the devices. Mirai hacked the devices, they were not ""performing as designed"".",Feb 7 '17 at 15:26
6,8,60,"One small problem with your assumption about firewalls - IPv6. Vary few of the modems sold in the domestic market support firewalls for IPv6, yet the majority of them now support IPv6 and an increasing number of ISPs now enable IPv6 by default.  The other problem is that many of these IoT devices are designed to allow external connections - either requiring port forwarding or using something awful like uPnP. Combine this with the high use of IoT in domestic and small office situations where IT skills are often low and you have a problem. Relying on the firewall is really just 'candy' security",Feb 8 '17 at 18:34
6,10,48,"Hi @Culme, the issue here is that the devices are visible to the internet, where economies of scale mean that dozens of hacked devices can be set upon thousands of other devices, which can then hack millions.  An insecure 433MHz RF connection can be exploited only by an attacker physically located within signal range of your house. And hacking your single IoT device doesn't grant him the ability to hack thousands of other RF devices, unless he drives to a thousand other homes.  The internet-facing vulnerabilities are the ones that lead to Mirai, not the RF facing ones.",Feb 7 '17 at 15:13
7,1,64,"Well, that kinda answers your question, doesn't it? I'd still collect all the info you have on your use cases and get in touch with Azure directly. They know what they allow users to do. (Also since the link to the Penetration testing overview page is dead...)",Aug 21 at 14:21
7,1,65,"This sounds good, one thing that might be worth checking if you do use Azure, is whether they filter any types of outbound traffic.  If you're trying to do something like 65K port scans or something more esoteric like SCTP scanning, you may find that traffic gets blocked :)",Aug 23 at 7:57
7,1,66,@jpmc26: thanks. I've fixed it.,Apr 26 '17 at 11:04
7,2,7,"If you are using stolen credit cards to pay for the VMs, aren't you flushing someone else's money down the drain?",Apr 25 '17 at 12:42
7,2,67,"I suspect Tor would not be very useful for DDoS attacks. Your traffic would first have to traverse a number of machines inside the Tor network, and then emerge at exit points. Effectively, you would be using Tor as a command-and-control system, and the exit nodes as the source of your DDoS traffic. This would probably be less effective than using a ""traditional"" malware-based botnet. You could probably craft an attack to DoS Tor itself, though.",Apr 25 '17 at 15:12
7,2,68,"@MichaelKjörling It still becomes someone else's someone else's money though, instead of remaining your someone else's money.",Apr 25 '17 at 17:26
7,2,69,"With a properly done attack, Tor could be rather productive.  You just need a magnification/reflection attack.  Take an old-school ICMP magnification: you send a few bytes over Tor to a vulnerable host claiming to be from the final target, they send a few hundred kB to the target.  You can use Tor to shotgun out to your amplifiers, which basically hides you behind 2 layers of obscurity from the target (vulnerable amplifiers, Tor, then you).  That also obscures Tor as being part of the attacker's vector (victim only sees packets from amplifiers who aren't greatly affected so don't report)",Apr 26 '17 at 13:03
7,2,69,"I might add, that is why good routers and firewalls are so picky about well formed ICMP packets, and why this isn't nearly as common an attack vector as it once was (also why I don't mind explaining it).  The first D in DDoS is for distributed, and while you got that from the attacker's perspective (multiple cloud instances to lay in the attack) you forgot that it isn't cost effective for an attacker to own the DDoS hosts, only the instigators.  So they can distribute the instigators in the cloud with Tor help, but the actual attackers are still gonna be vulnerable internet connected systems.",Apr 26 '17 at 13:06
7,3,71,"It's worth noting that Mirai isn't the first botnet used for ""DoS-as-a-Service"". Criminals use this monetization model for their botnets for years. The only new thing about Mirai is that it focuses on infecting IoT devices.",Jul 11 '17 at 16:12
7,4,71,Unfortunately there is also a flourishing black market for stolen credit cards and compromised online banking accounts which criminals can use to pay for cloud services anonymously.,Jul 11 '17 at 16:14
8,2,26,"I think this is an interesting comment, but I don't see that it would work for AWS.  AWS runs on virtual machines, so it seems to me that anyone with access to the host machine could simply find the key in the register.",May 4 '16 at 14:45
8,2,75,This comes close to a software-only solution. Its still not clear to me if this really works. I'm reading the references. Possibly it could be bootstrapped using a hardware module to ensure that RamCrypt has been booted securely.,May 4 '16 at 15:31
8,2,76,"You're right, it wouldn't work on AWS, since virtual machines trap access to hardware debug registers and emulate it. This is more about generally keeping secrets safe in memory. This is not possible on a virtual machine unless it is designed with this in mind (e.g. by isolating individual VMs with SGX).",Dec 1 '17 at 5:44
8,3,75,Not a random key but one entered by a human during run-time.,May 3 '16 at 7:47
8,3,77,"Usually humans enter passwords, not keys (although some key management routines may require direct entry of hexadecimals representing bytes of a key). Never confuse passwords and keys.",May 3 '16 at 8:05
8,3,75,"If you mean passwords to be alphanumeric, then I don't technically distinguish between a key and a strong password. A Base64 encoded 256 bit random key is also a password under this definition.",May 4 '16 at 3:38
8,3,75,"(maybe with some special security module that contains your program code) -- This might seem to work. However, isn't it 'turtles all the way down'? Because then we need to control the code that uses the program that uses the key.",May 6 '16 at 17:30
8,4,75,"Note that there is a subtle difference. In the DRM case, the device/application is bootstrapped in a compromised state. In my case, I can guarantee that my application (say, a custom made media player) was bootstrapped in a secure state when the key was supplied. Later at some point, the system is compromised. This is a weaker requirement than the pure DRM case.",May 4 '16 at 3:35
8,4,79,"@jus12 ""In the DRM case, the device/application is bootstrapped in a compromised state."" - not with secure boot!",May 4 '16 at 5:24
8,4,21,@Jus12 I don't believe that you can bootstrap to any safe state when the underlying hardware is controlled by a potentially malicious party.,May 4 '16 at 12:21
8,4,75,"@Polynomial That is one of the assumptions I am making. The underlying hardware was in a trusted state at the time when the key was supplied. It may later become compromised. I feel there is a difference in the attacker capabilities in these two cases, even though they appear to be similar.",May 4 '16 at 15:33
8,5,75,"Yes, for my application, the key is used consistently. If this can be done via HSM, this would solve the problem. How can we prevent the attacker from using the key inside the HSM?",May 4 '16 at 3:31
8,5,26,"@Jus12 I don't know that you can.  While the key is in use, it's in memory.  If it's in memory, it's at risk.  Think of the HSM as a safe.  If the secret is outside of the safe, it's not protected.  When it's ONLY in the safe, it's protected, but you still need to store the combination somewhere.  If the combination is in memory, you haven't really accomplished anything but misdirection.",May 4 '16 at 14:37
9,1,80,"Also there may occur a ""programming error"" causing all deletion commands to be ""ineffective"" and thus preserving all your data there. Happens. ;-)",Jul 7 '14 at 8:26
9,1,81,"Per Google's File deletion and recovery policy, ""you can contact us to help recover a deleted file or folder for a limited time"". The exact duration that the files are kept around to be recovered is not specified. According to the policy, recovery is only possible for consumer accounts; deleted files from enterprise accounts cannot be recovered.",Jul 7 '14 at 16:12
9,1,82,"It's known from recent leaks that NSA has been influencing and pushing weak cryptography standards through their relationship with NIST. Their MOU states NIST must consult with NSA on standards. It does not make sense that NSA would recommend algorithms they cannot break as it would be counter-productive to their mass surveillance mission. Thus if you use Suite B algorithms then you are likely not protected against the NSA. Public cryptographers have discovered a few weaknesses, but do not have the cryptanalytic capabilities of NSA.",Jul 7 '14 at 21:41
9,1,3,"@NDF1, quantum computers are only exceptionally fast at breaking RSA and factoring-related cyphers (Shor's algorithm).  Symmetric cyphers such as AES are not vulnerable, and ECC is not vulnerable.",Jul 7 '14 at 22:22
9,1,83,I would also note that it's not a requirement for the agency name to consist of three laters. Vide GCHQ.,Jul 9 '14 at 11:07
9,2,84,i thought Truecrypt has a security issue?,Jul 7 '14 at 12:28
9,2,85,The y do not have security issues. At least none that are publicly disclosed :-): The problem with TC is the fact that support is dropped by the two russian developers. They ended the development of TC in May 2014. TrueCrypt is now in the process of being evaluated by several crypto analysis teams. Phase 1 of the audit did not found any errors in the implementation. It's now in phase 2. You can track the progress here: istruecryptauditedyet.com  Security issues will arise if these audits detect flaws. Unless some development team picks up on the code and starts further development.,Jul 7 '14 at 13:21
9,2,85,In other words: TC is now not more or less secure than before the team decided to quit.,Jul 7 '14 at 13:25
9,2,86,Why does copying the file out of the container and then moving it back in add additional security? What is the concern? That they'll be able to see incremental changes?,Jul 7 '14 at 19:53
9,2,86,"Oh, perhaps I don't understand how TrueCrypt works on other platforms. On Linux, it mounts the encrypted drive as a filesystem, which means that all reads/writes are decrypted/encrypted directly to the container file, therefore there'd be nothing to do at all.",Jul 7 '14 at 23:46
9,4,88,"thank you for your recommendations. Honestly, I am looking for alternatives with similar functionality (e.g. automatic sync on mac, pc, android, + web browser ui) Can you recommend something like that?",Jul 8 '14 at 17:05
9,4,89,@gen: You might be interested in Software Recommendations.,Jul 9 '14 at 16:37
9,4,88,"@unor wow thanks, stack exchange is so good :)",Jul 9 '14 at 20:59
9,4,88,@unor; just posted a question there: softwarerecs.stackexchange.com/questions/7677/…,Jul 9 '14 at 21:16
9,5,91,"@to whoever downvoted, there's a lot of answers suggesting that encryption is the silver bullet on how to securely keep data in the cloud, its not - if you don't want your data to be accessible at some point in the future you will not upload it and one answer needed to say it",Jul 7 '14 at 18:39
9,5,92,"Encryption IS a secure method. BUT the question is: secure against what threat? No measure is ever a silver bullet, and in that way, there is no 'secure' method to do anything. It is always a question of the nature of the threat you are needing to secure against.",Jul 7 '14 at 19:44
9,5,91,"@schroeder, I agree, that's just misleading semantics when discussed in this context. For example: plain text is secure against a decent individual and pre-heartbleed OpenSSL communication was secure against people who didn't exploit heartbleed. Today's communication and data storage is also ""secure"" when you use ""industry accepted standards"", but same would have been said about OpenSSL traffic before heartbleed was announced. If your life depended on it in the long run, you would not trust what we today call ""secure"" communication.",Jul 7 '14 at 21:30
9,5,93,One cryptographic algorithm will be broken tomorrow. Just compute which one and avoid it :).,Jul 7 '14 at 21:53
9,7,88,"I have already considered numerous alternatives, but haven't find any suitable yet. By suitable I mean, trustworthy. I have plenty of problems with Tresorit:  ""You agree that Tresorit may also transmit any data stored by You to a third party if Tresorit has a reason to believe that it is required..."" that sounds pretty strange given their Zero Knoledge Policy.  Another problem with them: ""we might use trusted third parties, like Microsoft, to provide the Service."" Microsoft trusted party? :/ Those are some of my concerns with Tresorit. (These quotes are from Tresorit Eulas, etc)",Jul 8 '14 at 19:36
9,7,94,"What I do as a rule of thumb is use AxCrypt to first crypt the sensitive files on my local hard drive, and then I upload them to Dropbox (or Google Drive or whatever). This gets you as close as you're gonna get to ""true"" data privacy in the cloud. It doesn't matter whether Google keeps your files or not, because from a practical perspective nobody can decrypt them except you. notice I say from a ""practical"" perspective. Theoretically maybe someone can break your encryption, but when you consider all the variables involved, it's just not gonna happen.",Jul 9 '14 at 18:24
10,1,97,could you explain how DDoS mitigation on encrypted traffic works - doesn't it all just look like rubbish?,Nov 13 '13 at 17:03
10,1,98,"Traffic flow patterns, as I mentioned in the answer. Not content, which all looks like rubbish, as you say.",Nov 13 '13 at 19:38
10,1,97,"Thanks about the info, I think I have to read up on flow patterns :)",Nov 14 '13 at 9:50
10,3,97,Why should a provider have the SSL key if I use their appliance in my network? Assuming the appliance doesn't secretly phone home of course.,Nov 13 '13 at 13:33
10,3,101,"As you say @mohrphium, it could phone home. Given recent news it wouldn't surprise me if companies were collecting that data. They could encapsulate it in messages requesting software updates and you'd never know as it's all closed source.",Nov 13 '13 at 16:01
10,3,97,good point... thanks for the input :),Nov 13 '13 at 17:03
10,3,97,"Unfortunately I can't choose both your answers as ""the answer"". Thanks for your answer, especially the point of modifying configurations since I kinda tended to ""outsource and don't think about it anymore"". But of course we still have to take a look at our own configs.",Nov 14 '13 at 9:53
11,2,105,"No, AWS gives you a full paravirtualized server, for free for one year even. It's behind a NAT though...",Feb 12 '13 at 17:25
11,2,106,"@EricDong Thanks. Yeah, that won't work at all for port scanning, edited.",Feb 12 '13 at 17:28
11,2,107,"Yes, it's behind a NAT, but it's a 1:1 NAT. Should work just fine.",Feb 12 '13 at 17:38
12,1,111,"In this case you can't even run an offline search. You need to query google's servers that often, which makes is even more ridiculous.",Jan 21 '13 at 21:16
12,1,112,@CodesInChaos as if building a Dyson sphere around the sun to power an ideal computer sitting in deep space isn't ridiculous enough...,Jan 21 '13 at 21:21
12,1,113,"So a rubber hose is much more likely. I guess if I see someone building a Dyson sphere around the sun it's probably too late to worry about the guys with the rubber hose, though.",Jan 21 '13 at 21:52
12,1,114,"While I like your math, let me point out that you're overlooking the fact that the keyspace probably isn't a full 263 bits wide.  Whatever generator they use probably has at least a few rules to limit out stuff like a key of 11111...111; also, while brute-forcing a single, specific document is expensive, what you have to deal with is the possibility -- still remote -- of them randomly querying that link.  (This is of course nitpicking; your point is completely valid)",Jan 28 '13 at 5:48
12,1,112,"@RonLugge The effect of such rules may affect the numbers to several orders of magnitude, but it wouldn't affect the outcome. As for accidental stumbles; say each person on earth had 1 million documents on GA. That's what, 2^53 documents? So let's be generously inaccurate with our math and say that any guess has a 1 in 2^200 chance of accidentally stumbling on a real document. So if all he computers in the world do nothing but enumerate document links for the rest of eternity, the chances of a single hit are still indistinguishable from zero.",Jan 28 '13 at 6:25
12,2,115,And not forgetting the link hanging around in someone's browser history,Jan 21 '13 at 18:16
12,2,111,"Using a secret url is not security through obscurity if the url has sufficient entropy (And this one has around 256 bits). It's a viable form of authentication, even if there are certain associated risks.",Jan 21 '13 at 19:39
12,2,116,"It's not a valid form of authentication because the risk of someone leaking the url is higher than leaking their own credentials to log into the application. Authentication also requires proof of identity, while this does not provide that.",Jan 21 '13 at 20:24
12,2,116,"Plus I clearly stated that the guessing speed is very improbable, so please elaborate on why you insist to downvote my answer.",Jan 21 '13 at 20:27
12,1,118,"GiT has a great lab, I remember reading a lot of articles on it when it came out: Here is a whitepaper on it (unknown date, sorry. Also, PDF Warning): csc.gatech.edu/~copeland/6612/netseclab/… csc.gatech.edu/netseclab.html Description of lab and their methodology for grading",Jan 3 '13 at 17:06
12,1,119,If you are planning to go with vSphere and build the machine from scratch check the hardware compatability guide before you start.,Jan 4 '13 at 12:27
12,2,120,"Thanks Cristian, I think we can use the hackademic project for web pentest lab since it only require a server and LAMP or WAMP. if you have more information regarding what we are looking for that will be great.",Jan 4 '13 at 4:27
12,3,120,"The cloud service you mentioned is an interesting option that we might look into. Thank you and if there is more information from your source, do share. Thanks",Jan 4 '13 at 4:13
12,3,122,"A hosted service like Amazon would likely not serve your needs. When we looked into setting this same type of environment with them for use by our students, they informed us that the type of activities students would have to perform against the amazon network (portscans, network exploits, etc.) would violate their terms of service and they would probably have to shut us down. Keep that in mind as you make a selection. You may have to build something in house.",Jan 5 '13 at 3:45
12,3,120,"Thanks for the heads up queso, most probably some organization would agree and some won't. we would appreciate if you can share with us how did your institution setup the environment?",Jan 6 '13 at 10:51
12,4,120,"I am familiar with that site and its actually very good but we want to have control of the environment to add or edit the labs. Thanks, if you found more information for what we are looking for do share.",Jan 4 '13 at 4:31
12,4,11,"@KenAdams - the trick then is that you have to emulate a hack as opposed to actually doing it.  You could give each student their own instance, but assuming you want to be able to grade it, you need a way to report success or failure of the attempts.  A simple thing that one of my professors in college did was a binary bomb application that had various techniques for protecting a program and the goal of the students was to get the password out of it.  Incorrect attempts would trigger a notification to the teacher unless you intercepted the instructions and broke out of them.",Jan 4 '13 at 6:14
12,4,11,Not really sure exactly how they went about making it though.,Jan 4 '13 at 6:16
12,4,120,"Good point AJ, I agree it is a very important key to record or log the success of the student he/she pass a certain challenge. It would be very useful for practical quiz or challenge between students.",Jan 4 '13 at 7:19
12,5,120,"I have gone across NetWARS before but I was not sure, whether it function according to what we want. Thanks",Jan 4 '13 at 6:52
13,1,125,"Thanks for sharing that best-practice. It was hard to decide who gave the ""right answer"" regarding the original question - you or Thomas Pornin. I decided to give the tick to you, since your advice explains a practical workaround for the problem Thomas pointed out. For anyone who finds this post: Alexander's advice is to read and store encrypted data in the cloud but having the key to decrypt that data somewhere else.  As Alexander stated: That limits the abilities of such a solution in trade for increased security.  Thanks Alexander!",Oct 7 '12 at 9:10
13,2,21,Immutable Law of Security #6 - A computer is only as secure as the administrator is trustworthy.,Oct 6 '12 at 13:25
13,2,125,Are you saying that an encrypted disk (in the VM) would  have no effect on what the Host sees?  I thought this would make it at least a bit harder for an attacker to steal data.,Oct 6 '12 at 13:35
13,2,127,"@Emi If the guest can access the data, the host can access the data. For instance, a symmetric encryption key that allows the guest to decipher or encrypt blocks of data, must be held somewhere in the guest machines's memory for it to be of use. Since the guest's memory is really the underlying host's memory, the host can readily access the area containing the guest's key.  Now the attacker on the host has a copy of the key and can go on to read or modify the data as he pleases.",Jul 19 '16 at 8:36
13,4,125,"Well, the contract is just one side. When those paragraphs come into action, it is already to late, since the attack was successful. Are there any techniques to reduce the mentioned risk in any way?",Oct 6 '12 at 13:39
14,1,133,"Protect your encryption keys from both disclosure and loss. E.g., if your house burns down (floods, gets robbed, etc.), and takes your encryption keys with it, your backups are worthless.",Oct 9 '12 at 18:30
14,2,134,Thank you for this. It would also be nice to see what exactly can each of them do with your data.,Apr 7 '14 at 8:23
14,3,136,Illustrative way to highlight the differences between Public/Personal/Private.,Sep 26 '12 at 10:54
14,3,137,@OnTheShelf Would you provide a citation for SkyDrive running on Windows Azure?  I’ve been unable to find such reports.  Thanks.,Aug 24 '13 at 13:55
14,3,138,"@JCChu Azure is really a brand name for wide range of services, including very simple REST API access to MSFT global data centers, regionally or geo-redundant data (blob) storage, queues, identity and notification services, and a range of Windows Server hosting options (including much of the “fabric” which underlies Azure that is running on Windows Servers). It is not clear if you are looking to see the Azure brand name tied to SkyDrive, or have some concern that it may be less reliable because of some quantifiable difference. For example, while some SkyDrive data racks may be hosted in a MSFT",Aug 29 '13 at 19:16
14,3,138,"data center which pre-dates the Azure brand (for example the Bellevue DC’s which Bing, Windows Live and MSN used), MSFT Global Foundation Services (GFS) still runs them as they do Azure branded DCs. It is really a brand migration issue. Likewise Office365 is a separate brand, but the identity service it provides it is really Azure Active Directory, as SkyDrive Pro is really SharePoint Online.",Aug 29 '13 at 19:16
14,3,138,"Have you looked at their various SLA (service level agreements) to see if your concern is addressed? If it helps, SkyDrive (or whatever it is renamed to) is tightly integrated into Windows 8.1, so MSFT is HIGHLY MOTIVATED to ensure there is no data loss which might tarnish the global Windows brand.",Aug 29 '13 at 19:16
14,5,140,"The main players like SkyDrive, DropBox, Google Drive, don't encrypt in the cloud anyway. They only encrypt the transmission between cloud and client. They also are at liberty to scan contents, which is why there have been cases of individuals having content deleted because they break rules (copyright or in some way illegal).",Dec 14 '12 at 13:45
14,5,141,"Actually, Dropbox do encrypt at rest. See dropbox.com/help/7/en. Google don't, and Microsoft won´t say if they do or not.",Dec 17 '12 at 12:21
14,5,140,"Is that a recent change then as many articles on cloud encryption I'd been reading when reviewing them said they didn't and they only encrypted on transfer not at rest? Interesting, your point stands of course. They have the keys! and can (and probably do) look at the content, pass onto government authorities etc. It's as good as no encryption really.",Dec 17 '12 at 12:33
14,6,138,"Truecrypt is terrific for Private information, although often overkill for Personal information. The key task is to un-mount the encrypted volume so replication to the cloud can occur. SkyDrive, DropBox, and others handle that replication of volumes-in-use differently, so confirm that your updates are being pushed to the cloud as you expect them to be. Consider converting larger volumes into many smaller truecrypt volumes to ensure less data is delayed from replication.",Apr 25 '13 at 2:00
15,1,144,Thanks for your comment. I have not decided on DropBox but I would like to use a DropBox like solution. I want to share documents with other people over the internet. But I want to use personal keys for the encryption and not rely on encryption keys provided by the solution provider. I want a little program sitting on my site for the encryption (like e-mail encryption in outlook) based on the cert of the intended recipient. Because of file size e-mail is no option to use.,Jan 2 '12 at 19:43
15,1,145,+1 for 7zip (as long as you don't forget the password...),Jun 6 '14 at 20:07
15,1,146,"7zip is NOT secure - the protocol is secure as far as I'm aware, but the 7zip program (at least on windows) often leaves your archive out in plain-text in temporary folders and forgets to delete them. The creator refuses to see this as a bug and said he won't fix it - so I'd use something else. Don't have a recommendation tho - I still use 7zip for archives cause I haven't found a replacement : /. For single text files, I use andromeda.com/people/ddyer/notepad/NotepadCrypt-technotes.html - which is way better because your decrypted file is only in memory.",Oct 8 '15 at 22:27
15,1,147,"@BT that might not a security issue depending on your setup (or threat modeling). If you are sharing a computer then yes its a problem, if you only use that computer in a bunker 1 mile below sea level, and put the encrypted file onto a USB stick then its no issue at all.",Sep 21 '17 at 9:02
15,1,146,"@daniel Well, I suppose you have a point in the context of this question. I'm coming from bitcoin land where I was pretty upset to find that my keys were dropped in plain text on my HD without me knowing about it and persisting for months. That said, I don't trust an application where the author blatantly disregards these kinds of security issues. Doesn't make me confident the rest of it is secure, even for the OP's use case .",Sep 21 '17 at 22:52
15,3,144,Thank you for your suggestion. Creating a TrueCrypt volume and sharing the volume in a dropbox like solution might do the trick. But it still requires the other people to do something that is not familiar to them. I would like to have a transparent solution (that can also be used by people who are not technical skilled) in such a way that it cannot go wrong.,Jan 2 '12 at 19:51
15,4,151,Wuala has shut down in 2015.,Oct 6 '17 at 12:24
15,6,92,Thank you for disclosing your relationship with the tool!,Apr 29 '15 at 21:55
15,7,111,"But the point of this question is sharing it securely which implies client side encryption with a key the server doesn't know. You can use s3 as a backend behind a secure file sharing system, but it isn't secure by itself.",Oct 30 '13 at 16:35
15,7,155,Built in is a client side encryption service;   docs.aws.amazon.com/AmazonS3/latest/dev/…,Oct 30 '13 at 16:42
15,7,156,So basically just run your own service. This answer doesn't really help since the OP is looking for something similar to Dropbox. Having to develop a Dropbox clone first is not really what he was looking for I think.,Oct 30 '13 at 17:38
15,9,158,"Important point, boxcryptor is closed source  security.stackexchange.com/questions/63542/…",Jul 15 '16 at 9:42
15,10,160,"Are you affiliated with the linked software in any way? If so, please disclose your affiliation.",Mar 7 '14 at 10:46
16,1,163,"you also try asking google for the Sha1/Md5 digests. it is bizarre, how easy it is to find the right password by just submitting a digest to google!",Nov 16 '11 at 23:50
16,1,164,A simple google search has worked several times for me,Apr 5 '12 at 14:30
16,2,166,You should also consider the cost of unavailability due to EC2 failure. The probability of it happening again is small but not zero.,Nov 17 '11 at 20:16
16,2,167,Running a password-cracking job for a client is something that can wait 6-18 hours for an AWS service to come back up.,Nov 18 '11 at 2:34
16,2,168,@this.josh likewise the cost of replacing parts due to failure in the DIY model,Apr 5 '12 at 8:22
16,2,169,"@this.josh I think the cost of unavailability in a password cracker is pretty limited, and unavailability on Amazon is probably lower than on a self-constructed machine.",Jan 2 '13 at 15:52
16,4,172,Rainbow tables are limited only to non-salted hashes.,Nov 22 '11 at 21:07
17,1,177,"+1 on the ""if someone hated me that much"" point.  Like Chris Rock's riff about a world in which each bullet cost $1k.",Nov 2 '11 at 13:11
17,1,178,Thought it was $5K?,Nov 17 '11 at 16:06
17,1,179,"Nobody mentioned botnets. Nobody DDOS with one ADSL 10mbps. Hackers use botnets. Biggest botnets have millions of bots. This page is top google result for ""amazon s3 ddos cost"". I also consider if it is safe to Amazon as Amazon traffic is very expensive.",Mar 19 '14 at 23:35
17,1,180,"You can issue a large attack using Google docs, without hurting your humble ADSL connection.",May 24 '14 at 22:28
17,5,185,"But won't Amazon sue on me, if my card limit will be exhausted?",Jul 5 at 22:00
17,5,186,Amazon now has lots of limits and notifications you can have happen when things get out of control. docs.aws.amazon.com/awsaccountbilling/latest/aboutv2/…,Jul 9 at 19:58
18,1,188,"Smaller volume shops still need to be compliant, they just have an easier audit and approval process.",Sep 5 '11 at 13:31
18,1,107,"True... I did mean that they still have a bar when I said ""don't have to worry about a lot."" They do have to self-review and sign off on it, but they don't have to hire an auditor.",Sep 5 '11 at 13:33
18,7,194,"Hi, it wasn't spam - at least not an intentional one. Currently the above described solution is available via only one specific provider and so I figured I can mention him (it) by name... I do see your point. So, following your comment I`ve re-edited the post and removed all brand mentions.",Jul 17 '12 at 11:28
18,7,98,Thanks Igal - it just read a lot like an advert. This is definitely better - I have added a brief disclaimer just to let the reader know.,Jul 17 '12 at 11:46
18,7,194,"Thanks again, this all thing actually prompted me to go and have a look at infosecfrog so I feel it was a ""score 1"" for me :)",Jul 17 '12 at 12:23
18,7,98,"Well, I gave you an upvote for the revised version as well :-)",Jul 17 '12 at 12:37
18,7,195,@IgalZeifman - I find it hard to believe there is a single solution available and you just happen to work for them.,Jul 17 '12 at 14:26
19,1,197,"Don't want to be picky, but an ""infinite"" amount? ;)",Nov 14 '10 at 20:38
19,1,198,"@ Nev Stokes: Well we're still coming up with new security issues everyday in non-cloud environments, why not also cloud?",Nov 15 '10 at 1:43
19,1,175,"I'd be interested in seeing a real world comparison of risk between cloud and non-cloud deployments.  Since most risk is from insiders, one would think the cloud solution is more secure.  I doubt the local-non-cloud deployment will be as secure as the cloud deployment in most cases.",Dec 1 '10 at 21:03
19,1,98,"@makerofthings - I have a feeling your assumption that most risk is from insiders is outdated by a few years. Most real risk as measured at C-suite level is external (possibly with an element of internal collusion, but not always) as applications are more and more external. So far evidence proves cloud is definitely less secure, but to be fair, this could be mostly around misconfoguration :-)",Dec 30 '10 at 1:57
19,1,199,"In fact, the (very good) ENISA link lists 35 risks and 53 vulnerabilities - that's total of only 88 which was less than infinite last I checked. ""Infinite"" sounds a lot like paranoid scare tactics to me. Sure, If there was more content to the answer or to the indirect argument against cloud computing it contains, I'd be happy let the attack pass or would even join the crowd - but stated like this there just isn't.",Jan 10 '11 at 12:22
19,2,200,"Good points Avid although I'm not sure every item you listed falls into the security category, but still all very relevant to Cloud apps. I think your last point is a very important one. The individuals security (the user of your app) is at least as important as your companies security.",Dec 30 '10 at 2:51
19,2,188,"@Anonymous, actually I don't regard laws as protecting the individual's security - I can do that better than any vague and generic law. However, this is ""security"" because it relates to compliance to those laws.",Dec 30 '10 at 8:41
19,7,98,"the OP requested security issues specific to the cloud. What you have posted contains a reasonable list of security headings but reads as an advert. The link you added is also a marketing front page, not a source of security information.",Jan 10 '11 at 9:35
19,7,204,Adverts like these usually hurt the business more than it could do any good.,Sep 18 '13 at 4:22
19,1,98,Comments are not for extended discussion; this conversation has been moved to chat.,Sep 26 at 9:51
19,1,205,"Reminds me of the alleged habit of New York City inhabitants of the 1970s and -80s, when crime was at a high, to carry two wallets -- one with 20 dollars or so for a mugger and the other one with the real valuables. (Any parallels between police and muggers are, of course, entirely coincidental.)",Oct 4 at 12:35
19,2,207,"It's probably not illegal to have a crappy old phone., op would need to make very sure that is indeed the case.",Sep 26 at 11:53
19,2,208,"Be wary - my nokia 6310 supported Java, and stored up to 102 kbytes of JAR files.  And even worse, it was java.",Sep 26 at 11:56
19,2,209,@Criggie While possible that they've got a java version of the app... I'm betting they didn't get into that nightmare and just wave people on if their phone doesn't support the app.,Sep 26 at 12:00
19,2,206,"I agree with you. Getting this type of phone is the best solution IFF this won't draw suspicion from police even farther. I asked OP in comments if he can get simple phone or live without of phone at all, but didn't get reply and now my comment is deleted. Whatever. Regardless, additional ""benefit"" of keeping android phone with running app is for it to be ""red herring"". You give up a little bit of privacy in order to not get yourself into an even bigger trouble. What's better: government knowing exactly where you are at any time or sitting in jail?",Sep 26 at 13:10
19,2,210,"Only problem, they can still listen to all your calls, read your text and track your whereabouts through carrier surveillance. May be worth mentioning.",Sep 26 at 15:33
19,3,211,"There is one more risc too to concider - other channels used more less frequently - and it may not be for security, just for convenience. I can say, that I made application, which normally communicate in plain text each 1/2 hour, but 4x a day it also use other channel for other data and sometimes (like once a week to once a three months) use another channel for totally another kind of data. (And sometimes it update itself.) Lack of any of such communications is reported as big red error at central server. And it has nothing to do with spying or security, just with primary function of the app.",Sep 25 at 3:46
19,3,212,"There are a few more: sandbox the app + sandbox apps that you want to hide, off the top of my head.",Sep 25 at 6:05
19,3,213,"actually httpS is not very effective on neither Android devices nor iOS devices. the free version of Fiddler Proxy (+ this plugin) has everything needed to generate a fake certificate, install it on the phone, and perform MITM https-decryption, modifcation, redirection, and blocking. i've used this myself several times to study and cheat in mobile games. (and study the Facebook Messenger / friends API)",Sep 25 at 8:14
19,3,214,"@user1067003 Sure, performing a MitM on yourself is very doable.  I wasn't trying to imply otherwise.  However, it is still harder than simply sniffing network traffic for an unencrypted connection.  My point was that SSL is the first and most basic security step for web systems, and also very easy to do.  Anyone who is not bothering with HTTPS these days simply isn't trying, and SSL certainly does provide a barrier from simple snooping.   Add in HSTS and public key pinning and you're starting to get about as secure as possible on someone else's device.",Sep 25 at 10:33
19,3,215,"I'm not exactly an expert on mobile communication, but AFAIK any phone comes with both an IMEI (spoofable, but it's tricky) and an IMSI (not spoofable, as it's the ID of your phone in the network). Considering the capacities of Chinas surveillance I would be astonished if they couldn't detect a phone with an unique ID having the app active only sporadically. Let alone sniffing on higher levels of the system or examining the entire storage when the app is running.",Sep 26 at 17:52
19,5,217,"Whether this is possible is extremely dependent on the particular phone, even if Android is a given.",Sep 24 at 22:33
19,5,218,What stops them using the logs of the mobile phone network to check that app is running at all times the phone is connected?,Sep 25 at 8:08
19,5,132,@ThoriumBR Surveillance apps presumably do run all the time.,Sep 25 at 16:32
19,5,67,"@ThoriumBR A mobile phone doesn't go to sleep when not in use like a closed laptop; if nothing else, it will be constantly checking with transmitters to ensure it can receive incoming calls. It seems perfectly plausible to me for a background application to be logging many times a minute whenever the phone is switched on; saving to a local, encrypted, database; and periodically uploading reports to a central server. Gaps in that log might be viewed as suspicious, particularly if they can be compared against logs demanded from the network operator.",Sep 25 at 17:12
19,5,67,"@ThoriumBR The assumption that they want the app to be invisible and unobtrusive is also dubious. The Chinese government conducts surveillance by coercion, not subterfuge - they're not installing this app remotely without users' permission, they are (allegedly) demanding that they install it under threat of arrest. They have no motivation to hide what it does; anyone who gets angry and decides to bypass it can simply be publicly punished as ""subversive""; that's how totalitarianism works.",Sep 25 at 17:18
19,6,220,"Given how insecure the spyware appears to be, simply installing it will likely open you up to attacks from actors other than the Chinese government.",Sep 25 at 16:50
19,6,221,"@AndrolGenhald: Probably, but if you can't leave the country, what else do you want to do? Not complying is not an option, really.",Sep 25 at 16:52
19,6,220,"The situation certainly sucks. I just wanted to point out that even if you accept that it's ok for the Chinese government to do this, there are still other risks.",Sep 25 at 17:03
19,6,222,"This doesn't really answer the question. It's about ""I know I'm targeted. How do I defend?"". Your answer is basically ""How to avoid being targeted"" and therefore not really answering the exact question.",Sep 27 at 11:02
19,6,221,"@iBug: That's true, but sometimes ""Don't do it"" is the right answer. There's too much at stake, and chances that OP gets caught are high (I'd say 99%). The spyware transmits the IMEI, so they know exactly who isn't sending. They also know exactly who had the spyware installed. So... not good.",Sep 27 at 11:06
19,7,223,This will not help in case of keylogger spyware.,Sep 25 at 8:41
19,7,224,How can a keylogger affect this approach ? Please explain.,Sep 25 at 9:08
19,7,223,"Bare in mind that, keylogger can keep data inside the phone. So if the phone confiscated by the Big brother, the user still susceptible to phone activities forensic.",Sep 25 at 9:17
19,7,225,"I believe the first paragraph is the most critical one. OP is not alone in this, it's a big community of people affected and they will have found a workable solution. Just be aware that the more people fooling the system, the more likely the government will pick up on it and close the loophole. If you're using a method that gets closed there's a chance their net will catch you.",Sep 25 at 10:24
19,7,224,@Ruadhan2300 I mis read indeed your comment. I totally agree with you on that point.,Sep 25 at 11:28
19,8,76,There are certainly ways to defeat this spyware without raising red flags. It's not like the spyware's functionality is particularly secret (or particularly sophisticated).,Sep 24 at 13:45
19,8,226,"Police might not be information security gurus, but they are good at telling if I am hiding something in my other pocket. Then the consequences might be worse.",Sep 24 at 13:53
19,8,214,"I really doubt this is true, and even if it is correct you are not providing any evidence of that fact.  Rather, you are expecting everyone to just take your word for it.  Given the importance of this question to the OP, I think a little more effort is required.",Sep 24 at 16:00
19,8,227,"@forest But it might not be the same tomorrow as it is today, and that can make all the difference in defeating it or losing to it. When we're talking an oppressive government, can you, in good conscience, really tell someone you've never met to take that risk?",Sep 24 at 19:47
19,8,228,"Note that with the cooperation of network carriers, they will be able to tell if you are using another cellphone with the same SIM card, or if a subscriber has two SIM cards nearby, or the number of devices that are connected to your home WiFi or network. It may be unwise to use a second phone in any case.",Sep 25 at 16:58
19,9,230,"If I were trying to monitor everything, I would have code that flags packets going through the towers without corresponding reports from my spyware.",Sep 26 at 11:36
19,9,231,That would be very difficult to do.  Nothing is ever 100%.,Sep 26 at 13:41
19,9,230,"It would indeed be difficult to catch 100%.  It would not be difficult to catch 90%.  And if they weren’t already catching a huge percentage of what they want, threads like this would not exist.",Sep 26 at 16:45
19,9,232,"""Hang on, there are packets flying back and forth, but they are not connected to any running app ... Flag this phone as suspicious.""",Sep 27 at 11:37
19,9,79,@tripleee do people not use tethering in China?,Oct 1 at 2:34
19,10,230,"If you CAN afford a second phone, either they find out when you buy it or they find out when you use it.",Sep 30 at 23:43
19,10,233,"This is what I'm saying, the cellphone tower reports people in the area that aren't running the APP and then they can triangulate you and pull up a CCTV image of someone walking the path of the offending phone. Also, chances are this webpage is no longer available to the majority of the people there.",Oct 1 at 0:11
19,11,234,"your answer is good.   and is also just an example of how complicated it is to do monitoring and surveillence, which seemed like is an easy job to do.   your answer examplify the many variations of technologies that are available for monitoring and anti-monitoring - just like the end-less game of virus and anti-virus.   which is also why i hardly read all other solutions and techniques, which is not as technically deep as I wanted (from the monitoring/trojanizing point of view).",Oct 2 at 0:52
19,11,234,"talking about PC:   you also have chrome bugs reporting, windows telemetry etc all capable of sending back debugging information.   if they want to monitor, and you are not doing anything ""harmful"", just let them do it - it is like having a security guard near your house.   and you may be afraid that one day this security guard may come back and attack you?   then get multiple security guards.   Apps that can monitor other apps - like those of parental control apps which I used to install on my kids' phone.",Oct 2 at 0:55
19,11,235,@PeterTeoh Thanks. Variations as you rightly pointed out is the key to both sides. For those who care this is an endless game but sadly majority dint care IMO,Oct 2 at 5:13
19,12,235,+1. Unfortunately rooting and using niche tools like XprivacyLua is not for everyone ( I use).  Just as FYI am alternative in my answer security.stackexchange.com/a/194842/99059,Oct 2 at 5:15
19,15,232,Presumably then the app will alert that it cannot call home and display a big friendly red badge with yellow stars.,Sep 27 at 11:38
19,15,239,I'm not sure how the app works exactly. It could definitely be passed off as server-side error that wouldn't be your fault. You can also change it whenever you are about to be inspected and otherwise have it set to block traffic.,Sep 28 at 20:32
19,17,241,"Most of this answer is just saying ""lol you're f---ed good luck"", it doesn't really try to answer the question itself. Even if you factory reset your phone, if the police are on the streets, as the question says they are, they're just going to stop you and demand you install it again.",Sep 29 at 0:46
19,17,242,"@MatthewElvey people are sometimes being sent to ""reeducation camps"" for not having the software installed in this province, and they keep track of who has it installed. If it is suddenly not sending data anymore, they WOULD catch that. Not only is this answer not helpful, it is genuinely dangerous, especially if OP is Uyghur.",Sep 30 at 5:35
19,17,243,"Ok, thanks, user185163.  If the excuse/explanation:  ""I didn't remove it.  I was having trouble with my phone and the phone vendor removed it when they reset my phone.  Here's a receipt / record of the visit.""   won't work to avoid 'reeducation camp' then my ""idea to consider"" indeed was poor and I've just edited my answer to reflect that.  What do you think now, @user185163 ?",Sep 30 at 18:59
19,17,243,I've radically edited my answer; would appreciate more re-rates and/or more feedback.  I find it interesting that the playing dumb strategy is said to be sure not to work in China. I imagine it might be useful in other countries/other legal systems.  But then the only repressive regimes I have significant experience with are the relatively lighter touch ones in the US.,Oct 7 at 23:57
19,18,220,Transport encryption doesn't do any good if the endpoint is compromised.,Sep 24 at 15:13
19,18,244,They'll generate a report on him stating that he uses Tor/VPN? What a recommendation...,Sep 24 at 22:21
19,18,217,"The spyware is locally intercepting the data, making both TOR and a VPN more than useless.  Those change and somewhat protect the path your data takes through the internet, they don't change what your device is doing before that!  And if the spyware sends its report over one of these the government could easily notice that they're receiving data from a known TOR node or VPN service....",Sep 24 at 22:40
19,18,230,They also know what phones are using which towers and whether those phones are reporting.  And they shut down/block VPNs when they detect them.,Sep 26 at 11:45
20,1,246,"Another reason is usability. Sending an SMS to a new number is more of a hassle, and much more error prone, than receiving one and getting a short code from it. Users should also be rightfully wary of letting random apps send SMSes, so automating the SMS sending isn't that good an idea.",Sep 17 at 17:29
20,1,247,I'd also be concerned about that getting hijacked and causing me to subscribe/pay for a premium texting service unintentionally.,Sep 17 at 19:42
20,1,248,"Sadly, it's not super hard to send a fake sms from arbitrary numbers on certain carriers :(  Intercepting the user receiving a message at least requires you to be near the person physically to easily intercept.",Sep 17 at 20:52
20,2,250,"Further to that, it's usually impossible to tell in advance how much an SMS to a certain number would cost. ""Premium"" numbers can charge an almost-arbitrarily high amount for SMS sent to them on top of operator costs. Therefore, ""send us an SMS"" is rife for scams.",Sep 18 at 8:53
20,1,237,"Actually, I see how it could be set up.  Don't have a fake login, but rather a real but restricted login.  Apps and data would either be open or restricted, if you were in the duress login you would see only those things not marked as restricted.",Jun 2 at 0:33
20,1,252,"@Loren that's a neat idea. The duress login could include limited data (maybe a few old documents) and intentionally broken apps. For example, the fake login could have an online banking app that looks real, but that always crashes. Mobile data could be restricted (""Sorry, you've used all your data for this month""), and apps could then whine about how they won't work until they can connect to the Internet.",Jun 2 at 2:46
20,1,237,"@RobertColumbia The tactics would be known, you can't use things like that.  But have the baking app on the restricted list--with the duress code you simply don't see it.  So long as you use apps for the sensitive stuff even someone who knows how the system works can't tell if it's the duress code or not other than by rooting the phone.  If you want to make it even more secure there are two duress codes--if the second is used the entire sensitive dataset is deleted.  (Use the first on the snoopy official, the second if arrested.)",Jun 2 at 3:30
20,1,253,"That's not so difficult to achieve: ask the users to do it for themselves. For example, when you create a Facebook account  then FB can prompt you to create your ""dummy profile"" in case you are compromised. Still I think hackers will know it's fake and, since is a well known feature for all its users, it wont have any effect.",Jun 2 at 18:46
20,1,254,"Even when access is granted to obviously fake data, that data still has to be processed to determine that it is fake, making it take longer for the hacker to gain access to the real data.",Jun 4 at 7:02
20,2,76,I don't think that's what plausible deniability is. Honeypot != plausible deniability.,Jun 1 at 13:22
20,2,255,"@forest: The question is a bit confused, because it describes a honeypot but the use case (criminal pointing a gun at the phone's owner) demands plausible deniability.  This answer addresses the use case.",Jun 1 at 14:12
20,2,256,@BenVoigt that's still not what plausible deniability is,Jun 1 at 17:33
20,2,255,"@Kevin: It's exactly what the term ""plausible deniability"" means in the context of cryptosystems.  In addition to VeraCrypt which this answer mentioned, see also LUKS, TrueCrypt.",Jun 1 at 18:59
20,2,257,"@Kevin where it comes to crypotsystems, plausible deniability essentially means that when forced to provide access to content secured by a password/encryption, once I provide that access (give my account credentials, enter password/decryption key), I can claim that I've given access to the content I've secured and the adversary cannot reasonably prove otherwise. I can plausibly deny that the real data is still hidden behind yet another key/credential and that I've actually provided access to the real data (or all the data that's available).",Jun 1 at 20:00
20,3,259,"Yep! This is why, above all of your other passwords, regardless of your password system, your email password should ALWAYS be unique.",Jun 4 at 11:27
20,3,260,And always mean Not even with an account of an obscure phpBB forum from 2001. Or an android application thats ask for an username/password even if you used it for 5 minutes. Or an old torrent traker. Especially with Android apps when an apps can request the mail of all device account then check with the used password.,Jun 5 at 14:10
20,4,252,Will airport security in Oceania even allow you to fly to Eurasia? I thought Oceania has always been at war with Eurasia.,Jun 2 at 2:50
20,4,262,People keep devising increasingly clever technical means to defeat a potential request to unlock a phone/laptop/data carrier at a border/airport inspection but I don't see how any of this helps. You might just as well flat-out refuse to give them your password. You might end up in detention or being refused entry but that could also happen while deliberately trying to lock your phone and playing dumb won't help you. The real solution is to avoid taking any sensitive material over the border.,Jun 2 at 9:30
20,4,263,VeraCrypt is an example of a program which implements it - you can set up an alternate password which will uncover only fake part of the data,Jun 2 at 13:18
20,4,264,"In real life, it is however much more likely that instead of ""letting you go on your way"" they will confiscate the equipment and give it to their forensic analysts, detain you, and put you permanently on ""possible terrorist"" list. Or worse.",Jun 3 at 19:49
20,4,265,"@RobertColumbia ""I thought Oceania has always been at war with Eurasia"" They have. Until Oceania makes peace with Eurasia, then they will always have been at war with Eastasia.",Jun 4 at 9:16
20,6,267,Also interesting is Turris from NIC.CZ turris.cz/en,Jun 4 at 20:45
20,11,272,This answer is comedy gold! 😂,Jun 5 at 8:37
21,1,275,"Thank you. I'm Facebook linked. The scammer can know my first and last name from it, date of birth, and Gmail address. Is this sufficient information the scammer can use to do this ""social engineering"" thing where they convince a customer service rep that they're me and gain access to something of mine? I don't have an online account for bank services, so I think my money is safe.",Mar 29 at 17:49
21,1,276,"Technically, yes. But I doubt it would be of any use. It's not like they can magically take over your gmail account and click on activation links etc. But as I said, I think in this situation, their goal was a Telegram account. There's much easier ways to hack people than social engineering based on a handful of public info!",Mar 29 at 18:51
21,1,277,@Dooma You should make your birth date and email private on Facebook...,Mar 29 at 21:48
21,1,275,@Bakuriu Did it.,Mar 29 at 21:57
21,1,278,"@Nomad, Perhaps, they thought that Dooma had an account on Telegram (since Telegram doesn't have encryption turned on by default, then that means they could have accessed his private messages if he had any). thehackernews.com/2016/08/hack-telegram-account.html",Mar 29 at 22:05
21,2,279,"Sadly we cannot tell who has good intentions or not, so caution is everything, if someone asks for your contact ask them to send theirs first. You can easily know if its real or not at that point.",Mar 29 at 20:57
21,2,280,"Multiple applications can connect to the same telegram account, unlike whats app",Mar 30 at 14:31
21,3,275,Thanks. I'll see what I can do regarding a new number.,Mar 29 at 18:35
21,3,281,"Most automated attacks via MMS/SMS target a wide range of numbers. You're no more at risk to those attacks for having shared your number. If it is a targeted attack, then you may be in trouble, but this doesn't seem like a targeted attack. So changing your phone number seems a bit of an overreaction.",Mar 29 at 19:00
21,3,275,Interesting point.,Mar 29 at 20:13
21,3,282,"also, to protect against this, it's far more important to install system patches (aka updates) on the smartphone.",Mar 30 at 10:49
21,3,283,"The original poster should not change their number. There is no risk if they didn’t go past what was described in the original post. Had the original poster gone further and given up more info, then maybe that is a risk. But at this point the risk is silly at best. Many phone numbers are public in some way so changing a number is rash… It’s only advisable if that number is connected to something and the scammer can connect the pieces. As it stands, utterly no risk but a wee bit of sweat from the stress of realizing that one might have been scammed.",Mar 31 at 1:36
21,4,283,"100% correct. The vast majority of phone numbers are public for the most part. The risk only comes if that phone number is somehow connected to something nefarious or some two-factor authentication scam. Either way, this was a “nibble” at a scam and not a scam.",Mar 31 at 1:33
22,1,9,"@RafiRosa To be honest, I don't think you will ever be able to say for sure where it came from. But in the end, what you need to do is the same - a factory reset.",Mar 27 at 17:21
22,1,286,@RafiRosa You can sideload apps that have valid Apple-signed certificates. Otherwise they jailbroke your phone for you.,Mar 28 at 3:54
22,1,287,@Rafi Rosa It's possible the app was compiled directly from XCode to your phone or using TestFlight.  Other than jailbreaking this is the only way unapproved apps can get on your phone.  That pretty much means you should stop using your phone and wipe it ASAP.,Mar 28 at 17:29
22,1,288,"@Anders I have done a complete factory reset of my phone and changed all passwords that I used while using it. After that all of apps I have previously installed were restored by iPhone and all of my files were stored on iCloud, is it all I can do?",Mar 28 at 19:47
22,1,289,"@ray That's not a thing on iOS. Carriers do not have control over firmware updates, and cannot force-install apps.",Mar 30 at 19:40
22,3,291,"Unfortunately, it's pretty common for repair shops to ask for the PIN to log in and verify all hardware functionality after opening the case, just in case they knocked something loose (camera, GPS, bluetooth, etc) which isn't detectable on a lock screen. I go to a shop nearby that will do repairs while you wait so I can log in for them to check while I watch, but I've seen plenty of customers give up the PIN without a moment's pause.",Mar 28 at 20:35
22,4,293,"Unless the employee who didn't know was just working the cash register & did not know that the repairs guys in back routinely install helper apps & remove them after the repair is complete (and forgot to this time). In any case, restore from backup",Mar 28 at 10:58
22,4,294,Might be worth reporting it to the police also so that they can send someone in undercover to do an investigation if they have the will and resources (though they won't),Mar 28 at 12:18
22,4,288,"That was my first thought, that it's some leftover software to test the battery, but the guy who repaired it said that it was already there and didn't have anything to do with it.",Mar 28 at 15:22
22,4,56,"It's a problem if they unlocked the phone at all, even for testing.",Mar 28 at 19:31
22,4,236,"It's a problem for us security aware folks, but most people and most repair people don't see a problem there. And often they are right and not all persons with access rights do bad things. But when they don't tell the truth afterwards, the trust is gone.",Mar 29 at 7:20
23,1,228,"I might be wrong, but I think iPhone applications are sandboxed and a key logger cannot be installed except if the OS has been jailbroken/rooted, or an alternate on-screen keyboard has been installed (which the user can check).",Jul 28 '17 at 13:56
23,1,300,could potentially install full monitoring and install things like key loggers Without physical access to the phone. How would they achieve this? OP only said they pay the phone bill,Jul 28 '17 at 15:20
23,1,301,@users1 If they enrolled it in the orgs mobile management server.,Jul 28 '17 at 15:27
23,1,56,"In any reasonable world, there wouldn't be any way to ""enroll it in the mobile management server"" without explicit consent from the owner of the device, unlocking it and selecting an option to enroll it. However I wouldn't put it past phone vendors to put carrier backdoors in that allow the carrier to enroll the device without the owner's consent...",Jul 28 '17 at 17:34
23,1,301,"The question didn't mention physical access, typically the enrolment will require the user to click a link in an email, scan a QR code or something similar. In my experiance in a byod situation the user will typically be required to complete the enrolment. If the phone is issued then it will be pre-enrolled. Not all orgs will require it to be enrolled, but if it is then all of what has been said is possible. If the org is paying the subscription, then they may require it to be enrolled. This would be a fairly standard and reasonable request, especially if corp data is ever on the device.",Jul 29 '17 at 8:11
23,3,56,"And 4, buy yourself a personal device, consider your already-purchased device a loss and a lesson if you can't get your employer to pay for the BYOD they already duped you into buying, and start keeping work and personal devices 100% separate and isolated.",Jul 28 '17 at 17:36
23,3,228,"I know of no mobile provider that allows the customer to view which Internet sites they accessed (which requires a proxied connection or deep packet inspection), not even which IP addresses traffic was sent to. Can you point at some example(s)?",Jul 28 '17 at 14:00
23,3,101,"I don't know of any that would do it for an end user account, but all the big EU providers offer these types of services to enterprise clients. Vodafone, EE, etc.",Jul 28 '17 at 14:04
23,3,228,@GdG however I have searched and I couldn't find any web resource where Vodafone (or other operator) describes such facilities for business customers. And I'd really like to see it.,Jul 28 '17 at 14:49
23,3,7,"@GdD It would also seem to be a potential privacy regulations nightmare, even more so in light of the EU GDPR coming into effect next summer. A citation for your claim that ""all the big EU providers offer [detailed traffic monitoring] services to enterprise clients"" would much improve this answer. Even just a link to a single such provider's web site showing that such service is available in some location within the EU would be beneficial.",Jul 28 '17 at 14:56
23,3,101,"I couldn't cite that without violating agreements @MichaelKjörling, and I'm not going to do that. Regarding the GDPR, an organization can perform surveillance on employees if it has a legal requirement.",Jul 28 '17 at 15:04
24,1,303,"This is makes no sense. Both the hashed password or the password itself can serve as an authentication key. If an attacker can break your transport security then they can get your key and break the system. However, hashing on the user's end is a great idea because if this transport security is broken then the attacker only gets a hash instead of the user's password.",Oct 11 '16 at 3:10
24,1,304,So should I hash server side or client side?,Oct 11 '16 at 3:20
24,1,304,"I'm confused, some places say hash user side, some places say otherwise.",Oct 11 '16 at 3:34
24,1,57,"@David: the only thing proven by the client sending a hash is that the client knows the hash, not that the client knows the secret (the original password). If the transport layer security is broken, it doesn't matter if the attacker only sees the hash, because it's as good as the password. Better, in fact, since if the attacker got hold of the password, they would h ave to go to all the trouble to hash it with the correct algorithm and correct number of iterations before sending it. By hashing client side, you've done that work for them.",Oct 11 '16 at 4:47
24,1,305,"@Tobiq No, hash on server side ONLY!",Oct 11 '16 at 9:17
24,5,304,Will the client side hash match the server side hash??,Oct 11 '16 at 3:22
24,5,303,"If they use the same hash algorithm and salt, yes.",Oct 11 '16 at 3:55
24,5,57,"Which means you have to publish the algorithm, and the number of iterations. TLS isn't perfect, but if it's broken and the bad guys get the password hash, it's game over anyway, because in this scheme the hash is the password--literally no difference at all. The hash is the password. This is wrong. It sounds like you're just trying to mitigate blame on the server side so you don't have to take responsibility if you screw up your TLS configuration.",Oct 11 '16 at 4:52
24,5,57,"The only thing that sending a hash to the server proves is that the sender knows the hash, not that the sender knows the original secret (the password). A bad guy could intercept the hash and use it to login just as easily as they can intercept the plaintext password and use it to log in.",Oct 11 '16 at 4:57
24,5,57,"I believe we collectively have an obligation to provide complete and accurate answers to these kinds of questions if we're going to answer them at all.  ;-) The fact is that overall security in the context we're talking about is ONLY served by hashing on the server. Hashing on the client can augment security, but it can also dramatically decrease security if it's done wrong. Far too many answers seem to come out and declare that hashing on the client is better, and a replacement, for hashing on the server, and that simply is not true.",Oct 11 '16 at 18:30
25,4,312,"Could you add a source for your claim, that it is not recommended to change the base image?",Mar 22 at 12:34
25,4,313,"Changing anything from the base layer, which is generally a Ubuntu or similar (as @LieRyan said, Alpine is one of the most minimalist base layer out there), implies creating another layer in the final image to redefine the FileSystem, requiring to rebuild most part of the container (all the layers above the application itself) on any small change on the application or code. Creating a container (at least in medium-big projects) implies a previous planning on its layering, not just start deleting things trying to harden the deploy. Regards",Mar 22 at 17:45
26,1,111,"Can't you use the same encoding (<>""'& to their equivalent entities) for HTML, HTML attributes and XHTML?",Jul 7 '16 at 13:26
26,1,66,@CodesInChaos: If you have a pure (X)HTML context this should be ok. But there are slight differences in Javascript context in HTML vs. XHTML context. Try <script><![CDATA[ var foo='</script>'; alert(foo); ]]></script> within HTML and XHTML context.,Jul 7 '16 at 13:53
26,1,316,"What difficulties would there be with having a DOM object attribute which would indicate ""This object will never legitimately contain any 'dangerous' objects or attributes outside certain categories, so the effects of any such objects/attributes should be stifled""?  While ensuring safety with browsers that lack such a feature might be difficult, having a means of setting one string to create some text that includes bold and italic would seem much cleaner than having to assemble such text as a bunch of DOM objects.",Jul 7 '16 at 16:55
26,1,66,"@supercat: have a looking at Content Security Policy 2.0 which has nonces to mark parts where inline script is safe and can otherwise forbid inline script at all. But of course you need browser support for this, support in the frameworks and knowledge of the developers that this feature exists at all and why they should use it.",Jul 7 '16 at 18:44
26,1,317,@supercat: markdown is a safe way to allow user markup.,Jul 7 '16 at 20:05
26,2,7,"Another thing you may want to add while you are at it later, is overlong UTF-8 sequences.",Jul 7 '16 at 14:18
26,2,317,"I wrote my own sanitize function, and i thought it was easy, what am i missing? it's only hard if you try to implement 1,000,001 things yourself. I run marked on the sanitized text to get clickable links and allow markdown formatting, and from everything i've seen, it's safe and sound. It was harder back in the IE days, but most bugs have been fixed, so now it's only gaping holes that need patched up.",Jul 7 '16 at 20:08
26,2,9,"@dandavis I think the function works fine to stop XSS between tags. If you use it sanitize attribute values when you concatenate a HTML string it would not work, since it does not escape '. So understanding the context is key.",Jul 7 '16 at 21:05
26,2,317,"really good to know, thanks! you're right that there's not something equally simple for attribs, since new Option(0,str).outerHTML.split('""')[1] doesn't work in IE/Edge...",Jul 7 '16 at 21:59
26,3,318,Why is #2 relevant here?,Jul 7 '16 at 13:56
26,3,319,"Sorry, but my work day is 8 hours, not 12 hours. MAYBE 10 if I include my commute.",Jul 7 '16 at 14:56
26,3,320,"I think the use of the word ""stupidity"" in this context is rather extreme, insulting and simply incorrect. Programmers who leave their code open to such vulnerabilities are most likely not stupid, but instead (a) ignorant, (b) unskilled or (c) under a lot of pressure from management to deliver features fast and cheap (while security concerns are last on the list, or not at all).",Jul 8 '16 at 7:48
26,3,321,"@RaduMurzea I completely agree with you, you are more then welcome to edit my answer!",Jul 8 '16 at 8:14
26,1,324,"Thanks. What I meant by ""as secure as possible"" is ""as secure as possible given my knowledge and my capabilities"".  If I install an anti-virus on my system, I certainly made my system more secure. But can I say, I secured my system?",Mar 20 '16 at 13:35
26,1,116,A system can never be 100% secure,Mar 20 '16 at 14:22
26,1,325,"@othman I'm definitely not a security expert, but I think that it depends on many things, including what your system actually is (personal laptop with no credit card info,etc.;personal laptop with credit card info,...;corporate laptop;web server;...) and how much money/resources can you invest.",Mar 20 '16 at 18:06
26,1,92,@LucasKauffman no worries - just thought I'd give you a head's up,Mar 24 '16 at 15:02
26,5,281,"The question is about appsec, not the theoretical details of encryption. I know the word 'appsec' may isn't in the text, but it is the tag the OP chose.",Mar 20 '16 at 16:32
26,5,329,You think that cryptography is not related to appsec?,Mar 20 '16 at 16:33
26,5,281,I think you only partially (very partially) answered the question and provide no practical advice to the OP.,Mar 20 '16 at 16:38
26,5,329,"Yes I partially answered the question and I stated it ""In terms of cryptography"". Partial contribution, is a contribution anyway, right? I just added something which other answers don't have.",Mar 20 '16 at 16:40
26,5,281,"Yes, upon rereading the question, I see you did respond to it.",Mar 20 '16 at 16:44
27,1,330,"I agree that prompting for the password seems to be the most sensible solution when faced with user managed username changes.  However, some systems (e.g. Microsoft Active Directory) allow administrators to change usernames without user involvement.  In these situations the requirement for a user to provide their password isn't really compatible.  I suspect your other suggestion of hashing all variations may be the only workable option of meeting the requirement.  Otherwise we may have to be willing to allow for the risk of an admin-changed username matching a password.",Mar 7 '16 at 19:53
27,1,331,@PwdRsch why would an administrator want to change usernames without user involvement? I can not imagine a legit use case.,Mar 7 '16 at 19:56
27,1,281,"@PwdRsch - Perhaps you can do the uname/password check on every login? Or on the first login after a username change? That said, how about you just fail to meet the requirements in those edge cases? They hardly seem worth worrying about.",Mar 7 '16 at 20:03
27,1,332,"@emory brings up a good point. If the admin changes the username, what do you do if your policy is violated? Just not change the name? Use a different - incorrect - name? That doesn't make sense. (when the user changes it themselves, you could require a password change, but letting the admin change the password doesn't seem desirable; if it were, you could just make a password change mandatory and not have a problem)",Mar 7 '16 at 20:11
27,1,333,"If the admin changes the username, you could set a flag that the password needs to be changed. A link is sent to the user, notifying the change. The very next time that user logins, the password has to be changed. In my case, I always try to force the use of paraphrases which are way longer than usernames. Even better, ditch the password and use keys instead.",Mar 8 '16 at 1:26
27,2,330,"I do agree that a determined user can choose a weaker password than we might like, despite the policy rules or other controls we use to prevent bad choices.  However, I don't feel like this requirement (as stated) is taking things too far.  Pair that technical control with education as you suggest and hopefully we gain the security advantages of both.  However, just because most attackers will make guesses beyond a password matching the username doesn't mean that we shouldn't attempt to enforce this rule. We still need to eliminate the low hanging fruit.",Mar 8 '16 at 16:55
27,2,157,"@PwdRsch I don't disagree, my point, I suppose, is that you don't need to hide what you're doing from the user - explicitly requiring them to enter their password when making a name change, or running the same check the next time they log in after an admin changed their name, actually improves the education because it gives them a reason to pay attention.  That said, if an admin is able to, essentially, accidentally guess a user's password when selecting their username, then that's a reason to offload the education onto the user anyway because that was a horribly chosen password.",Mar 8 '16 at 20:59
27,3,332,"Depending on the hashing and the hardware, it may take around a minute for that. If an admin changes the username that might be fine (if it is clearly displayed that this is a slow process), if a user changes it, a minute might not be acceptable. It may result in problems, eg users resubmitting forms and then not knowing with what username they ended up with, or users closing the window before they get the message that their new username is not acceptable.",Mar 8 '16 at 14:32
27,3,334,"@tim It needs to be slow. Otherwise, an attacker who takes over the server or has a replica of the server could simply keep trying to change the username until they figure out the password (in practice they could make something much better than the server). You can trade speed for space though: en.wikipedia.org/wiki/Scrypt",Mar 8 '16 at 17:00
27,3,157,"If you (assumed to be a non-expert password cracker) can brute force it, an attacker can do the same much, much quicker.  If you are an expert password cracker, then you already know the futility of what you're doing.",Mar 8 '16 at 21:00
27,3,334,"@Jason you don't need to know the password, just make sure that the username isn't the password.",Mar 8 '16 at 21:01
27,4,335,"Brenda Utthead would have a colorable objection to your proposed policy, especially if usernames are used in public communication.",Mar 8 '16 at 5:11
27,4,331,@DamianYerrick To be clear it is my understanding that the OP has a strict requirement that userids be derived formulaicly from legal names and not match passwords.  I think users should be able to pick their own userid which need not resemble their legal name.  Brenda's objection has more to do with OP's requirements than my policy.,Mar 8 '16 at 8:44
27,4,331,"@DamianYerrick in comments, the OP said that if Brenda Smith (userid bsmith, password butthead) married Rick Utthead (userid rutthead) and took Utthead's name, then the admin would have to change Brenda's userid to butthead but that would be a problem because now her userid and password are the same.",Mar 8 '16 at 10:33
27,4,331,"@DamianYerrick but if you believe that the userid matching the password is not the big problem in Brenda's scenario, then I have to agree.",Mar 8 '16 at 10:36
27,4,336,"@DamianYerrick Cisco Systems actually did that, and seemed spectacularly unlucky with their staff names, along the lines of Chris Rapherty, Simon Hitchin, and so forth. I believe they also truncated their usernames to 8 letters. Much amusement (outside Cisco) ensued.",Mar 9 '16 at 8:25
27,5,330,This was one of the early answers offered as a seemingly good option that the poster then later deleted once people chimed in with the warnings you list. ;)  I agree that the tradeoffs in security don't really make this worthwhile.,Mar 8 '16 at 17:22
27,5,337,"@PwdRsch Oh, thanks - I didn't realize. This answer, for once, I'd be perfectly fine to see getting uncommented downvotes :)",Mar 8 '16 at 18:11
27,5,19,@DewiMorgan You could make it CW... that way you wouldn't lose rep for the downvotes.,Mar 8 '16 at 18:16
27,5,337,"Ooh, thanks, @wizzwizz4, I didn't know that. Done! Feels kinda... naughty and exploitatious, though :(",Mar 8 '16 at 18:27
27,1,338,"Thanks for the long description ! But do you know if there is HIPAA equivalence for England ? I'm not encrypting data with SQL command but via my app. So in theory it's harder to decrypt ? I didn't really understand fully what you describe, will try to look into it.",Nov 3 '15 at 21:51
27,1,339,"HIPAA is a U.S. law so it does not govern healthcare data in England.  However, the Data Protection Act (DPA) and the soon-to-be-adopted EU GDPR will govern data located in the UK.  I am no expert int he GDPR, but it does include provisions similar to HIPAA regarding the use of encryption.",Nov 3 '15 at 22:01
27,2,338,Thanks for the answer ! This is more like a worst case scenario plan than anything else.   There is many things to do before getting to steal the DB data but I'm not well aware of security requirement (To make it more funny : It's not the same requirements depending on the country...).  But don't you think the solution I provided on the original post (optimius package) would be kind of weak to secure the data ?,Nov 3 '15 at 15:38
27,2,340,"I was not able to follow the link to the optimus package, but you sound quite correct that obscuring ids will still allow for a pattern recognition. If you change one id to another equivalent id then you still have matching ids. If someone accesses your entire DB, it is reasonable to believe that they may also have access to the controlling files including the methods of obfuscation and encryption.",Nov 3 '15 at 16:00
27,2,338,github.com/jenssegers/optimus here is the link :),Nov 3 '15 at 16:03
27,2,340,"The Optimus could work if you only used it on only one table (patient or doctor table for example). Then, if someone got the entire DB but not the Optimus constructor values they would not easily make any direct connections (perhaps comparing appointment times could be used to circumvent this entirely). It still, however, adds a layer of difficulty to building and maintaining the entire system and the payoff is not encryption, but rather security through obscurity. It's merely a more sophisticated obfuscation than using base64 or another encoding method.",Nov 3 '15 at 16:19
28,1,265,"If I remember correctly, some of the initial ""jail-breaking"" methods for Sony's Playstation Portable (PSP) used a ""specially crafted"" image file that broke the PSP's decoder and allowed code embedded in the JPG to execute.",Aug 27 '15 at 12:28
28,1,343,"""attacker could potentially execute arbitrary code"" is that boilerplate for any buffer overflow bug?  Elevating privileges from the user-mode thread would be another problem.",Aug 27 '15 at 16:25
28,1,35,"@JDługosz, yes, that's a standardized description.  Most CVEs and descriptions of security holes use a set of standard phrases like ""[local|remote] attacker could potentially execute [arbitrary] [commands|code] [with [user|elevated] privileges]"".  The re-use of succinct keywords and phrases (""boilerplate"") allows defenders to quickly assess risk - for example, the [local|remote] keyword is important in assessing risk.  The phrasing used in the GDI+ announcement tells me the code runs with the privileges of the user opening the JPEG - in 2004-2006 Windows, often an Administrator!",Aug 27 '15 at 16:48
28,1,344,"This exploit would only be possible if the decompression algorithm in question had a bug in it that allowed arbitrary code execution, correct?",Aug 29 '15 at 3:19
28,1,345,"@TripeHound yep, rainbow colors, ghost in the shell cover picture and tiff format to use chickHEN. I still have those somewhere around here. Edit: yep, chickHEN but not tiff :/",Aug 29 '15 at 13:18
28,2,346,"Actually, the media framework is called ""Stagefright"", but the name is already catchy enough to name it ""Stagefright bug"". /offtopic",Aug 27 '15 at 19:02
28,3,348,"Yes... sooo hard with unmanaged code -.- If one would just code in managed code, buffer over/underflows would reduce to below 1% of their current impact on security...",Aug 28 '15 at 11:35
28,3,316,"If C compiler writers were interested in promoting robustness, C could outperform Java for many tasks where the semantics are ""Given valid input, produce correct output; given invalid input, produce loosely-constrained output"".  Unfortunately, compiler writers seem to have no interest in that, and prefer to optimize out logic which would prevent security-critical forms of UB if it doesn't prevent what would otherwise be non-security-critical forms of UB from occurring in those same situations.",Aug 28 '15 at 21:45
28,3,316,"@Falco: Managed code isn't free; on the other hand, since hyper-modern C is eliminating many of the performance advantages C used to have in cases where programmers didn't care about precise behavior in cases of things like overflow, the only way I can see C remaining competitive is to officially catalog behaviors that weren't guaranteed by the Standard but were widely implemented, and allow programmers to specify them.",Aug 28 '15 at 21:50
28,3,349,"@Falco Unfortunately, managed runtimes also have their share of buffer overflows. The people who wrote Java did a horrible job of using defensive programming to guard the runtime's weak spots. In fact, I just ran into one in the latest Java (and reported it to Oracle, who confirmed it). It all boils down to an ill-advised pursuit of premature optimization. I wonder if we suddenly have a breakthrough and can build 20 GHz chips, will programmers finally embrace bounds checks and such. Or are they too fn stubborn.",Aug 29 '15 at 10:41
28,3,350,"@AleksandrDubinsky I wouldn't hold my breath - we've had a few increases in the order of magnitude of processing speeds, and so many still cling to avoiding bounds checking. The reasons they had so far will still be the same if CPUs get 1000x faster. There is hope, though - for example, Microsoft Research had been working on a full blown managed OS from the ground up - it wasn't designed for performance but rather safety and security, but for a research project, it still performed well enough. And when the whole OS is managed, you avoid the cost of communicating between managed and unmanaged.",Aug 31 '15 at 8:20
28,5,353,"While the technique is possible against a buggy JPEG decoder, this doesn't appear to be an example of such. This is simply encoding a configuration file in a JPEG to hide updates to an existing infection. OP appears to be asking about JPEG images as a vector for transmitting new infections.",Aug 26 '15 at 19:20
28,1,354,"Couldn't you hash it twice?  Once on the client side, once on the server?",Nov 10 at 22:33
28,1,355,"@NathanMerrill - Hashing the password on the client side just makes the hash the password (absent some scheme to include extra information).  However, only securing the password is worthless - you have to at least authenticate the channel, or an attacker can impersonate both ends of the conversation, even without knowing the password.",Nov 11 at 4:55
28,1,356,"This is misleading. Yes, you can. This question asks for how to secure passwords when you can't use HTTP. A bad company policy, a misconfigured firewall can all force HTTP to be used. In situations like this, exchanging certificates (IPsec TLS SCRAM etc) through a side-channel is possible and should be the answer. Answer the question instead of giving advice that was not sought after.",Nov 12 at 1:17
28,1,332,"@noɥʇʎԀʎzɐɹƆ I did mention that there are alternatives when a secure side-channel can be used (which is required for the alternatives mentioned in other answers). But that's not really what the question is about (""The method should be usable in any browser""). There are definitely use-cases for these alternatives, but ""we can't use HTTPS because our infrastructure is too broken"" shouldn't be one of them.",Nov 12 at 10:40
28,1,9,"I agree with the main poin - it can't be done. But I'd add that even if you are Dave and roll your own crypto, it would not help. The code that does the crypto is delivered over HTTP, and can therefore be tampered with.",Nov 13 at 14:44
28,3,357,"You can safely do this with a fat client (a desktop or mobile application) that is distributed in a safe manner. However, with an in-browser thin client, the client code itself is delivered over HTTP as well, and as @AndrolGenhald pointed out, attackers in the middle can intercept and change it to send the password to them.",Nov 9 at 19:07
28,3,358,"@Zoltan That's very true, thank you for the clarification. The original question doesn't specify whether they need a thin or fat client, so my answer wouldn't apply in all cases. But even over HTTP, I think this provides some additional security. The attack has gone from just snooping traffic to modifying code. Nothing insurmountable, so it wouldn't be secure, but maybe less bad? And I think having both HTTPS and SCRAM is very beneficial.",Nov 9 at 19:17
28,3,357,"If you agree, you may consider mentioning this restriction in your answer. Otherwise I really like your answer as challange-response was my first thought too and none of the other answers mentioned it.",Nov 9 at 19:29
28,3,359,"@Melanie You are absolutely correct that even with just HTTP it's better. There are attackers only capable of passive attacks. That being said, there's no reason not to use HTTPS nowadays when it's free.",Nov 10 at 4:30
28,3,360,"@IanF1 The server only needs to know a Hash of the password. Also, all Browsers I know implement a similar mechanism: HTTP Digest Authentication, so even with a thin client one can use this method. On the other hand, HTTP digest is based on the obsolete MD5 hashes, but I am not sure how insecure it is due to this (MD5 is not broken for every application).",Nov 12 at 5:59
28,7,363,"Then some attacker can inject some code to get the password directly from the <input>. A crazy idea: ""Sadly it's just a little bit hard to support HTTPS on Reserved IP addresses. Please run this code on your terminal and paste the result HMAC were."" (of course disable copy pasting to prevent pastejacking in the long run).",Nov 10 at 10:34
28,10,367,"How is the DNS resolution protected? (1) Is the DNS resolver (a) local? (b) reachable by a secure link? (2)(a) Does resolution happen over the VPN? Is the authoritative DNS server reachable by the resolver by a secure link? (b) What happens if the DNS resolution occurs before the VPN is set-up? (c) Can false DNS results obtained before the VPN is set-up be cached? (3)(a) Does the resolver use DNSSEC? (b) How is validation failure treated by the resolver? DNS resolution can be secured, by it isn't trivial.",Nov 11 at 2:16
28,10,368,"@curiousguy The same can be said for HTTPS though, unless you manually verify the certificate.",Nov 11 at 22:11
28,10,367,"Unless you accept random unverified certs (by clicking through any alert box), or cert authorities get hacked (possible, but doesn't happen every day), or they are totally incompetent (also possible, but errors can be detected and revoked), when do you need to ""manually verify the certificate""?",Nov 13 at 0:03
29,1,83,How's that voluntary? Didn't you mean involuntary?,Nov 5 at 15:43
29,1,371,@d33tah because those helpful security probes are volunteering their resources to pen test your website.,Nov 5 at 16:22
29,1,219,"I mean voluntary. They are testing your site for free. Sometimes they even send you a damage report, but don't count on that...",Nov 5 at 17:34
29,1,248,"@ThoriumBR: Ah. The ""attacker"" is volunteering. Got it. That's also only questionably legal, last I checked. Not outright illegal, but a grey area.",Nov 5 at 18:50
29,1,372,"Nice to see these generous people for their volunteer work. Maybe they would even crack my site and create backups of my customer data, for free! It is very helpful. :-)",Nov 6 at 4:53
29,2,373,A great plugin for Wordpress is Wordfence. It automatically blocks suspicious requests. Also it makes it easy to view all traffic and block in one click.,Nov 6 at 3:04
29,5,375,Blocking the whole country will prevent all its people from accessing the website. Is this really a good practice ?,Nov 5 at 16:37
29,5,376,"No, it is definitely not a good practice ....",Nov 5 at 16:48
29,5,377,"No, but it's good security.",Nov 5 at 16:49
30,1,379,The current time must also be sent in any HTTP response.,Jun 8 at 9:36
30,1,380,Does it become a problem when the server time is not accurate?,Jun 8 at 10:26
30,1,76,"@ToddSewell If the server time is not accurate, an attacker can abuse that in various ways. TLS and certificates in general rely on accurate system time.",Jun 8 at 10:27
30,1,21,"Related, I wrote a guide to a bunch of different ways you can determine the time on a remote server.",Jun 8 at 11:33
30,1,381,"""as long as it is accurate"" This seems to imply that server time being inaccurate would be a security issue. Is it? If so, how?",Jun 8 at 22:23
30,2,382,"I think you misunderstood the ""To explain more.."" part. In contrary, I'm already assuming mobile app users are more likely to change the device time to cheat, that's why I need the server time for counter-checking. If there's a more correct way of doing this, I'm all ears. But thank you for your input as well.",Jun 8 at 10:51
30,2,383,"@Manny: send every command to the server. Have the server verify every action. You can assume in the client code that the server will approve and carry out consequences. If it turns out the server rejects an action (one second later e.g.,), revert on the client. This way, your server is the authority. Your server is (should be) 100% under your control and there you can trust things like system time.",Jun 8 at 13:58
30,2,384,"""Leaking"" system time should never be fixed. It is required to be revealed for proper operation of TLS and HTTP.",Jun 8 at 18:00
30,2,385,@OrangeDog exactly what I said in my answer.,Jun 8 at 18:07
31,1,379,"According to MDN, SRI only works for <script> and <link> subresources. What about other subresources like images, frames, etc.?",May 8 at 12:39
31,1,389,"@BenoitEsnard I don't know of any clever way to make that work for iframe or img, but it looks like they plan to extend SRI to other resource types soon (as I added to the answer).",May 8 at 13:06
31,1,390,"@BenoitEsnard eventually, you can load the image with javascript and check the signature.",May 8 at 13:32
31,1,391,"You could load the images without waiting for the JS, and only display them once the JS loads.",May 8 at 19:14
31,1,389,"@CandiedOrange Well, the main point is that flipping any single bit isn't sufficient to bypass SRI and inject a malicious script. Against a MITM threat, you'd obviously have to serve the original document over a secure channel (but not the script).",May 9 at 11:04
31,2,392,"Quick lower bound math. 32 sites. Let's say 10M hits a day. Lets say each website's homepage loads 200 resources (sampled homepages for wikipedia, Amazon, and facebook). Let's say each month has 30 days. Seven months. That's 13 Trillion requests. That is 0.386% * 10^6 requests experience this or one in a quarter billion. So yeah, I'd not worry about this unless OP is CTO for Twitter. Neat exploit nonetheless.",May 8 at 14:40
31,2,71,"@usr-local-ΕΨΗΕΛΩΝ Infrastructure problems are in the scope of the article. I quote: ""While a bit-error in the memory of a PC or phone will only affect one user, a bit-error in a proxy, recursive DNS server, or a database cache may affect thousands of users. Bit-errors in web application caches, DNS resolvers, and a proxy server were all observed in my experiment. For instance, a bit error changing fbcdn.net to fbbdn.net led to more than a thousand Farmville players to make requests to my server."". It does not really matter for this attack where and how the bitflip occured.",May 8 at 15:10
31,2,76,@Lan One in a quarter billion actually seems really high.,May 9 at 2:37
31,2,393,@Philipp I'd expect the server gear to have ECC memory to avoid exactly this scenario,May 9 at 8:46
31,2,394,"@ratchetfreak, while ECC can help, if your RAM is faulty it may be spitting out more error bits than the ECC can repair, even worse if it's your ECC chip itself that's faulty... However, the same argument applies, if the server even boots in this situation it'll be fairly unstable. Multi-bit errors that are too much for the ECC do occur, but at an even rarer rate than already noted.",May 10 at 16:58
31,3,395,"The author addressed point 2 by showing the fraction of source referral domains that were set at the original (the last figure on the page). Further, there was evidence of programmatic access to the bitsquat domains (Windows Update).",May 8 at 15:04
31,3,396,"Underrated answer: the article’s conclusion is very obviously bogus. Things like “several bit errors per request” are a dead giveaway that these are not, in fact, bit errors but some other source of errors (or, as mentioned in another answer, seriously broken pieces of hardware). Other than that, bit errors virtually don’t happen. The other answers follow red herrings: this isn’t a real threat, there’s no need to defend against it.",May 11 at 14:32
31,4,398,"àpple.com is not the result of bit-squatting, that's a different type of attack.",May 8 at 19:14
31,4,399,"@Barmar That seems like it is a vicious and undeserved attack on us poor souls that sometimes work in France, on those damn azerty keyeboards, but write only english... =(",May 9 at 11:03
31,4,277,"@Barmar I don't see where I implied that àpple.com would be a bitsquatting attack. Bitsquatting attacks are just a subclass of the more general ""similar-domain attacks"". The only difference between bitsquatting and things like typosquatting is that bitsquatting might happen due to bit errors in the computer/network. However my answer provide an effective defense for all such attacks. If the attackers cannot own the bitsquatted domain, the bitsquatting attack cannot take place.",May 9 at 16:22
31,4,398,"Yeah, sorry about that. I was mostly reacting to your last paragraph. Bitsquatting is not likely to be used for phishing, since the resulting name doesn't look like the original. It's only useful for capturing traffic that was intended for the original domain.",May 9 at 16:36
31,4,397,"Registering all bitsquat domains requires is O(n) domain registrations, with n the length of domain name. You can multiply n by ~254 factor. We are assuming at most 1 character flips and 0x0 not allowed. Retain any illegal DNS char to find the correct figure.",May 10 at 13:19
31,5,400,"I'm not sure how much this would help for bitsquatting. If a bit gets flipped somewhere in the network code while preparing a request for a resource, the CSP would still match OK because it gets checked before the request is started.",May 11 at 19:00
31,5,401,"Ah, it seems I didn't read into the question enough. Still, it can help by doing the same thing for IPs.",May 11 at 20:23
32,1,296,"To emphasize Peter's point on maintenance with some personal experience: it is already hard to work on old code or code that somebody else wrote. Adding a foreign language to the mix would be nightmarish. Doubly so if comments aren't in English. If your staff speaks a language besides English, OK, then do whatever you want. Otherwise, I'd give the idea a hard ""No"".",Apr 30 at 19:14
32,1,403,"It's a common misconception that security through obscurity is a ""bad idea"" per se but that is not correct. What's a bad idea is to rely on security through obscurity. If you're following best practices elsewhere then it can be fine as an added component to defence in depth. Often such tactics are useless at worst and marginally useful at best. A good example is running SSH on a non-default port. (I'm not saying that the OP's example is justified however).",Apr 30 at 23:18
32,1,404,"""The enemy knows the system.""",May 1 at 8:52
32,1,405,"I feel you're downplaying the last two points. Obscurity of this sort will make it harder for others to spot weaknesses in the system, no? Seems to me we can expect security to be actively weakened by this practice.",May 1 at 13:37
32,1,296,"@dandavis Fixing vulnerabilities is an important part of the software lifecycle. Anything that complicates that process is generally bad, and this is especially true for zero-days. If you slow the development process, you extend the window of zero-day vulnerability. I don't see a significant improvement from such an approach. Plus, just because your programmers are unfamiliar with a language doesn't mean your adversaries are too. I would assume there are adversaries fluent in any given language, which is actually a handicap if your programmers are not.",May 1 at 15:15
32,3,407,"To add, people can reverse engineer code from machine code. People have figured out how to hack complicated games by just looking at how their memory changes when they do actions. And that's without how the front end of the web forces you to give actual source code (even minimized, that's considerably higher level, and thus patterns are more evident). There's also anti-obfusification tools that try to somewhat undo some of the trickier obfusification techniques (and of course, code formatters also help).",May 1 at 22:30
32,3,408,"While this is correct in the case of Java / JavaScript, there are also some programming languages that use a non-English language for their built-in functionality. Though the obscurity of those languages may be more relevant to security than their function names.",May 3 at 6:43
32,3,76,"Not just reverse engineer games from runtime analysis, but even create completely working source code that compiles into exactly equivalent bytecode, turning a closed source game into a multiplatform game!",May 5 at 7:29
32,4,76,"It wouldn't be more secure, especially as reverse engineers (for example) often don't even have the original symbol names to work with, so are already used to working with completely made-up names or identifiers.",May 1 at 5:50
32,4,25,"We are talking about a REST, i.e. a web application. An attacker is far more likely to analyse the web interaction than the Java bytecode.",May 1 at 6:00
32,4,76,"My point is that reverse engineers are already used to this kind of thing, even if they're not doing actual decompilation. I wrote an answer to that effect, with C reverse engineering merely as an example.",May 1 at 6:01
32,4,410,"Naming things after their opposites would be more likely to introduce bugs than naming in a foreign language. ""And then, we call create_user and... Wait, why does it keep saying 'account does not exist'? Of course it doesn't exist -- that's why I'm trying to create it!"" But +1 for your more general point.",May 1 at 12:40
32,4,25,"Of course it's a silly idea and I don't recommend it. But from a purely security perspective, it would be more secure. :-) (not every secure idea is a good idea)",May 1 at 20:51
32,5,411,"Sure, I never intended to use language as a security measure. I was just curious about the community's thoughts on the matter.",May 1 at 22:24
32,5,412,This. Either your application is secure or it isn't. The language you use for naming parameters has zero effect on making it more secure.,May 2 at 12:59
32,6,92,"Your comparison has severe problems. Navajo was extremely rare and not a written language. The OP could simply be asking about a common language in his/her geographic location (i.e. the available dev talent pool speaks it). Also, translations could also be maintained on the dev end.",May 1 at 14:21
32,6,413,"@schroeder My choice of an oral language was perhaps poor, but the historical aspect made for an interesting analogy.  I carefully read the question for any hint about the developers' language, but even then there are major business aspects in terms of future out- or even in-sourcing. e.g. take the stereotypical case of outsourcing to India, and use Hindi.  Then when the bosses decide to bring the maintenance in house for political reasons you have to find fluent developers.  I did say it was extreme, to make a point",May 1 at 14:38
32,10,410,This is just rules-lawyering. The scheme would so obviously be pointless if the language chosen was the one spoken by most of the users that we can be sure the asker meant to exclude that.,May 1 at 12:46
32,10,417,"Yes, but presumably there are not many scenarios where the dev team can be relied on to always know the same non-English language and the community that uses the application don't know that language.",May 3 at 9:38
32,10,418,"Actually there are plenty of bilingual communities and markets. A lot of developers for the italian market are in Albania, so they can make the development in a different language. Same for developing in Hindu for an english speaking app, etc. All I wanted to point out is that the language of the users/targets will play a roll on how much ""security"" this factor can provide.",May 3 at 14:23
33,1,419,"The exception would be if a domain has been subdivided. E.g. user1 has control over example.com/user1 and subdomains, user2 has control over example.com/user2 and subdomains, etc. And theoretically, if the string ""example.com/test"" is generated dynamically, that could open an injection vulnerability.",Apr 12 at 18:18
33,1,420,maybe? but a redirect doesnt automatically grant you permission ... if I get redirected from /index.html to /superTopsecretKittys.html ... im still going to get a 401 Unauthorized,Apr 12 at 20:14
33,1,419,"Yes, but it raises phishing issues. If I can get do an injection attack that gets a website to redirect users to my website, then I be like ""Whoops, there's an error, you need to re-enter your credentials"".",Apr 12 at 20:26
33,1,420,thats a completely different issue ... if you inject something into someones website ... they have bigger problems then a simple redirect.,Apr 12 at 22:21
33,1,227,I wouldn't mention HTTP to HTTPS here. There are some weak spots in doing so that aren't relevant to the OP's description.,Apr 13 at 8:42
33,5,423,Sadly the edit does not improve the answer.,Apr 12 at 18:31
